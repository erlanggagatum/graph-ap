{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This model using modified similarity (similarity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from preprocessing import data_transformation\n",
    "from similarity import calculate_similarity_matrix\n",
    "\n",
    "from model import GCN\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='datasets/', name='MUTAG')\n",
    "torch.manual_seed(1234)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split: Train test validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```train_dataset```: for training model<br/>\n",
    "```val_dataset```: evaluate model for hyperparameter tunning<br/>\n",
    "```test_dataset```: testing model after complete training<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, ts, vl = 0.8, 0.1, 0.1\n",
    "dslen = len(dataset)\n",
    "tri = round(tr*dslen)\n",
    "tsi = round((tr+ts)*dslen)\n",
    "train_dataset = dataset[:tri]\n",
    "test_dataset = dataset[tri:tsi]\n",
    "val_dataset = dataset[tsi:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)\n",
    "test_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)\n",
    "val_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper 128\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MFConv\n",
    "# from torch_geometric.nn import GINConv\n",
    "from torch.nn import Linear, Sequential, ReLU, BatchNorm1d\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(Base, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = MFConv(in_channels=dataset.num_node_features, out_channels=hidden_channels)\n",
    "        self.conv2 = MFConv(in_channels=hidden_channels, out_channels=hidden_channels)\n",
    "                \n",
    "        # classification layer        \n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        h = self.lin(embedding)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.3, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base(model, loader, experiment_mode=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        if experiment_mode:\n",
    "            emb, h, S, communities, sub_emb = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(h, data.y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_base(model, loader, experiment_mode=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h, S, communities, sub_emb = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        pred = h.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseTrain(train_loader, val_loader, test_loader, epoch = 10, fold=0):\n",
    "    num_hidden_layer = 128\n",
    "    base = Base(dataset, num_hidden_layer)\n",
    "    early_stopping_patience = 20\n",
    "    best_val_score = -float(\"inf\")\n",
    "    epochs_without_improvement = 0\n",
    "    best_state = None\n",
    "    \n",
    "    # Train\n",
    "    for _ in range(epoch):\n",
    "        \n",
    "        loss = round(train_base(base, train_loader).item(), 5)\n",
    "        train_acc = round(test_base(base, train_loader), 5)\n",
    "        val_acc = round(test_base(base, val_loader), 5)\n",
    "        \n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; val_acc: {val_acc}; test: {round(test_base(base, test_loader), 2)}')\n",
    "\n",
    "        if (val_acc > best_val_score):\n",
    "            best_val_score = val_acc\n",
    "            epochs_without_improvement = 0\n",
    "            \n",
    "            print('best found, save model')\n",
    "            # save model\n",
    "            # torch.save(base.state_dict(), \"model-history/\"+str(fold)+\".base_best_model-_data-mutag.pth\")\n",
    "            best_state = copy.deepcopy(base.state_dict())\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if (epochs_without_improvement >= early_stopping_patience):\n",
    "                print('early stop triggered')\n",
    "                break\n",
    "                \n",
    "            \n",
    "    # Test\n",
    "    # test = test_base(best, test_loader)\n",
    "    # print(f'Accuracy: {test}')\n",
    "    \n",
    "    # Create a new instance of the model for testing\n",
    "    best_model = Base(dataset, num_hidden_layer)\n",
    "    best_model.load_state_dict(best_state)\n",
    "\n",
    "    # Test\n",
    "    test = test_base(best_model, test_loader)\n",
    "    print(f'Accuracy: {test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1])\n",
      "150\n",
      "tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[:round(len(dataset) * 0.8)]\n",
    "test_dataset = dataset[round(len(dataset) * 0.8):]\n",
    "print(train_dataset.y)\n",
    "print(len(train_dataset.y))\n",
    "print(test_dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.30551; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.35693; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 2; loss: 0.2006; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 3; loss: 0.25402; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 4; loss: 0.21419; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 5; loss: 0.32722; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 6; loss: 0.25249; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 7; loss: 0.28485; train_acc: 0.74815; val_acc: 0.8; test: 0.68\n",
      "best found, save model\n",
      "epoch 8; loss: 0.27261; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 9; loss: 0.28332; train_acc: 0.75556; val_acc: 0.8; test: 0.68\n",
      "epoch 10; loss: 0.15359; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 11; loss: 0.14743; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 12; loss: 0.23338; train_acc: 0.75556; val_acc: 0.8; test: 0.76\n",
      "epoch 13; loss: 0.31248; train_acc: 0.6963; val_acc: 0.6; test: 0.61\n",
      "epoch 14; loss: 0.20869; train_acc: 0.77037; val_acc: 0.8; test: 0.76\n",
      "epoch 15; loss: 0.24926; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 16; loss: 0.23254; train_acc: 0.86667; val_acc: 0.73333; test: 0.87\n",
      "epoch 17; loss: 0.15785; train_acc: 0.75556; val_acc: 0.8; test: 0.74\n",
      "epoch 18; loss: 0.20484; train_acc: 0.87407; val_acc: 0.8; test: 0.84\n",
      "epoch 19; loss: 0.26285; train_acc: 0.77037; val_acc: 0.8; test: 0.74\n",
      "epoch 20; loss: 0.316; train_acc: 0.87407; val_acc: 0.8; test: 0.87\n",
      "epoch 21; loss: 0.1521; train_acc: 0.7037; val_acc: 0.6; test: 0.63\n",
      "epoch 22; loss: 0.25549; train_acc: 0.88889; val_acc: 0.8; test: 0.87\n",
      "epoch 23; loss: 0.18908; train_acc: 0.77037; val_acc: 0.8; test: 0.74\n",
      "epoch 24; loss: 0.32497; train_acc: 0.87407; val_acc: 0.86667; test: 0.89\n",
      "best found, save model\n",
      "epoch 25; loss: 0.41594; train_acc: 0.85185; val_acc: 0.86667; test: 0.84\n",
      "epoch 26; loss: 0.11896; train_acc: 0.8; val_acc: 0.8; test: 0.79\n",
      "epoch 27; loss: 0.20215; train_acc: 0.9037; val_acc: 0.8; test: 0.87\n",
      "epoch 28; loss: 0.11633; train_acc: 0.74074; val_acc: 0.8; test: 0.74\n",
      "epoch 29; loss: 0.0683; train_acc: 0.85185; val_acc: 0.86667; test: 0.84\n",
      "epoch 30; loss: 0.17918; train_acc: 0.81481; val_acc: 0.8; test: 0.79\n",
      "epoch 31; loss: 0.12841; train_acc: 0.88889; val_acc: 0.86667; test: 0.89\n",
      "epoch 32; loss: 0.05478; train_acc: 0.79259; val_acc: 0.8; test: 0.74\n",
      "epoch 33; loss: 0.35327; train_acc: 0.88148; val_acc: 0.86667; test: 0.92\n",
      "epoch 34; loss: 0.12136; train_acc: 0.77037; val_acc: 0.8; test: 0.74\n",
      "epoch 35; loss: 0.21018; train_acc: 0.83704; val_acc: 0.86667; test: 0.84\n",
      "epoch 36; loss: 0.25226; train_acc: 0.88889; val_acc: 0.86667; test: 0.89\n",
      "epoch 37; loss: 0.3222; train_acc: 0.85926; val_acc: 0.86667; test: 0.87\n",
      "epoch 38; loss: 0.19506; train_acc: 0.88889; val_acc: 0.86667; test: 0.89\n",
      "epoch 39; loss: 0.10332; train_acc: 0.86667; val_acc: 0.86667; test: 0.87\n",
      "epoch 40; loss: 0.32621; train_acc: 0.88889; val_acc: 0.93333; test: 0.92\n",
      "best found, save model\n",
      "epoch 41; loss: 0.33225; train_acc: 0.88889; val_acc: 0.93333; test: 0.89\n",
      "epoch 42; loss: 0.17359; train_acc: 0.88889; val_acc: 0.93333; test: 0.92\n",
      "epoch 43; loss: 0.20246; train_acc: 0.8963; val_acc: 1.0; test: 0.92\n",
      "best found, save model\n",
      "epoch 44; loss: 0.19509; train_acc: 0.88148; val_acc: 0.86667; test: 0.76\n",
      "epoch 45; loss: 0.11929; train_acc: 0.74074; val_acc: 0.73333; test: 0.87\n",
      "epoch 46; loss: 0.05078; train_acc: 0.84444; val_acc: 0.86667; test: 0.74\n",
      "epoch 47; loss: 0.05298; train_acc: 0.84444; val_acc: 0.8; test: 0.89\n",
      "epoch 48; loss: 0.03235; train_acc: 0.78519; val_acc: 0.8; test: 0.74\n",
      "epoch 49; loss: 0.15408; train_acc: 0.88889; val_acc: 0.93333; test: 0.89\n",
      "Accuracy: 0.9210526315789473\n",
      "Fold 1/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.32279; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.32831; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 2; loss: 0.27318; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 3; loss: 0.39365; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 4; loss: 0.32039; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 5; loss: 0.42457; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 6; loss: 0.2361; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 7; loss: 0.34691; train_acc: 0.80741; val_acc: 0.66667; test: 0.79\n",
      "epoch 8; loss: 0.35266; train_acc: 0.6963; val_acc: 0.66667; test: 0.63\n",
      "epoch 9; loss: 0.28954; train_acc: 0.72593; val_acc: 0.6; test: 0.63\n",
      "epoch 10; loss: 0.26511; train_acc: 0.77778; val_acc: 0.66667; test: 0.74\n",
      "epoch 11; loss: 0.09185; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 12; loss: 0.31189; train_acc: 0.88148; val_acc: 0.73333; test: 0.84\n",
      "best found, save model\n",
      "epoch 13; loss: 0.33568; train_acc: 0.78519; val_acc: 0.66667; test: 0.74\n",
      "epoch 14; loss: 0.27193; train_acc: 0.85185; val_acc: 0.66667; test: 0.84\n",
      "epoch 15; loss: 0.26236; train_acc: 0.79259; val_acc: 0.66667; test: 0.74\n",
      "epoch 16; loss: 0.25377; train_acc: 0.80741; val_acc: 0.66667; test: 0.79\n",
      "epoch 17; loss: 0.17344; train_acc: 0.74815; val_acc: 0.66667; test: 0.74\n",
      "epoch 18; loss: 0.13408; train_acc: 0.77778; val_acc: 0.86667; test: 0.92\n",
      "best found, save model\n",
      "epoch 19; loss: 0.16646; train_acc: 0.77037; val_acc: 0.66667; test: 0.74\n",
      "epoch 20; loss: 0.18109; train_acc: 0.77778; val_acc: 0.86667; test: 0.92\n",
      "epoch 21; loss: 0.17375; train_acc: 0.8; val_acc: 0.66667; test: 0.74\n",
      "epoch 22; loss: 0.26763; train_acc: 0.88148; val_acc: 0.66667; test: 0.84\n",
      "epoch 23; loss: 0.17341; train_acc: 0.8; val_acc: 0.66667; test: 0.74\n",
      "epoch 24; loss: 0.17375; train_acc: 0.67407; val_acc: 0.86667; test: 0.84\n",
      "epoch 25; loss: 0.17655; train_acc: 0.81481; val_acc: 0.6; test: 0.79\n",
      "epoch 26; loss: 0.18623; train_acc: 0.6963; val_acc: 0.86667; test: 0.89\n",
      "epoch 27; loss: 0.12648; train_acc: 0.8; val_acc: 0.66667; test: 0.74\n",
      "epoch 28; loss: 0.17528; train_acc: 0.9037; val_acc: 0.73333; test: 0.87\n",
      "epoch 29; loss: 0.08427; train_acc: 0.74815; val_acc: 0.73333; test: 0.74\n",
      "epoch 30; loss: 0.14785; train_acc: 0.88148; val_acc: 0.86667; test: 0.92\n",
      "epoch 31; loss: 0.25649; train_acc: 0.85185; val_acc: 0.6; test: 0.82\n",
      "epoch 32; loss: 0.29001; train_acc: 0.91111; val_acc: 0.73333; test: 0.89\n",
      "epoch 33; loss: 0.18391; train_acc: 0.81481; val_acc: 0.66667; test: 0.74\n",
      "epoch 34; loss: 0.32717; train_acc: 0.9037; val_acc: 0.73333; test: 0.89\n",
      "epoch 35; loss: 0.04695; train_acc: 0.77037; val_acc: 0.73333; test: 0.74\n",
      "epoch 36; loss: 0.1431; train_acc: 0.85926; val_acc: 0.86667; test: 0.92\n",
      "epoch 37; loss: 0.19232; train_acc: 0.87407; val_acc: 0.6; test: 0.84\n",
      "epoch 38; loss: 0.2102; train_acc: 0.91111; val_acc: 0.73333; test: 0.92\n",
      "early stop triggered\n",
      "Accuracy: 0.9210526315789473\n",
      "Fold 2/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.31188; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.43171; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 2; loss: 0.28151; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 3; loss: 0.41403; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 4; loss: 0.16813; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 5; loss: 0.37987; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 6; loss: 0.20582; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 7; loss: 0.34478; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 8; loss: 0.16792; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 9; loss: 0.29974; train_acc: 0.75556; val_acc: 0.53333; test: 0.66\n",
      "epoch 10; loss: 0.26582; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 11; loss: 0.18875; train_acc: 0.6963; val_acc: 0.53333; test: 0.61\n",
      "epoch 12; loss: 0.15116; train_acc: 0.76296; val_acc: 0.6; test: 0.66\n",
      "best found, save model\n",
      "epoch 13; loss: 0.13248; train_acc: 0.7037; val_acc: 0.53333; test: 0.61\n",
      "epoch 14; loss: 0.19959; train_acc: 0.77778; val_acc: 0.66667; test: 0.76\n",
      "best found, save model\n",
      "epoch 15; loss: 0.33288; train_acc: 0.77778; val_acc: 0.6; test: 0.74\n",
      "epoch 16; loss: 0.14719; train_acc: 0.79259; val_acc: 0.73333; test: 0.79\n",
      "best found, save model\n",
      "epoch 17; loss: 0.09331; train_acc: 0.75556; val_acc: 0.6; test: 0.68\n",
      "epoch 18; loss: 0.19585; train_acc: 0.77778; val_acc: 0.86667; test: 0.89\n",
      "best found, save model\n",
      "epoch 19; loss: 0.0901; train_acc: 0.75556; val_acc: 0.6; test: 0.74\n",
      "epoch 20; loss: 0.13128; train_acc: 0.82963; val_acc: 0.73333; test: 0.82\n",
      "epoch 21; loss: 0.19311; train_acc: 0.88889; val_acc: 0.8; test: 0.84\n",
      "epoch 22; loss: 0.14846; train_acc: 0.78519; val_acc: 0.6; test: 0.76\n",
      "epoch 23; loss: 0.10245; train_acc: 0.81481; val_acc: 0.86667; test: 0.89\n",
      "epoch 24; loss: 0.16664; train_acc: 0.77037; val_acc: 0.6; test: 0.74\n",
      "epoch 25; loss: 0.12203; train_acc: 0.8; val_acc: 0.86667; test: 0.89\n",
      "epoch 26; loss: 0.2351; train_acc: 0.79259; val_acc: 0.6; test: 0.74\n",
      "epoch 27; loss: 0.15098; train_acc: 0.88889; val_acc: 0.8; test: 0.87\n",
      "epoch 28; loss: 0.07751; train_acc: 0.74074; val_acc: 0.6; test: 0.66\n",
      "epoch 29; loss: 0.10277; train_acc: 0.84444; val_acc: 0.8; test: 0.82\n",
      "epoch 30; loss: 0.18893; train_acc: 0.87407; val_acc: 0.8; test: 0.84\n",
      "epoch 31; loss: 0.16307; train_acc: 0.79259; val_acc: 0.6; test: 0.74\n",
      "epoch 32; loss: 0.10445; train_acc: 0.71111; val_acc: 0.73333; test: 0.82\n",
      "epoch 33; loss: 0.15113; train_acc: 0.79259; val_acc: 0.6; test: 0.74\n",
      "epoch 34; loss: 0.16053; train_acc: 0.9037; val_acc: 0.86667; test: 0.89\n",
      "epoch 35; loss: 0.14446; train_acc: 0.8; val_acc: 0.6; test: 0.74\n",
      "epoch 36; loss: 0.04355; train_acc: 0.91111; val_acc: 0.86667; test: 0.89\n",
      "epoch 37; loss: 0.54397; train_acc: 0.87407; val_acc: 0.8; test: 0.82\n",
      "epoch 38; loss: 0.57127; train_acc: 0.91111; val_acc: 0.86667; test: 0.92\n",
      "early stop triggered\n",
      "Accuracy: 0.8947368421052632\n",
      "Fold 3/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.33054; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.30397; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 2; loss: 0.27141; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 3; loss: 0.19967; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 4; loss: 0.26384; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 5; loss: 0.19288; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 6; loss: 0.22855; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 7; loss: 0.2487; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 8; loss: 0.22651; train_acc: 0.74074; val_acc: 0.86667; test: 0.66\n",
      "best found, save model\n",
      "epoch 9; loss: 0.2173; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 10; loss: 0.24384; train_acc: 0.8; val_acc: 0.93333; test: 0.79\n",
      "best found, save model\n",
      "epoch 11; loss: 0.10186; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 12; loss: 0.26726; train_acc: 0.82963; val_acc: 0.86667; test: 0.84\n",
      "epoch 13; loss: 0.13732; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 14; loss: 0.23623; train_acc: 0.82222; val_acc: 0.73333; test: 0.89\n",
      "epoch 15; loss: 0.28527; train_acc: 0.77037; val_acc: 0.86667; test: 0.74\n",
      "epoch 16; loss: 0.26053; train_acc: 0.79259; val_acc: 0.53333; test: 0.92\n",
      "epoch 17; loss: 0.16476; train_acc: 0.73333; val_acc: 0.86667; test: 0.68\n",
      "epoch 18; loss: 0.18336; train_acc: 0.80741; val_acc: 0.73333; test: 0.89\n",
      "epoch 19; loss: 0.34348; train_acc: 0.79259; val_acc: 0.86667; test: 0.84\n",
      "epoch 20; loss: 0.12807; train_acc: 0.74815; val_acc: 0.86667; test: 0.74\n",
      "epoch 21; loss: 0.18659; train_acc: 0.85185; val_acc: 0.86667; test: 0.87\n",
      "epoch 22; loss: 0.23682; train_acc: 0.85185; val_acc: 0.86667; test: 0.87\n",
      "epoch 23; loss: 0.26714; train_acc: 0.88889; val_acc: 0.86667; test: 0.84\n",
      "epoch 24; loss: 0.20337; train_acc: 0.75556; val_acc: 0.86667; test: 0.74\n",
      "epoch 25; loss: 0.14256; train_acc: 0.88148; val_acc: 0.86667; test: 0.92\n",
      "epoch 26; loss: 0.2046; train_acc: 0.81481; val_acc: 0.86667; test: 0.82\n",
      "epoch 27; loss: 0.10958; train_acc: 0.71852; val_acc: 0.4; test: 0.82\n",
      "epoch 28; loss: 0.21123; train_acc: 0.77778; val_acc: 0.86667; test: 0.76\n",
      "epoch 29; loss: 0.13319; train_acc: 0.76296; val_acc: 0.46667; test: 0.92\n",
      "epoch 30; loss: 0.11522; train_acc: 0.85185; val_acc: 0.86667; test: 0.84\n",
      "early stop triggered\n",
      "Accuracy: 0.7894736842105263\n",
      "Fold 4/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.32638; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.33984; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 2; loss: 0.27564; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 3; loss: 0.35; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 4; loss: 0.1534; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 5; loss: 0.36599; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 6; loss: 0.21628; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 7; loss: 0.20465; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 8; loss: 0.38435; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 9; loss: 0.31399; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 10; loss: 0.22114; train_acc: 0.75556; val_acc: 0.6; test: 0.68\n",
      "epoch 11; loss: 0.10498; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 12; loss: 0.32823; train_acc: 0.81481; val_acc: 0.73333; test: 0.89\n",
      "best found, save model\n",
      "epoch 13; loss: 0.2857; train_acc: 0.77037; val_acc: 0.66667; test: 0.71\n",
      "epoch 14; loss: 0.21125; train_acc: 0.85926; val_acc: 0.8; test: 0.84\n",
      "best found, save model\n",
      "epoch 15; loss: 0.23956; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 16; loss: 0.23515; train_acc: 0.86667; val_acc: 0.8; test: 0.84\n",
      "epoch 17; loss: 0.15905; train_acc: 0.76296; val_acc: 0.66667; test: 0.74\n",
      "epoch 18; loss: 0.2236; train_acc: 0.88148; val_acc: 0.73333; test: 0.84\n",
      "epoch 19; loss: 0.1918; train_acc: 0.74815; val_acc: 0.66667; test: 0.74\n",
      "epoch 20; loss: 0.24462; train_acc: 0.80741; val_acc: 0.73333; test: 0.92\n",
      "epoch 21; loss: 0.17568; train_acc: 0.77037; val_acc: 0.66667; test: 0.74\n",
      "epoch 22; loss: 0.18243; train_acc: 0.82222; val_acc: 0.73333; test: 0.89\n",
      "epoch 23; loss: 0.25207; train_acc: 0.76296; val_acc: 0.66667; test: 0.74\n",
      "epoch 24; loss: 0.23423; train_acc: 0.81481; val_acc: 0.73333; test: 0.89\n",
      "epoch 25; loss: 0.28451; train_acc: 0.82222; val_acc: 0.6; test: 0.84\n",
      "epoch 26; loss: 0.20282; train_acc: 0.87407; val_acc: 0.73333; test: 0.87\n",
      "epoch 27; loss: 0.22497; train_acc: 0.82222; val_acc: 0.6; test: 0.82\n",
      "epoch 28; loss: 0.21848; train_acc: 0.88889; val_acc: 0.8; test: 0.84\n",
      "epoch 29; loss: 0.11112; train_acc: 0.80741; val_acc: 0.66667; test: 0.74\n",
      "epoch 30; loss: 0.20377; train_acc: 0.8963; val_acc: 0.73333; test: 0.89\n",
      "epoch 31; loss: 0.03396; train_acc: 0.74815; val_acc: 0.66667; test: 0.71\n",
      "epoch 32; loss: 0.1627; train_acc: 0.9037; val_acc: 0.73333; test: 0.92\n",
      "epoch 33; loss: 0.20914; train_acc: 0.81481; val_acc: 0.6; test: 0.74\n",
      "epoch 34; loss: 0.12103; train_acc: 0.74815; val_acc: 0.66667; test: 0.89\n",
      "early stop triggered\n",
      "Accuracy: 0.8421052631578947\n",
      "Fold 5/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.31118; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.39547; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 2; loss: 0.3538; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 3; loss: 0.31866; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 4; loss: 0.23026; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 5; loss: 0.29989; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 6; loss: 0.26361; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 7; loss: 0.28195; train_acc: 0.74815; val_acc: 0.86667; test: 0.74\n",
      "best found, save model\n",
      "epoch 8; loss: 0.28148; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 9; loss: 0.23767; train_acc: 0.6963; val_acc: 0.8; test: 0.66\n",
      "epoch 10; loss: 0.12491; train_acc: 0.67407; val_acc: 0.73333; test: 0.61\n",
      "epoch 11; loss: 0.13841; train_acc: 0.68889; val_acc: 0.73333; test: 0.63\n",
      "epoch 12; loss: 0.23463; train_acc: 0.75556; val_acc: 0.93333; test: 0.76\n",
      "best found, save model\n",
      "epoch 13; loss: 0.24493; train_acc: 0.6963; val_acc: 0.73333; test: 0.63\n",
      "epoch 14; loss: 0.22742; train_acc: 0.84444; val_acc: 0.86667; test: 0.87\n",
      "epoch 15; loss: 0.28053; train_acc: 0.67407; val_acc: 0.73333; test: 0.63\n",
      "epoch 16; loss: 0.15231; train_acc: 0.76296; val_acc: 0.93333; test: 0.74\n",
      "epoch 17; loss: 0.18158; train_acc: 0.82222; val_acc: 0.86667; test: 0.89\n",
      "epoch 18; loss: 0.27294; train_acc: 0.77037; val_acc: 0.93333; test: 0.79\n",
      "epoch 19; loss: 0.28618; train_acc: 0.81481; val_acc: 0.93333; test: 0.84\n",
      "epoch 20; loss: 0.32426; train_acc: 0.88148; val_acc: 0.86667; test: 0.89\n",
      "epoch 21; loss: 0.08626; train_acc: 0.73333; val_acc: 0.8; test: 0.68\n",
      "epoch 22; loss: 0.08997; train_acc: 0.77037; val_acc: 0.93333; test: 0.79\n",
      "epoch 23; loss: 0.26741; train_acc: 0.88889; val_acc: 0.86667; test: 0.89\n",
      "epoch 24; loss: 0.34785; train_acc: 0.83704; val_acc: 0.93333; test: 0.82\n",
      "epoch 25; loss: 0.16085; train_acc: 0.73333; val_acc: 0.73333; test: 0.89\n",
      "epoch 26; loss: 0.12818; train_acc: 0.75556; val_acc: 0.86667; test: 0.74\n",
      "epoch 27; loss: 0.09995; train_acc: 0.87407; val_acc: 0.86667; test: 0.92\n",
      "epoch 28; loss: 0.06707; train_acc: 0.74815; val_acc: 0.8; test: 0.74\n",
      "epoch 29; loss: 0.17729; train_acc: 0.88889; val_acc: 0.86667; test: 0.89\n",
      "epoch 30; loss: 0.20533; train_acc: 0.87407; val_acc: 0.86667; test: 0.87\n",
      "epoch 31; loss: 0.14721; train_acc: 0.8963; val_acc: 0.86667; test: 0.89\n",
      "epoch 32; loss: 0.06385; train_acc: 0.83704; val_acc: 0.93333; test: 0.84\n",
      "early stop triggered\n",
      "Accuracy: 0.7631578947368421\n",
      "Fold 6/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.30761; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.24957; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 2; loss: 0.29569; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 3; loss: 0.25756; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 4; loss: 0.43532; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 5; loss: 0.3081; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 6; loss: 0.41203; train_acc: 0.6963; val_acc: 0.6; test: 0.61\n",
      "epoch 7; loss: 0.24857; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 8; loss: 0.2156; train_acc: 0.73333; val_acc: 0.66667; test: 0.68\n",
      "best found, save model\n",
      "epoch 9; loss: 0.29777; train_acc: 0.6963; val_acc: 0.6; test: 0.61\n",
      "epoch 10; loss: 0.17052; train_acc: 0.73333; val_acc: 0.66667; test: 0.66\n",
      "epoch 11; loss: 0.20791; train_acc: 0.71852; val_acc: 0.6; test: 0.61\n",
      "epoch 12; loss: 0.25915; train_acc: 0.78519; val_acc: 0.8; test: 0.79\n",
      "best found, save model\n",
      "epoch 13; loss: 0.21901; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 14; loss: 0.21859; train_acc: 0.80741; val_acc: 0.86667; test: 0.89\n",
      "best found, save model\n",
      "epoch 15; loss: 0.19915; train_acc: 0.68889; val_acc: 0.6; test: 0.61\n",
      "epoch 16; loss: 0.206; train_acc: 0.82963; val_acc: 0.93333; test: 0.84\n",
      "best found, save model\n",
      "epoch 17; loss: 0.30743; train_acc: 0.77037; val_acc: 0.8; test: 0.74\n",
      "epoch 18; loss: 0.17015; train_acc: 0.80741; val_acc: 0.8; test: 0.82\n",
      "epoch 19; loss: 0.14087; train_acc: 0.74815; val_acc: 0.86667; test: 0.74\n",
      "epoch 20; loss: 0.14025; train_acc: 0.78519; val_acc: 0.8; test: 0.92\n",
      "epoch 21; loss: 0.1079; train_acc: 0.74815; val_acc: 0.66667; test: 0.71\n",
      "epoch 22; loss: 0.08622; train_acc: 0.8; val_acc: 0.8; test: 0.79\n",
      "epoch 23; loss: 0.28569; train_acc: 0.86667; val_acc: 0.93333; test: 0.89\n",
      "epoch 24; loss: 0.22008; train_acc: 0.79259; val_acc: 0.8; test: 0.79\n",
      "epoch 25; loss: 0.14552; train_acc: 0.87407; val_acc: 0.93333; test: 0.84\n",
      "epoch 26; loss: 0.03316; train_acc: 0.74074; val_acc: 0.6; test: 0.71\n",
      "epoch 27; loss: 0.22391; train_acc: 0.86667; val_acc: 0.93333; test: 0.89\n",
      "epoch 28; loss: 0.21602; train_acc: 0.77778; val_acc: 0.8; test: 0.74\n",
      "epoch 29; loss: 0.20221; train_acc: 0.83704; val_acc: 0.93333; test: 0.89\n",
      "epoch 30; loss: 0.06143; train_acc: 0.74815; val_acc: 0.86667; test: 0.74\n",
      "epoch 31; loss: 0.07275; train_acc: 0.86667; val_acc: 0.93333; test: 0.87\n",
      "epoch 32; loss: 0.12304; train_acc: 0.83704; val_acc: 0.86667; test: 0.82\n",
      "epoch 33; loss: 0.16311; train_acc: 0.86667; val_acc: 0.93333; test: 0.89\n",
      "epoch 34; loss: 0.26566; train_acc: 0.76296; val_acc: 0.86667; test: 0.74\n",
      "epoch 35; loss: 0.18899; train_acc: 0.87407; val_acc: 0.93333; test: 0.92\n",
      "epoch 36; loss: 0.17341; train_acc: 0.79259; val_acc: 0.8; test: 0.71\n",
      "early stop triggered\n",
      "Accuracy: 0.8421052631578947\n",
      "Fold 7/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.33045; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.34399; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 2; loss: 0.3735; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 3; loss: 0.33317; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 4; loss: 0.22281; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 5; loss: 0.21626; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 6; loss: 0.25722; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 7; loss: 0.18334; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 8; loss: 0.16807; train_acc: 0.67407; val_acc: 0.8; test: 0.61\n",
      "epoch 9; loss: 0.19149; train_acc: 0.7037; val_acc: 0.86667; test: 0.66\n",
      "best found, save model\n",
      "epoch 10; loss: 0.24316; train_acc: 0.68889; val_acc: 0.86667; test: 0.63\n",
      "epoch 11; loss: 0.21356; train_acc: 0.77778; val_acc: 0.86667; test: 0.74\n",
      "epoch 12; loss: 0.23471; train_acc: 0.77778; val_acc: 0.86667; test: 0.76\n",
      "epoch 13; loss: 0.08909; train_acc: 0.67407; val_acc: 0.8; test: 0.61\n",
      "epoch 14; loss: 0.25744; train_acc: 0.8; val_acc: 0.86667; test: 0.92\n",
      "epoch 15; loss: 0.32013; train_acc: 0.80741; val_acc: 0.86667; test: 0.79\n",
      "epoch 16; loss: 0.13093; train_acc: 0.73333; val_acc: 0.86667; test: 0.71\n",
      "epoch 17; loss: 0.17602; train_acc: 0.84444; val_acc: 0.93333; test: 0.82\n",
      "best found, save model\n",
      "epoch 18; loss: 0.22252; train_acc: 0.77037; val_acc: 0.86667; test: 0.76\n",
      "epoch 19; loss: 0.27416; train_acc: 0.80741; val_acc: 0.86667; test: 0.89\n",
      "epoch 20; loss: 0.2135; train_acc: 0.74815; val_acc: 0.86667; test: 0.74\n",
      "epoch 21; loss: 0.25883; train_acc: 0.82222; val_acc: 0.86667; test: 0.82\n",
      "epoch 22; loss: 0.13523; train_acc: 0.78519; val_acc: 0.86667; test: 0.76\n",
      "epoch 23; loss: 0.25274; train_acc: 0.82222; val_acc: 0.93333; test: 0.89\n",
      "epoch 24; loss: 0.26123; train_acc: 0.77778; val_acc: 0.86667; test: 0.76\n",
      "epoch 25; loss: 0.20241; train_acc: 0.85185; val_acc: 1.0; test: 0.87\n",
      "best found, save model\n",
      "epoch 26; loss: 0.17562; train_acc: 0.88148; val_acc: 1.0; test: 0.84\n",
      "epoch 27; loss: 0.12658; train_acc: 0.81481; val_acc: 0.86667; test: 0.82\n",
      "epoch 28; loss: 0.2927; train_acc: 0.88148; val_acc: 1.0; test: 0.87\n",
      "epoch 29; loss: 0.05132; train_acc: 0.76296; val_acc: 0.86667; test: 0.74\n",
      "epoch 30; loss: 0.1282; train_acc: 0.82963; val_acc: 0.86667; test: 0.89\n",
      "epoch 31; loss: 0.1302; train_acc: 0.83704; val_acc: 0.93333; test: 0.82\n",
      "epoch 32; loss: 0.21833; train_acc: 0.68889; val_acc: 0.73333; test: 0.82\n",
      "epoch 33; loss: 0.16692; train_acc: 0.77778; val_acc: 0.86667; test: 0.76\n",
      "epoch 34; loss: 0.26336; train_acc: 0.88889; val_acc: 1.0; test: 0.89\n",
      "epoch 35; loss: 0.09819; train_acc: 0.77778; val_acc: 0.86667; test: 0.74\n",
      "epoch 36; loss: 0.09146; train_acc: 0.82222; val_acc: 0.86667; test: 0.89\n",
      "epoch 37; loss: 0.38923; train_acc: 0.85185; val_acc: 1.0; test: 0.84\n",
      "epoch 38; loss: 0.18112; train_acc: 0.88889; val_acc: 1.0; test: 0.89\n",
      "epoch 39; loss: 0.17086; train_acc: 0.85926; val_acc: 1.0; test: 0.84\n",
      "epoch 40; loss: 0.30932; train_acc: 0.9037; val_acc: 1.0; test: 0.89\n",
      "epoch 41; loss: 0.0976; train_acc: 0.83704; val_acc: 1.0; test: 0.82\n",
      "epoch 42; loss: 0.1771; train_acc: 0.9037; val_acc: 1.0; test: 0.89\n",
      "epoch 43; loss: 0.16815; train_acc: 0.76296; val_acc: 0.93333; test: 0.71\n",
      "epoch 44; loss: 0.22929; train_acc: 0.77037; val_acc: 0.8; test: 0.87\n",
      "epoch 45; loss: 0.06916; train_acc: 0.82963; val_acc: 0.93333; test: 0.74\n",
      "early stop triggered\n",
      "Accuracy: 0.868421052631579\n",
      "Fold 8/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.31; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.28345; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 2; loss: 0.35204; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 3; loss: 0.24267; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 4; loss: 0.27447; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 5; loss: 0.26219; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 6; loss: 0.19932; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 7; loss: 0.27577; train_acc: 0.79259; val_acc: 0.73333; test: 0.76\n",
      "epoch 8; loss: 0.15919; train_acc: 0.66667; val_acc: 0.8; test: 0.61\n",
      "epoch 9; loss: 0.19221; train_acc: 0.68889; val_acc: 0.8; test: 0.63\n",
      "epoch 10; loss: 0.21218; train_acc: 0.71111; val_acc: 0.73333; test: 0.66\n",
      "epoch 11; loss: 0.15941; train_acc: 0.74074; val_acc: 0.73333; test: 0.68\n",
      "epoch 12; loss: 0.27344; train_acc: 0.8; val_acc: 0.8; test: 0.89\n",
      "epoch 13; loss: 0.22806; train_acc: 0.73333; val_acc: 0.8; test: 0.68\n",
      "epoch 14; loss: 0.18638; train_acc: 0.84444; val_acc: 0.8; test: 0.79\n",
      "epoch 15; loss: 0.17119; train_acc: 0.74815; val_acc: 0.73333; test: 0.74\n",
      "epoch 16; loss: 0.24763; train_acc: 0.84444; val_acc: 0.86667; test: 0.84\n",
      "best found, save model\n",
      "epoch 17; loss: 0.11943; train_acc: 0.74815; val_acc: 0.73333; test: 0.74\n",
      "epoch 18; loss: 0.20832; train_acc: 0.74815; val_acc: 0.73333; test: 0.92\n",
      "epoch 19; loss: 0.26434; train_acc: 0.78519; val_acc: 0.73333; test: 0.76\n",
      "epoch 20; loss: 0.22138; train_acc: 0.87407; val_acc: 0.73333; test: 0.82\n",
      "epoch 21; loss: 0.10783; train_acc: 0.71852; val_acc: 0.8; test: 0.71\n",
      "epoch 22; loss: 0.21172; train_acc: 0.88148; val_acc: 0.86667; test: 0.84\n",
      "epoch 23; loss: 0.35103; train_acc: 0.82963; val_acc: 0.73333; test: 0.82\n",
      "epoch 24; loss: 0.13576; train_acc: 0.88889; val_acc: 0.8; test: 0.84\n",
      "epoch 25; loss: 0.1904; train_acc: 0.77778; val_acc: 0.73333; test: 0.74\n",
      "epoch 26; loss: 0.17191; train_acc: 0.87407; val_acc: 0.73333; test: 0.84\n",
      "epoch 27; loss: 0.19052; train_acc: 0.91111; val_acc: 0.8; test: 0.87\n",
      "epoch 28; loss: 0.14961; train_acc: 0.77778; val_acc: 0.73333; test: 0.74\n",
      "epoch 29; loss: 0.10145; train_acc: 0.73333; val_acc: 0.73333; test: 0.92\n",
      "epoch 30; loss: 0.10414; train_acc: 0.83704; val_acc: 0.73333; test: 0.79\n",
      "epoch 31; loss: 0.12463; train_acc: 0.83704; val_acc: 0.86667; test: 0.89\n",
      "epoch 32; loss: 0.34304; train_acc: 0.87407; val_acc: 0.73333; test: 0.84\n",
      "epoch 33; loss: 0.11245; train_acc: 0.88148; val_acc: 0.73333; test: 0.84\n",
      "epoch 34; loss: 0.23111; train_acc: 0.87407; val_acc: 0.8; test: 0.82\n",
      "epoch 35; loss: 0.31019; train_acc: 0.9037; val_acc: 0.73333; test: 0.87\n",
      "epoch 36; loss: 0.15638; train_acc: 0.85185; val_acc: 0.73333; test: 0.79\n",
      "early stop triggered\n",
      "Accuracy: 0.8421052631578947\n",
      "Fold 9/10\n",
      "=== Base model vs Experiment ===\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.34516; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "best found, save model\n",
      "epoch 1; loss: 0.25602; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 2; loss: 0.28748; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 3; loss: 0.38612; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 4; loss: 0.21682; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 5; loss: 0.26345; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 6; loss: 0.27252; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 7; loss: 0.27649; train_acc: 0.77778; val_acc: 0.66667; test: 0.74\n",
      "epoch 8; loss: 0.25567; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 9; loss: 0.26501; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 10; loss: 0.21444; train_acc: 0.68148; val_acc: 0.66667; test: 0.61\n",
      "epoch 11; loss: 0.15718; train_acc: 0.68889; val_acc: 0.66667; test: 0.61\n",
      "epoch 12; loss: 0.20658; train_acc: 0.77037; val_acc: 0.66667; test: 0.68\n",
      "epoch 13; loss: 0.14493; train_acc: 0.77037; val_acc: 0.66667; test: 0.68\n",
      "epoch 14; loss: 0.2828; train_acc: 0.81481; val_acc: 0.66667; test: 0.87\n",
      "epoch 15; loss: 0.34187; train_acc: 0.77037; val_acc: 0.8; test: 0.79\n",
      "best found, save model\n",
      "epoch 16; loss: 0.18291; train_acc: 0.77778; val_acc: 0.73333; test: 0.74\n",
      "epoch 17; loss: 0.15308; train_acc: 0.79259; val_acc: 0.86667; test: 0.79\n",
      "best found, save model\n",
      "epoch 18; loss: 0.17027; train_acc: 0.83704; val_acc: 0.8; test: 0.82\n",
      "epoch 19; loss: 0.30152; train_acc: 0.80741; val_acc: 0.86667; test: 0.79\n",
      "epoch 20; loss: 0.21838; train_acc: 0.77778; val_acc: 0.73333; test: 0.76\n",
      "epoch 21; loss: 0.26561; train_acc: 0.88148; val_acc: 0.8; test: 0.84\n",
      "epoch 22; loss: 0.11254; train_acc: 0.77778; val_acc: 0.73333; test: 0.76\n",
      "epoch 23; loss: 0.11192; train_acc: 0.84444; val_acc: 0.73333; test: 0.89\n",
      "epoch 24; loss: 0.22757; train_acc: 0.76296; val_acc: 0.73333; test: 0.71\n",
      "epoch 25; loss: 0.13099; train_acc: 0.88148; val_acc: 0.8; test: 0.82\n",
      "epoch 26; loss: 0.15321; train_acc: 0.87407; val_acc: 0.8; test: 0.82\n",
      "epoch 27; loss: 0.22993; train_acc: 0.85926; val_acc: 0.86667; test: 0.82\n",
      "epoch 28; loss: 0.21692; train_acc: 0.86667; val_acc: 0.73333; test: 0.89\n",
      "epoch 29; loss: 0.12756; train_acc: 0.77778; val_acc: 0.73333; test: 0.74\n",
      "epoch 30; loss: 0.23881; train_acc: 0.85185; val_acc: 0.73333; test: 0.89\n",
      "epoch 31; loss: 0.06585; train_acc: 0.77037; val_acc: 0.66667; test: 0.74\n",
      "epoch 32; loss: 0.32565; train_acc: 0.87407; val_acc: 0.8; test: 0.87\n",
      "epoch 33; loss: 0.16438; train_acc: 0.85926; val_acc: 0.86667; test: 0.82\n",
      "epoch 34; loss: 0.40635; train_acc: 0.9037; val_acc: 0.86667; test: 0.89\n",
      "epoch 35; loss: 0.12848; train_acc: 0.77778; val_acc: 0.73333; test: 0.74\n",
      "epoch 36; loss: 0.07311; train_acc: 0.88889; val_acc: 0.86667; test: 0.89\n",
      "epoch 37; loss: 0.08784; train_acc: 0.82222; val_acc: 0.86667; test: 0.79\n",
      "early stop triggered\n",
      "Accuracy: 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_dataset\n",
    "test_dataset\n",
    "k = 10\n",
    "batch_size = 128\n",
    "\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "k_counter = 0\n",
    "fold_logs = {}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(train_dataset)))):\n",
    "    print(f'Fold {fold}/{k}')\n",
    "    \n",
    "    fold_train = []\n",
    "    for key in train_idx:\n",
    "        fold_train.append(train_dataset[key])\n",
    "\n",
    "    fold_val = [] \n",
    "    for key in val_idx:\n",
    "        fold_val.append(train_dataset[key])\n",
    "\n",
    "    tr = DataLoader(fold_train, batch_size=batch_size, shuffle=True)\n",
    "    vd = DataLoader(fold_val, batch_size=batch_size, shuffle=True)\n",
    "    ts = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(\"=== Base model vs Experiment ===\")\n",
    "    print(\"=== Base model ===\")\n",
    "    fold_logs[fold] = baseTrain(tr, vd, ts, 50, fold=fold)\n",
    "    k_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: None, 1: None, 2: None, 3: None, 4: None, 5: None, 6: None, 7: None, 8: None, 9: None}\n"
     ]
    }
   ],
   "source": [
    "print(fold_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Experiment(dataset=dataset, hidden_channels=128)\n",
    "e.load_state_dict(torch.load(\"model-history/GIN-MUTAG/6.experiment_best_model-gin_data-mutag.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
