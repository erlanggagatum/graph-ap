{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from preprocessing import data_transformation\n",
    "from similarity import calculate_similarity_matrix\n",
    "\n",
    "from model import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='datasets/', name='MUTAG')\n",
    "torch.manual_seed(1234)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split: Train test validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```train_dataset```: for training model<br/>\n",
    "```val_dataset```: evaluate model for hyperparameter tunning<br/>\n",
    "```test_dataset```: testing model after complete training<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, ts, vl = 0.8, 0.1, 0.1\n",
    "dslen = len(dataset)\n",
    "tri = round(tr*dslen)\n",
    "tsi = round((tr+ts)*dslen)\n",
    "train_dataset = dataset[:tri]\n",
    "test_dataset = dataset[tri:tsi]\n",
    "val_dataset = dataset[tsi:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)\n",
    "test_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)\n",
    "val_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper 128\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base(model, loader, experiment_mode=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(h, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss\n",
    "    #     print(h[0])|\n",
    "    # print(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_base(model, loader, experiment_mode=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        pred = h.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct/len(loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper 128\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "batch1 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering label [0 0 0 0 0 0 1 0 0 1 2 2 2 2 2 1 2]\n",
      "{0: [0, 1, 2, 3, 4, 5, 7, 8], 1: [6, 9, 15], 2: [10, 11, 12, 13, 14, 16]}\n",
      "\n",
      "clustering label [0 1 1 3 0 0 2 2 2 2 2 3 3 1 3 3 3 3 3 2 1 3 3]\n",
      "{0: [0, 4, 5], 1: [1, 2, 13, 20], 3: [3, 11, 12, 14, 15, 16, 17, 18, 21, 22], 2: [6, 7, 8, 9, 10, 19]}\n",
      "\n",
      "clustering label [0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "{0: [0, 1, 2, 3], 1: [4, 5, 6], 2: [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]}\n",
      "\n",
      "clustering label [0 0 0 0 1 1 1 1 1 2 1 1 0 0 3 1 2 2 3 3 2 1 1]\n",
      "{0: [0, 1, 2, 3, 12, 13], 1: [4, 5, 6, 7, 8, 10, 11, 15, 21, 22], 2: [9, 16, 17, 20], 3: [14, 18, 19]}\n",
      "\n",
      "clustering label [0 1 1 1 0 0 0 3 1 1 2 2 2 3 3 2]\n",
      "{0: [0, 4, 5, 6], 1: [1, 2, 3, 8, 9], 3: [7, 13, 14], 2: [10, 11, 12, 15]}\n",
      "\n",
      "clustering label [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1]\n",
      "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 1: [10, 11, 12, 13, 14, 15, 16]}\n",
      "\n",
      "clustering label [0 0 0 0 2 2 1 1 1 1 2 0 0 2 1 1]\n",
      "{0: [0, 1, 2, 3, 11, 12], 2: [4, 5, 10, 13], 1: [6, 7, 8, 9, 14, 15]}\n",
      "\n",
      "clustering label [1 0 0 0 2 2 2 0 1 1 1 1 1 1 1 2 1 1 1 2 2 2 2 0 0]\n",
      "{1: [0, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], 0: [1, 2, 3, 7, 23, 24], 2: [4, 5, 6, 15, 19, 20, 21, 22]}\n",
      "\n",
      "clustering label [0 2 1 1 0 0 0 1 2 2 2]\n",
      "{0: [0, 4, 5, 6], 2: [1, 8, 9, 10], 1: [2, 3, 7]}\n",
      "\n",
      "clustering label [0 1 1 1 0 0 0 2 2 3 3 3 2 2 4 4 4]\n",
      "{0: [0, 4, 5, 6], 1: [1, 2, 3], 2: [7, 8, 12, 13], 3: [9, 10, 11], 4: [14, 15, 16]}\n",
      "\n",
      "batch communities {0: {0: [0, 1, 2, 3, 4, 5, 7, 8], 1: [6, 9, 15], 2: [10, 11, 12, 13, 14, 16]}, 1: {0: [0, 4, 5], 1: [1, 2, 13, 20], 3: [3, 11, 12, 14, 15, 16, 17, 18, 21, 22], 2: [6, 7, 8, 9, 10, 19]}, 2: {0: [0, 1, 2, 3], 1: [4, 5, 6], 2: [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]}, 3: {0: [0, 1, 2, 3, 12, 13], 1: [4, 5, 6, 7, 8, 10, 11, 15, 21, 22], 2: [9, 16, 17, 20], 3: [14, 18, 19]}, 4: {0: [0, 4, 5, 6], 1: [1, 2, 3, 8, 9], 3: [7, 13, 14], 2: [10, 11, 12, 15]}, 5: {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 1: [10, 11, 12, 13, 14, 15, 16]}, 6: {0: [0, 1, 2, 3, 11, 12], 2: [4, 5, 10, 13], 1: [6, 7, 8, 9, 14, 15]}, 7: {1: [0, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], 0: [1, 2, 3, 7, 23, 24], 2: [4, 5, 6, 15, 19, 20, 21, 22]}, 8: {0: [0, 4, 5, 6], 2: [1, 8, 9, 10], 1: [2, 3, 7]}, 9: {0: [0, 4, 5, 6], 1: [1, 2, 3], 2: [7, 8, 12, 13], 3: [9, 10, 11], 4: [14, 15, 16]}}\n",
      "batch loop\n",
      "\n",
      "==== BATCH 0 ====\n",
      "lower bound 0\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "pool subgraph ===  [[-7.13079805e-02 -1.06299196e-01  2.83601729e-02  5.57242841e-02\n",
      "  -5.24456015e-03  3.03573050e-02 -1.00384892e-01  1.16899168e-01\n",
      "  -3.58921189e-02  3.15075531e-02  7.81057272e-02 -5.37340463e-02\n",
      "   4.42506466e-03  1.16599278e-01 -6.20746617e-02  1.73391757e-02\n",
      "   1.21321341e-01  6.42146282e-02  3.56211793e-03 -1.30183586e-01\n",
      "  -3.80475083e-02  8.14759494e-02  7.51192719e-02  1.68375585e-01\n",
      "  -2.49571478e-03  1.14458229e-01  2.42939830e-03 -5.37478190e-02\n",
      "   1.05898074e-01 -2.19778559e-01 -4.78154444e-03 -3.56793813e-02\n",
      "   2.34372258e-02 -1.23886944e-04  1.58505100e-02  3.34608613e-02\n",
      "  -1.49960813e-01  1.71618282e-02 -1.40344288e-01  7.24917182e-02\n",
      "   3.63402329e-02  1.22698031e-01  7.89134665e-02  1.03688332e-01\n",
      "  -1.44760875e-03  5.81526724e-02  1.60458458e-02  1.03602199e-01\n",
      "  -4.90078963e-02  2.20424643e-01 -1.18592205e-01 -5.29263592e-02\n",
      "   6.33594482e-02  1.19433802e-01  6.94065415e-02  5.84633723e-02\n",
      "   7.48535413e-02 -5.42511345e-02 -1.02321480e-02 -9.43313232e-02\n",
      "   2.87959212e-02 -5.17806816e-02 -1.81190204e-03  2.49202600e-01]\n",
      " [-4.85402526e-02 -9.28918049e-02  2.72228196e-02  4.97978690e-02\n",
      "  -2.25850752e-03  2.88634648e-02 -9.00549938e-02  8.48199042e-02\n",
      "  -2.81851093e-02  2.96294911e-02  6.98807215e-02 -4.38755043e-02\n",
      "  -7.61780702e-03  1.09786093e-01 -5.76210953e-02  1.17514016e-02\n",
      "   1.11660175e-01  6.11487639e-02 -7.80464251e-03 -1.11487055e-01\n",
      "  -3.55088568e-02  7.02188450e-02  7.41280926e-02  1.41750423e-01\n",
      "  -8.97261631e-03  9.89804218e-02 -6.05111942e-04 -3.74682502e-02\n",
      "   8.61976959e-02 -1.83969123e-01 -8.50662884e-03 -3.35255607e-02\n",
      "   2.99862130e-02 -1.41035610e-04  1.10526625e-02  2.78144367e-02\n",
      "  -1.28521142e-01  1.00096657e-02 -1.25329964e-01  5.93038388e-02\n",
      "   3.03616331e-02  1.09412156e-01  6.02749524e-02  9.19510623e-02\n",
      "  -2.71523418e-03  5.09750222e-02  1.03682242e-02  9.76006538e-02\n",
      "  -4.77933288e-02  2.03328465e-01 -1.15256622e-01 -5.40691738e-02\n",
      "   6.08675728e-02  1.02639779e-01  6.38437097e-02  5.07867225e-02\n",
      "   7.51198704e-02 -5.10043229e-02 -9.85248387e-03 -8.70159666e-02\n",
      "   2.47114816e-02 -5.51040334e-02 -6.49331355e-03  2.15008557e-01]\n",
      " [-9.19292911e-02 -1.28238744e-01  1.92368459e-02  5.56038273e-02\n",
      "  -3.78333606e-03  2.86538141e-02 -1.11092150e-01  1.38995351e-01\n",
      "  -5.19780076e-02  1.26945685e-02  6.80515530e-02 -6.84368635e-02\n",
      "   2.78981500e-02  1.24537195e-01 -7.45947771e-02  5.61318271e-03\n",
      "   1.25115248e-01  8.48626023e-02  7.05755137e-03 -1.58917097e-01\n",
      "  -5.62396900e-02  8.61549812e-02  7.27533549e-02  1.90794244e-01\n",
      "  -1.45553749e-02  1.27531707e-01  1.34441277e-02 -5.17279973e-02\n",
      "   1.45753286e-01 -2.57147084e-01 -1.87453966e-02 -3.28215544e-02\n",
      "   1.56498097e-02  1.66274714e-03  2.38747165e-02  3.18464953e-02\n",
      "  -1.81019266e-01  2.94147218e-02 -1.40710426e-01  8.22822408e-02\n",
      "   3.59172092e-02  1.32949869e-01  7.90261111e-02  1.46706703e-01\n",
      "  -8.11504146e-03  6.09654415e-02  1.54097361e-02  1.22685896e-01\n",
      "  -5.26603702e-02  2.46034781e-01 -1.23119791e-01 -5.59430153e-02\n",
      "   7.50016533e-02  1.44869523e-01  8.81972387e-02  3.40712317e-02\n",
      "   7.91142086e-02 -7.35116626e-02 -3.85549869e-02 -1.09379385e-01\n",
      "   2.69820923e-02 -3.91388610e-02 -1.89267679e-02  2.99235081e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 1 ====\n",
      "lower bound 17\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 3\n",
      "break new community 2\n",
      "pool subgraph ===  [[-0.12144645 -0.15307883  0.02319898  0.07499442 -0.01164866  0.0328696\n",
      "  -0.13569657  0.1812034  -0.06392801  0.01948284  0.09337158 -0.08753499\n",
      "   0.03858336  0.14447287 -0.08023492  0.01473026  0.15844384  0.08890502\n",
      "   0.0197903  -0.19063146 -0.06305069  0.11163729  0.0820257   0.23767805\n",
      "  -0.00922363  0.1643831   0.01677768 -0.0729273   0.17790319 -0.32092146\n",
      "  -0.01171769 -0.03615575  0.01405685  0.00316906  0.03133016  0.04214125\n",
      "  -0.22115064  0.03666062 -0.17314935  0.10313381  0.04579801  0.16188014\n",
      "   0.1121131   0.16794979 -0.00658807  0.07831855  0.02428093  0.13659222\n",
      "  -0.06019838  0.29590405 -0.13706381 -0.05983061  0.09000779  0.17051143\n",
      "   0.10428912  0.05316568  0.08443372 -0.08009291 -0.0344092  -0.1260954\n",
      "   0.03564219 -0.0427734  -0.01304923  0.36143678]\n",
      " [-0.07478761 -0.11300908  0.02799896  0.06156468 -0.00606807  0.03092885\n",
      "  -0.1076082   0.12144163 -0.03820506  0.03160288  0.08352658 -0.05910543\n",
      "   0.00498984  0.12392363 -0.06498208  0.01751267  0.13180969  0.06691728\n",
      "   0.0031194  -0.13716359 -0.04194513  0.08830398  0.07886571  0.18020546\n",
      "  -0.00499732  0.1260018   0.00253249 -0.05509962  0.11616865 -0.23502565\n",
      "  -0.00616457 -0.03538097  0.02520239  0.00124826  0.01788523  0.03468265\n",
      "  -0.1618245   0.017855   -0.14822338  0.07633639  0.03686114  0.13124739\n",
      "   0.08413655  0.11257778 -0.0018566   0.06380007  0.01584005  0.1104454\n",
      "  -0.0508999   0.23832884 -0.12391591 -0.05614237  0.07006116  0.12492912\n",
      "   0.07612391  0.05804534  0.07785358 -0.05911463 -0.0136253  -0.10018854\n",
      "   0.03121344 -0.05308251 -0.00532575  0.26553788]\n",
      " [-0.10536694 -0.1328112   0.02012744  0.06506518 -0.01010639  0.02851768\n",
      "  -0.11773036  0.15721209 -0.05546397  0.01690331  0.08100919 -0.07594535\n",
      "   0.03347492  0.12534465 -0.06961183  0.01277997  0.13746591  0.07713401\n",
      "   0.01717007 -0.1653919  -0.0547028   0.09685653  0.07116549  0.20620951\n",
      "  -0.00800241  0.14261878  0.01455632 -0.06327173  0.15434883 -0.27843147\n",
      "  -0.01016627 -0.03136872  0.01219572  0.00274949  0.02718206  0.03656176\n",
      "  -0.19187031  0.03180675 -0.1502244   0.08947891  0.03973438  0.14044721\n",
      "   0.09726933  0.14571325 -0.00571579  0.06794921  0.02106612  0.11850742\n",
      "  -0.05222814  0.25672633 -0.11891655 -0.05190907  0.07809076  0.14793572\n",
      "   0.09048125  0.04612653  0.07325468 -0.06948862 -0.02985342 -0.10940039\n",
      "   0.03092318 -0.03711021 -0.01132152  0.3135826 ]\n",
      " [-0.07529056 -0.10820412  0.02954316  0.06004617 -0.00489263  0.03211519\n",
      "  -0.10444152  0.11983059 -0.04245402  0.03422525  0.07667367 -0.05409403\n",
      "   0.00375444  0.11935922 -0.06706411  0.01264718  0.12599914  0.07074341\n",
      "   0.00235131 -0.13331052 -0.03883804  0.08339804  0.07586008  0.17310885\n",
      "  -0.00487573  0.11897427  0.00362211 -0.05227326  0.11776986 -0.23126653\n",
      "  -0.00524959 -0.03436635  0.02080553  0.00201521  0.01928308  0.03543396\n",
      "  -0.15470013  0.02069807 -0.13977725  0.077718    0.03582571  0.12625722\n",
      "   0.08238837  0.11055264 -0.000771    0.06114331  0.01745582  0.10444894\n",
      "  -0.05012827  0.22761292 -0.12044835 -0.05793098  0.065583    0.12184495\n",
      "   0.07550387  0.06051153  0.0762182  -0.05382964 -0.01468671 -0.09843456\n",
      "   0.02985408 -0.04958635 -0.00643891  0.25877117]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 2 ====\n",
      "lower bound 40\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "pool subgraph ===  [[-0.10075533 -0.12699844  0.01924652  0.06221746 -0.00966405  0.02726953\n",
      "  -0.11257765  0.15033141 -0.05303646  0.01616351  0.07746366 -0.07262146\n",
      "   0.03200984  0.1198587  -0.06656512  0.01222065  0.13144942  0.07375807\n",
      "   0.0164186  -0.15815319 -0.05230862  0.09261738  0.06805078  0.19718431\n",
      "  -0.00765217  0.1363768   0.01391925 -0.06050254  0.14759343 -0.26624537\n",
      "  -0.0097213  -0.02999583  0.01166196  0.00262914  0.02599238  0.03496155\n",
      "  -0.18347272  0.03041467 -0.14364952  0.08556269  0.03799532  0.13430026\n",
      "   0.09301216  0.1393358  -0.00546563  0.06497525  0.02014413  0.11332068\n",
      "  -0.04994224  0.24549019 -0.11371194 -0.04963714  0.07467296  0.141461\n",
      "   0.08652115  0.04410772  0.07004854 -0.06644731 -0.02854683 -0.10461225\n",
      "   0.02956976 -0.035486   -0.01082598  0.29985803]\n",
      " [-0.10996245 -0.13860371  0.02100528  0.06790294 -0.01054716  0.02976144\n",
      "  -0.12286508  0.16406882 -0.05788301  0.01764053  0.08454237 -0.07925767\n",
      "   0.03493491  0.1308115  -0.07264791  0.01333737  0.14346142  0.08049819\n",
      "   0.01791895 -0.17260538 -0.05708865  0.10108085  0.07426935  0.21520324\n",
      "  -0.00835145  0.14883903  0.01519118 -0.06603131  0.16108066 -0.29057516\n",
      "  -0.01060967 -0.03273686  0.01272764  0.0028694   0.02836758  0.03815639\n",
      "  -0.20023864  0.033194   -0.15677636  0.09338149  0.04146737  0.14657276\n",
      "   0.10151168  0.15206846 -0.00596511  0.07091275  0.0219849   0.12367606\n",
      "  -0.05450604  0.26792336 -0.12410306 -0.05417303  0.08149665  0.1543879\n",
      "   0.09442758  0.04813834  0.07644965 -0.07251931 -0.03115548 -0.11417184\n",
      "   0.03227186 -0.03872876 -0.01181528  0.32725937]\n",
      " [-0.07930576 -0.11497914  0.02820391  0.06392096 -0.00440765  0.03198102\n",
      "  -0.11031344  0.12593274 -0.04591544  0.03133508  0.07849711 -0.05837317\n",
      "   0.00684081  0.1222322  -0.072336    0.01473127  0.13458309  0.07329399\n",
      "   0.00378241 -0.14147495 -0.04304416  0.09215255  0.07816776  0.18574205\n",
      "  -0.00691601  0.1278495   0.00335859 -0.05676414  0.130799   -0.24673222\n",
      "  -0.00629508 -0.03324921  0.01983656  0.00376363  0.02270384  0.03549595\n",
      "  -0.16816804  0.02065557 -0.1482101   0.08356941  0.03602049  0.13273509\n",
      "   0.08932717  0.11833143  0.00091777  0.0677267   0.01512465  0.11062265\n",
      "  -0.04996543  0.23982674 -0.12265789 -0.06064217  0.06960489  0.12702222\n",
      "   0.08145715  0.05580778  0.07658243 -0.06066876 -0.02072472 -0.10390984\n",
      "   0.03200495 -0.04722512 -0.01022892  0.27432915]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 3 ====\n",
      "lower bound 57\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "break new community 3\n",
      "pool subgraph ===  [[-0.1151654  -0.14516181  0.02199917  0.07111583 -0.01104623  0.03116964\n",
      "  -0.12867854  0.17183181 -0.06062175  0.0184752   0.08854252 -0.08300779\n",
      "   0.03658788  0.13700091 -0.0760853   0.01396841  0.15024938  0.08430698\n",
      "   0.01876676 -0.18077227 -0.05978981  0.10586359  0.07778342  0.22538568\n",
      "  -0.00874659  0.15588142  0.01590996 -0.06915558  0.16870231 -0.30432385\n",
      "  -0.01111165 -0.03428581  0.01332983  0.00300519  0.02970983  0.03996177\n",
      "  -0.20971302  0.03476458 -0.16419431  0.09779988  0.04342941  0.15350791\n",
      "   0.10631476  0.15926366 -0.00624733  0.07426805  0.02302513  0.12952787\n",
      "  -0.05708502  0.28060026 -0.12997504 -0.05673629  0.08535272  0.16169282\n",
      "   0.09889544  0.05041602  0.08006692 -0.07595062 -0.0326296  -0.11957394\n",
      "   0.03379885 -0.04056122 -0.01237436  0.34274382]\n",
      " [-0.07778822 -0.1101656   0.02531034  0.05696518 -0.0071211   0.0298418\n",
      "  -0.102074    0.12297589 -0.04074887  0.02723526  0.0774537  -0.05853335\n",
      "   0.01179387  0.11691902 -0.06078548  0.01334209  0.12286889  0.06572919\n",
      "   0.00580095 -0.13458084 -0.04267946  0.08176781  0.07113184  0.17086788\n",
      "  -0.00462249  0.11830395  0.0069116  -0.05214972  0.11415539 -0.22835467\n",
      "  -0.00677508 -0.03404611  0.0198489   0.00096426  0.01786599  0.03414238\n",
      "  -0.15559481  0.02115796 -0.13677643  0.07321801  0.03632514  0.1239773\n",
      "   0.07991696  0.11232103 -0.0045821   0.05673849  0.01837038  0.10392062\n",
      "  -0.04979619  0.22500526 -0.11555265 -0.05119148  0.06713326  0.12300126\n",
      "   0.07456888  0.05619866  0.0730671  -0.05466188 -0.01357318 -0.09498261\n",
      "   0.02809633 -0.04836388 -0.00386139  0.2586469 ]\n",
      " [-0.07330108 -0.11113535  0.02771501  0.06064675 -0.00592551  0.03052651\n",
      "  -0.10594726  0.11922365 -0.03742257  0.03136441  0.08238368 -0.05803398\n",
      "   0.00451757  0.12215524 -0.06399999  0.01733237  0.12987029  0.06582906\n",
      "   0.00287716 -0.13483019 -0.04117337  0.0869375   0.07786169  0.17729623\n",
      "  -0.00488442  0.12398969  0.00232713 -0.05420696  0.11399105 -0.23109748\n",
      "  -0.00602113 -0.03493841  0.02503034  0.00120946  0.01750174  0.03416683\n",
      "  -0.15911756  0.01740626 -0.14610397  0.075074    0.03630054  0.12926592\n",
      "   0.08276426  0.11052203 -0.00177598  0.06284143  0.01554283  0.10877347\n",
      "  -0.05016305  0.23470687 -0.12223821 -0.05541003  0.06895944  0.12284201\n",
      "   0.07484737  0.05739457  0.07682009 -0.05813427 -0.01320412 -0.0986451\n",
      "   0.03077718 -0.05255894 -0.00516605  0.26111382]\n",
      " [-0.10967193 -0.13823751  0.02094978  0.06772354 -0.01051929  0.02968282\n",
      "  -0.12254047  0.16363535 -0.05773007  0.01759392  0.084319   -0.07904828\n",
      "   0.03484262  0.13046589 -0.07245597  0.01330213  0.14308239  0.08028549\n",
      "   0.0178716  -0.17214936 -0.05693781  0.1008138   0.07407312  0.21463466\n",
      "  -0.00832938  0.1484458   0.01515105 -0.06585685  0.16065508 -0.28980745\n",
      "  -0.01058165 -0.03265037  0.01269401  0.00286181  0.02829263  0.03805558\n",
      "  -0.19970961  0.03310631 -0.15636215  0.09313477  0.04135781  0.14618552\n",
      "   0.10124348  0.15166669 -0.00594935  0.0707254   0.02192682  0.12334931\n",
      "  -0.05436203  0.26721551 -0.12377518 -0.0540299   0.08128133  0.15398\n",
      "   0.09417809  0.04801115  0.07624767 -0.07232771 -0.03107316 -0.11387019\n",
      "   0.03218659 -0.03862644 -0.01178407  0.32639473]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 4 ====\n",
      "lower bound 80\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 3\n",
      "break new community 2\n",
      "pool subgraph ===  [[-0.12438482 -0.15701328  0.02404017  0.07687972 -0.01175792  0.03372444\n",
      "  -0.13930473  0.18583604 -0.06524796  0.0202592   0.09571619 -0.08951058\n",
      "   0.03913868  0.14810083 -0.08287137  0.01563578  0.16248045  0.09121355\n",
      "   0.02036873 -0.19561041 -0.06427548  0.11486074  0.08471132  0.24426067\n",
      "  -0.00930866  0.16854516  0.01676673 -0.07534931  0.1823399  -0.32915823\n",
      "  -0.01176664 -0.03724034  0.01464782  0.00318214  0.03221811  0.04309149\n",
      "  -0.22692735  0.03724798 -0.17846226  0.10622008  0.04703882  0.16613596\n",
      "   0.11527734  0.17171933 -0.00618536  0.08090845  0.02449785  0.14031463\n",
      "  -0.06150161  0.30332376 -0.1409312  -0.06169868  0.09184197  0.17494637\n",
      "   0.10647429  0.05435608  0.08679784 -0.08243522 -0.03535787 -0.12954224\n",
      "   0.03663695 -0.04387803 -0.01334117  0.37069006]\n",
      " [-0.10049404 -0.1283953   0.02510993  0.06410146 -0.00584149  0.02770635\n",
      "  -0.11622579  0.15178942 -0.05035718  0.02192553  0.0806747  -0.06974162\n",
      "   0.02510623  0.12428305 -0.07447936  0.01937426  0.13495674  0.07824099\n",
      "   0.01499963 -0.16317442 -0.04766177  0.09900693  0.07841802  0.20981803\n",
      "  -0.00469301  0.14014824  0.00725963 -0.06866792  0.15207031 -0.27188242\n",
      "  -0.00621327 -0.03167062  0.0159269   0.00193553  0.02619706  0.03378857\n",
      "  -0.18810085  0.02896853 -0.1566172   0.0926298   0.03882148  0.1402467\n",
      "   0.10062988  0.13671249  0.00102889  0.07503837  0.01616561  0.11893223\n",
      "  -0.04893872  0.25112514 -0.12203579 -0.05403236  0.07141987  0.14464347\n",
      "   0.08415918  0.04427918  0.07419874 -0.07269874 -0.02982597 -0.11089427\n",
      "   0.0324088  -0.03545899 -0.01141258  0.30587767]\n",
      " [ 0.01673147 -0.05735883  0.05384787  0.05260854  0.00200893  0.04408671\n",
      "  -0.07926577  0.01542021  0.01006961  0.07931125  0.09880657 -0.01231083\n",
      "  -0.08109073  0.13098587 -0.04456879  0.02374932  0.121068    0.03746669\n",
      "  -0.04379024 -0.05314096 -0.01080317  0.05736688  0.10159289  0.09432504\n",
      "   0.00370522  0.07547514 -0.02683103 -0.02266717 -0.007394   -0.1074111\n",
      "   0.00336733 -0.05370843  0.06624849 -0.00334084 -0.01437637  0.03412847\n",
      "  -0.069828   -0.0211043  -0.13902623  0.03033778  0.03149887  0.10769784\n",
      "   0.03962449  0.01661777 -0.00048888  0.04055386  0.00868681  0.08733459\n",
      "  -0.05619802  0.19512484 -0.14684347 -0.07025939  0.05522929  0.05995286\n",
      "   0.03971251  0.11150763  0.09961836 -0.02081257  0.04627402 -0.07194539\n",
      "   0.03063433 -0.11458098  0.01923028  0.12741166]\n",
      " [ 0.0125781  -0.06869249  0.05519537  0.06287582  0.00449775  0.04561604\n",
      "  -0.09406827  0.02265327  0.00355654  0.08070296  0.10317735 -0.01614215\n",
      "  -0.08235121  0.1404723  -0.05901646  0.02663351  0.14129438  0.04707704\n",
      "  -0.04487244 -0.06738368 -0.01492769  0.074681    0.11000322  0.11898939\n",
      "  -0.00092654  0.09389892 -0.02954288 -0.02939252  0.01889599 -0.13826484\n",
      "   0.0016905  -0.05233919  0.06621434  0.00039105 -0.00727922  0.03563881\n",
      "  -0.09473594 -0.02180136 -0.15760711  0.0441189   0.03178975  0.12294415\n",
      "   0.05357087  0.03050329  0.00443604  0.05545353  0.00340609  0.09979104\n",
      "  -0.05669291  0.22206997 -0.15694206 -0.08048318  0.06250767  0.06970287\n",
      "   0.05277623  0.10795874  0.10446385 -0.03209964  0.03607312 -0.08477094\n",
      "   0.03703782 -0.11332137  0.01086548  0.15673885]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 5 ====\n",
      "lower bound 96\n",
      "len communities on this batch 2\n",
      "break new community 0\n",
      "break new community 1\n",
      "pool subgraph ===  [[-0.07550509 -0.11114542  0.02858121  0.06202522 -0.003232    0.03086986\n",
      "  -0.10736656  0.12174092 -0.04288752  0.03170332  0.07662908 -0.05522591\n",
      "   0.00433458  0.11874461 -0.07189394  0.01707501  0.13097093  0.07128823\n",
      "   0.00361854 -0.13763539 -0.03983065  0.09091013  0.07808286  0.18241116\n",
      "  -0.00564787  0.12414899  0.00106124 -0.05744778  0.12632662 -0.23887524\n",
      "  -0.00514371 -0.03254728  0.02053229  0.00314914  0.02174947  0.03400092\n",
      "  -0.16332606  0.01851756 -0.14722459  0.0823949   0.03503695  0.12933607\n",
      "   0.08804334  0.11275023  0.00300107  0.06807835  0.01314597  0.10844086\n",
      "  -0.04785217  0.23250281 -0.12086091 -0.05984317  0.06605521  0.12334601\n",
      "   0.07723843  0.05375311  0.07490801 -0.06053733 -0.0200212  -0.10174627\n",
      "   0.03192583 -0.04614001 -0.00955927  0.26535044]\n",
      " [-0.10167556 -0.14385847  0.02383134  0.06425218 -0.00507949  0.03167791\n",
      "  -0.11728303  0.15126185 -0.06146695  0.02482437  0.08536332 -0.07630343\n",
      "   0.0374786   0.12645331 -0.06924224  0.00456124  0.14164205  0.08378233\n",
      "   0.00929055 -0.17075499 -0.06466471  0.10328089  0.07210827  0.21050677\n",
      "  -0.01138487  0.13839853  0.0189963  -0.06434798  0.14958418 -0.28301937\n",
      "  -0.01313257 -0.03469539  0.00834006  0.00456098  0.03191014  0.0434901\n",
      "  -0.19737917  0.03196337 -0.14705765  0.08920146  0.04447918  0.14572612\n",
      "   0.10083077  0.14511924  0.00474151  0.06945742  0.0211293   0.11668075\n",
      "  -0.06344213  0.25940158 -0.12489112 -0.05870584  0.07425232  0.14225493\n",
      "   0.08848305  0.05842548  0.08027988 -0.06925461 -0.02356638 -0.11234546\n",
      "   0.03212315 -0.03524784 -0.0066447   0.32114169]]\n",
      "Pool size  (2, 64)\n",
      "\n",
      "==== BATCH 6 ====\n",
      "lower bound 113\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 2\n",
      "break new community 1\n",
      "pool subgraph ===  [[-1.04515166e-01 -1.32703776e-01  2.43086303e-02  6.51459154e-02\n",
      "  -7.63988018e-03  2.90427391e-02 -1.19221819e-01  1.57453783e-01\n",
      "  -5.33612414e-02  2.15222413e-02  8.21865201e-02 -7.27411434e-02\n",
      "   2.80931258e-02  1.26835171e-01 -7.51817090e-02  1.87093917e-02\n",
      "   1.37964984e-01  7.84919038e-02  1.63623152e-02 -1.66376735e-01\n",
      "  -5.07810029e-02  1.00668982e-01  7.77080394e-02  2.13880954e-01\n",
      "  -5.60723714e-03  1.43666382e-01  8.31151878e-03 -6.93119603e-02\n",
      "   1.53964261e-01 -2.79852244e-01 -7.98015056e-03 -3.36578659e-02\n",
      "   1.54297352e-02  1.92342292e-03  2.76204164e-02  3.63443311e-02\n",
      "  -1.93699752e-01  2.97371152e-02 -1.59438024e-01  9.32554491e-02\n",
      "   4.10062000e-02  1.43794672e-01  1.01247426e-01  1.42008285e-01\n",
      "  -5.65965020e-04  7.41322531e-02  1.81867713e-02  1.22504756e-01\n",
      "  -5.17765190e-02  2.58209882e-01 -1.23204667e-01 -5.43300615e-02\n",
      "   7.48580111e-02  1.48382826e-01  8.78432306e-02  4.62325861e-02\n",
      "   7.58706977e-02 -7.28056369e-02 -3.14162672e-02 -1.13304918e-01\n",
      "   3.26019743e-02 -3.84334897e-02 -1.22859411e-02  3.14730674e-01]\n",
      " [-4.59978568e-02 -7.99786473e-02  3.51247977e-02  4.76065197e-02\n",
      "   1.58847218e-03  2.88534959e-02 -8.27477835e-02  8.15013071e-02\n",
      "  -2.27139794e-02  4.18827748e-02  6.92489625e-02 -3.29494580e-02\n",
      "  -1.77636150e-02  1.03004526e-01 -5.81590123e-02  1.95888371e-02\n",
      "   1.02186985e-01  5.66841767e-02 -7.52315057e-03 -9.95450877e-02\n",
      "  -2.16641113e-02  6.77271380e-02  7.65183270e-02  1.38088105e-01\n",
      "   1.56983493e-03  8.95617058e-02 -8.66961762e-03 -4.60695658e-02\n",
      "   7.59853950e-02 -1.69484078e-01  1.17852439e-03 -3.40706641e-02\n",
      "   2.86679802e-02 -7.06167901e-04  9.34023317e-03  2.78211475e-02\n",
      "  -1.13364315e-01  9.20902286e-03 -1.24826029e-01  6.13083749e-02\n",
      "   2.98911305e-02  1.04118711e-01  6.65612202e-02  6.95512010e-02\n",
      "   5.24450171e-03  5.40024855e-02  9.70377773e-03  8.64503682e-02\n",
      "  -4.17663076e-02  1.81536218e-01 -1.10579857e-01 -5.19860008e-02\n",
      "   4.66255297e-02  9.13200217e-02  5.15153718e-02  5.99936660e-02\n",
      "   7.00655282e-02 -4.27015598e-02 -1.43965706e-03 -8.12842709e-02\n",
      "   2.66416113e-02 -5.16593140e-02  1.36013764e-04  1.91887632e-01]\n",
      " [-6.18188358e-02 -9.96962320e-02  4.33070543e-02  5.93072539e-02\n",
      "   7.13326992e-03  2.82599730e-02 -9.96215753e-02  9.76972710e-02\n",
      "  -2.42823949e-02  3.88797759e-02  8.19819663e-02 -4.40070624e-02\n",
      "  -1.62239197e-02  1.24244349e-01 -7.31258374e-02  3.04653565e-02\n",
      "   1.22714363e-01  6.51610773e-02 -3.83665861e-03 -1.24016308e-01\n",
      "  -2.50434488e-02  9.05785197e-02  9.56021566e-02  1.79058952e-01\n",
      "   4.30553163e-03  1.14411181e-01 -1.66959835e-02 -6.02321918e-02\n",
      "   1.03825362e-01 -2.09475512e-01  1.25915403e-03 -4.04569432e-02\n",
      "   3.55843385e-02  1.05356480e-03  1.81488884e-02  2.58068759e-02\n",
      "  -1.50970753e-01  1.44474576e-02 -1.57562524e-01  7.44818933e-02\n",
      "   3.49326390e-02  1.28623147e-01  8.63263616e-02  8.68206182e-02\n",
      "   9.68002569e-03  8.11218908e-02  6.31507457e-03  1.06708577e-01\n",
      "  -4.11092872e-02  2.24855129e-01 -1.23892544e-01 -5.36249485e-02\n",
      "   5.37063172e-02  1.12058356e-01  6.18930506e-02  5.01734675e-02\n",
      "   7.73076043e-02 -6.46907063e-02 -1.29713649e-02 -1.00764437e-01\n",
      "   3.59412073e-02 -5.02700964e-02 -6.08084677e-03  2.38839928e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 7 ====\n",
      "lower bound 129\n",
      "len communities on this batch 3\n",
      "break new community 1\n",
      "break new community 0\n",
      "break new community 2\n",
      "pool subgraph ===  [[-6.26906132e-02 -9.94269997e-02  2.95866234e-02  5.35786301e-02\n",
      "  -5.34319103e-03  3.16889882e-02 -9.55690568e-02  1.05204023e-01\n",
      "  -3.24463611e-02  3.48667656e-02  7.75633144e-02 -4.91755001e-02\n",
      "  -1.89697277e-03  1.15182154e-01 -5.77424721e-02  1.45276375e-02\n",
      "   1.17468754e-01  6.05675330e-02 -1.10716543e-03 -1.19415061e-01\n",
      "  -3.61401389e-02  7.51537463e-02  7.39588216e-02  1.54301321e-01\n",
      "  -2.56228354e-03  1.06566839e-01  1.94590135e-03 -4.72415974e-02\n",
      "   9.21230012e-02 -2.03955242e-01 -4.60802174e-03 -3.70619185e-02\n",
      "   2.55226827e-02 -1.63856545e-04  1.26849202e-02  3.35472592e-02\n",
      "  -1.37719493e-01  1.47239414e-02 -1.33494551e-01  6.56898292e-02\n",
      "   3.54214497e-02  1.17584467e-01  7.16726103e-02  9.41840623e-02\n",
      "  -3.47234922e-03  5.19619013e-02  1.68326075e-02  9.81738220e-02\n",
      "  -4.95711031e-02  2.11875727e-01 -1.17390397e-01 -5.27294464e-02\n",
      "   6.18448866e-02  1.11200924e-01  6.63756188e-02  6.41748495e-02\n",
      "   7.55264896e-02 -4.71987005e-02 -3.74766936e-03 -8.90422538e-02\n",
      "   2.71829860e-02 -5.70701156e-02  7.95049748e-04  2.32170177e-01]\n",
      " [-8.02844693e-02 -1.14929866e-01  2.71980082e-02  6.31175305e-02\n",
      "  -4.82599812e-03  3.12792188e-02 -1.09467278e-01  1.26738546e-01\n",
      "  -4.60123532e-02  2.97993780e-02  7.77186643e-02 -5.90673345e-02\n",
      "   8.90553743e-03  1.20933609e-01 -7.11181858e-02  1.44243578e-02\n",
      "   1.33081144e-01  7.25994977e-02  4.76938351e-03 -1.41473068e-01\n",
      "  -4.34511341e-02  9.13210423e-02  7.66281337e-02  1.84900487e-01\n",
      "  -6.91116157e-03  1.27353672e-01  4.18774521e-03 -5.65386631e-02\n",
      "   1.30820597e-01 -2.45944981e-01 -6.55658964e-03 -3.27598906e-02\n",
      "   1.90470618e-02  3.56778833e-03  2.27227473e-02  3.51061374e-02\n",
      "  -1.67857075e-01  2.12223662e-02 -1.46493516e-01  8.29034177e-02\n",
      "   3.58468130e-02  1.31632208e-01  8.87377513e-02  1.18900292e-01\n",
      "   3.49232377e-04  6.67951669e-02  1.53881640e-02  1.09857616e-01\n",
      "  -4.94586541e-02  2.38045573e-01 -1.20806307e-01 -5.91173741e-02\n",
      "   6.94033304e-02  1.27046886e-01  8.10684812e-02  5.43489856e-02\n",
      "   7.53565986e-02 -6.05728735e-02 -2.11085682e-02 -1.02920756e-01\n",
      "   3.15337532e-02 -4.58293393e-02 -1.00902537e-02  2.73856311e-01]\n",
      " [-4.27185223e-02 -8.31597773e-02  3.56567507e-02  5.48390192e-02\n",
      "   2.90450962e-03  3.02830716e-02 -8.97344593e-02  7.88617050e-02\n",
      "  -2.61110215e-02  4.39001764e-02  7.07519478e-02 -3.32364031e-02\n",
      "  -2.31867824e-02  1.07412186e-01 -6.57240925e-02  2.00026594e-02\n",
      "   1.15010265e-01  6.03395333e-02 -1.07480659e-02 -1.02159216e-01\n",
      "  -2.35392355e-02  7.72999492e-02  8.08624141e-02  1.47405456e-01\n",
      "  -2.13054895e-03  9.92337503e-02 -1.14510410e-02 -4.66458197e-02\n",
      "   8.81691906e-02 -1.82371981e-01  1.45696744e-04 -3.22092131e-02\n",
      "   2.94753099e-02  2.48010355e-03  1.30121817e-02  2.85145543e-02\n",
      "  -1.24088770e-01  6.29209005e-03 -1.33604443e-01  6.72916402e-02\n",
      "   2.82698243e-02  1.11184753e-01  7.24516260e-02  7.40642122e-02\n",
      "   8.68416202e-03  6.28293846e-02  5.78076465e-03  9.19445148e-02\n",
      "  -4.14542458e-02  1.95962586e-01 -1.15265526e-01 -6.02183174e-02\n",
      "   5.16194901e-02  9.19611249e-02  5.87998140e-02  5.82469124e-02\n",
      "   7.26290229e-02 -4.80133751e-02 -6.61096652e-03 -8.69476395e-02\n",
      "   3.05343193e-02 -5.24219705e-02 -6.16931275e-03  2.01308798e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 8 ====\n",
      "lower bound 154\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 2\n",
      "break new community 1\n",
      "pool subgraph ===  [[-6.19284641e-02 -1.22192560e-01  1.69879678e-02  3.36420778e-02\n",
      "   1.00420148e-02  2.92982878e-02 -9.56945587e-02  9.87317264e-02\n",
      "  -4.75789048e-02  2.11327308e-04  3.95534630e-02 -5.35677494e-02\n",
      "   1.71854163e-02  1.20981084e-01 -8.67161117e-02 -8.66032358e-03\n",
      "   9.93128400e-02  1.05160475e-01 -1.57391775e-02 -1.50722183e-01\n",
      "  -6.23876881e-02  6.61912225e-02  7.86208250e-02  1.57404250e-01\n",
      "  -3.09720892e-02  9.26625784e-02  1.26028939e-02 -2.69559552e-02\n",
      "   1.26174968e-01 -2.10598722e-01 -3.76334232e-02 -3.54601010e-02\n",
      "   2.56185783e-02 -3.71895316e-04  1.68233735e-02  2.21241834e-02\n",
      "  -1.57742077e-01  2.44941395e-02 -1.21057257e-01  7.02651143e-02\n",
      "   2.93846577e-02  1.16231291e-01  3.91239957e-02  1.49439352e-01\n",
      "  -1.07318888e-02  4.81366171e-02  2.64945097e-03  1.33659739e-01\n",
      "  -5.67816058e-02  2.21660387e-01 -1.31042162e-01 -6.56326227e-02\n",
      "   6.70678755e-02  1.41348617e-01  8.28227121e-02  6.12793613e-03\n",
      "   9.32772085e-02 -8.46398696e-02 -5.79287168e-02 -1.11887340e-01\n",
      "   1.85799182e-02 -4.15125685e-02 -3.44170472e-02  2.70720836e-01]\n",
      " [-4.43264991e-02 -9.57677091e-02  2.92427571e-02  4.02506155e-02\n",
      "   1.65639116e-02  3.43170576e-02 -9.14153183e-02  7.62747377e-02\n",
      "  -4.20954532e-02  2.34923946e-02  3.33378576e-02 -2.66039030e-02\n",
      "  -1.68891087e-02  1.13238702e-01 -9.03403511e-02 -5.08659087e-03\n",
      "   9.69364395e-02  1.02128965e-01 -2.38408772e-02 -1.21428085e-01\n",
      "  -3.94527024e-02  6.83526335e-02  8.13279152e-02  1.48527876e-01\n",
      "  -1.88303155e-02  8.53166083e-02 -4.53813824e-03 -2.67812616e-02\n",
      "   1.17672066e-01 -1.93430826e-01 -2.60651714e-02 -3.23554439e-02\n",
      "   2.32899425e-02  3.02807622e-03  1.57276397e-02  2.11163145e-02\n",
      "  -1.31340496e-01  1.57633520e-02 -1.18104344e-01  7.61693791e-02\n",
      "   2.37024066e-02  1.10925416e-01  4.15405693e-02  1.14740265e-01\n",
      "   3.47929945e-03  5.91521685e-02 -3.40672106e-03  1.16241095e-01\n",
      "  -4.35051372e-02  2.03072225e-01 -1.32877352e-01 -7.81603456e-02\n",
      "   5.63613524e-02  1.09967716e-01  7.71659066e-02  2.52524116e-02\n",
      "   9.06582177e-02 -7.14685445e-02 -4.78040886e-02 -1.03328896e-01\n",
      "   2.20547312e-02 -4.49545334e-02 -3.34129414e-02  2.31516649e-01]\n",
      " [-7.67477020e-03 -7.40051363e-02  4.79865680e-02  5.76148489e-02\n",
      "   8.42617475e-04  4.04017647e-02 -8.98571517e-02  4.47301688e-02\n",
      "  -2.34629237e-03  6.80851750e-02  9.66360737e-02 -2.54723404e-02\n",
      "  -6.06962112e-02  1.31515237e-01 -5.35543142e-02  2.51236344e-02\n",
      "   1.28366714e-01  4.66009155e-02 -3.15395410e-02 -7.81965144e-02\n",
      "  -1.83285975e-02  7.02821231e-02  9.94961932e-02  1.24994496e-01\n",
      "   1.22742829e-03  9.40987170e-02 -2.18787891e-02 -3.46374335e-02\n",
      "   3.02855473e-02 -1.47385566e-01  1.49474246e-03 -4.84920004e-02\n",
      "   5.72545233e-02 -1.75189519e-03 -4.69765626e-03  3.40296156e-02\n",
      "  -9.93484668e-02 -1.20243244e-02 -1.48148656e-01  4.61673280e-02\n",
      "   3.27665797e-02  1.17834955e-01  5.55621833e-02  4.34975601e-02\n",
      "   2.13373691e-03  5.25366496e-02  8.51930922e-03  9.73187461e-02\n",
      "  -5.41927768e-02  2.13392425e-01 -1.44126369e-01 -6.93283211e-02\n",
      "   5.99678857e-02  7.88068287e-02  5.00341123e-02  9.54733202e-02\n",
      "   9.50510893e-02 -3.50876004e-02  2.75826030e-02 -8.29984918e-02\n",
      "   3.26526728e-02 -9.77411792e-02  1.05124458e-02  1.69863895e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 9 ====\n",
      "lower bound 165\n",
      "len communities on this batch 5\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "break new community 3\n",
      "break new community 4\n",
      "pool subgraph ===  [[-0.1261359  -0.15898978  0.02409477  0.07789019 -0.01209845  0.03413879\n",
      "  -0.14093626  0.18820034 -0.06639651  0.02023513  0.09697699 -0.09091504\n",
      "   0.0400732   0.15005146 -0.08333306  0.01529906  0.16456194  0.09233796\n",
      "   0.02055449 -0.19799244 -0.06548532  0.11594798  0.08519298  0.24685564\n",
      "  -0.00957977  0.17073051  0.01742553 -0.0757433   0.18477266 -0.33331336\n",
      "  -0.01217017 -0.03755184  0.01459965  0.00329142  0.03253992  0.0437685\n",
      "  -0.22969004  0.03807622 -0.17983528  0.10711618  0.04756645  0.16813088\n",
      "   0.11644217  0.17443493 -0.00684245  0.08134271  0.02521848  0.14186654\n",
      "  -0.06252286  0.3073299  -0.14235633 -0.06214087  0.09348328  0.1770955\n",
      "   0.1083161   0.05521859  0.08769398 -0.08318559 -0.03573786 -0.13096439\n",
      "   0.03701846 -0.04442504 -0.01355307  0.37539316]\n",
      " [-0.10975093 -0.13833709  0.02096487  0.06777232 -0.01052687  0.02970419\n",
      "  -0.12262874  0.16375322 -0.05777166  0.01760659  0.08437974 -0.07910522\n",
      "   0.03486771  0.13055988 -0.07250816  0.01331172  0.14318546  0.08034333\n",
      "   0.01788448 -0.17227336 -0.05697883  0.10088642  0.07412648  0.21478928\n",
      "  -0.00833538  0.14855273  0.01516196 -0.06590429  0.16077081 -0.2900162\n",
      "  -0.01058927 -0.03267389  0.01270315  0.00286388  0.02831302  0.038083\n",
      "  -0.19985346  0.03313015 -0.15647479  0.09320186  0.0413876   0.14629081\n",
      "   0.10131642  0.15177595 -0.00595363  0.07077635  0.02194261  0.12343816\n",
      "  -0.05440119  0.26740798 -0.12386434 -0.05406882  0.08133988  0.15409092\n",
      "   0.09424594  0.04804574  0.07630259 -0.07237982 -0.03109554 -0.11395222\n",
      "   0.03220978 -0.03865426 -0.01179256  0.32662986]\n",
      " [-0.11159107 -0.14291423  0.0307489   0.07828758 -0.00674125  0.03614869\n",
      "  -0.13508863  0.16760127 -0.06481661  0.03295352  0.08787789 -0.07497905\n",
      "   0.02082341  0.14352375 -0.08981571  0.01249888  0.15845716  0.09561935\n",
      "   0.01204772 -0.18032233 -0.0527025   0.11030498  0.08823279  0.23255276\n",
      "  -0.00951481  0.15909457  0.00961806 -0.07023132  0.17829797 -0.31400878\n",
      "  -0.00805466 -0.03514872  0.01534737  0.0052512   0.03300455  0.04309272\n",
      "  -0.21034439  0.03428261 -0.17210677  0.10826168  0.04285972  0.15987345\n",
      "   0.11269299  0.15761761  0.00147403  0.08411713  0.02138394  0.13200258\n",
      "  -0.05835935  0.28910229 -0.14155339 -0.07129327  0.08311035  0.1613695\n",
      "   0.10189182  0.05976082  0.08742692 -0.07503392 -0.03531549 -0.12798097\n",
      "   0.03769349 -0.04332062 -0.01766065  0.34722267]\n",
      " [-0.11371014 -0.14362035  0.02212724  0.07034394 -0.01064659  0.03084844\n",
      "  -0.12749071  0.17002169 -0.05956964  0.01868792  0.08760267 -0.08175885\n",
      "   0.03558609  0.13552029 -0.07601812  0.01456336  0.14868013  0.08350403\n",
      "   0.01862942 -0.17901791 -0.05861146  0.10523532  0.07773009  0.22373452\n",
      "  -0.00841537  0.15422268  0.01511712 -0.06918454  0.1668229  -0.3011571\n",
      "  -0.01066908 -0.03410448  0.01351458  0.00286469  0.02946974  0.03940179\n",
      "  -0.2076455   0.03396292 -0.16360731  0.09734539  0.04305461  0.15207191\n",
      "   0.10562506  0.15693899 -0.00543746  0.07426447  0.02228706  0.12849551\n",
      "  -0.05621763  0.2775085  -0.12912152 -0.05655829  0.08387502  0.16008206\n",
      "   0.0972571   0.04970992  0.0794738  -0.07557305 -0.03238395 -0.11864229\n",
      "   0.03360317 -0.04015592 -0.01220089  0.33912319]\n",
      " [ 0.01921719 -0.04608441  0.05133967  0.04138295  0.00072774  0.04295635\n",
      "  -0.06396466  0.01027517  0.00962499  0.07410853  0.08737251 -0.00693527\n",
      "  -0.07545952  0.11655557 -0.03378014  0.01836272  0.10103636  0.03121604\n",
      "  -0.04174924 -0.0406627  -0.00896204  0.04162333  0.08838899  0.06876451\n",
      "   0.00724794  0.05437123 -0.02184574 -0.01629312 -0.02430012 -0.08168901\n",
      "   0.00389417 -0.05352944  0.05969971 -0.00466637 -0.01822495  0.03198125\n",
      "  -0.04876849 -0.01879727 -0.11689367  0.01996843  0.02996212  0.09014297\n",
      "   0.02806509  0.00537428 -0.00443204  0.02520247  0.01260119  0.07262509\n",
      "  -0.05364681  0.16284092 -0.13209875 -0.0615683   0.04704391  0.05043802\n",
      "   0.03076121  0.11144251  0.09154492 -0.01053775  0.05193095 -0.058362\n",
      "   0.02405263 -0.10990805  0.02564213  0.1003903 ]]\n",
      "Pool size  (5, 64)\n",
      "\n",
      "\n",
      "====== ALL SUBGRAPH POOLING RESULT ======\n",
      "[[array([-7.13079805e-02, -1.06299196e-01,  2.83601729e-02,  5.57242841e-02,\n",
      "       -5.24456015e-03,  3.03573050e-02, -1.00384892e-01,  1.16899168e-01,\n",
      "       -3.58921189e-02,  3.15075531e-02,  7.81057272e-02, -5.37340463e-02,\n",
      "        4.42506466e-03,  1.16599278e-01, -6.20746617e-02,  1.73391757e-02,\n",
      "        1.21321341e-01,  6.42146282e-02,  3.56211793e-03, -1.30183586e-01,\n",
      "       -3.80475083e-02,  8.14759494e-02,  7.51192719e-02,  1.68375585e-01,\n",
      "       -2.49571478e-03,  1.14458229e-01,  2.42939830e-03, -5.37478190e-02,\n",
      "        1.05898074e-01, -2.19778559e-01, -4.78154444e-03, -3.56793813e-02,\n",
      "        2.34372258e-02, -1.23886944e-04,  1.58505100e-02,  3.34608613e-02,\n",
      "       -1.49960813e-01,  1.71618282e-02, -1.40344288e-01,  7.24917182e-02,\n",
      "        3.63402329e-02,  1.22698031e-01,  7.89134665e-02,  1.03688332e-01,\n",
      "       -1.44760875e-03,  5.81526724e-02,  1.60458458e-02,  1.03602199e-01,\n",
      "       -4.90078963e-02,  2.20424643e-01, -1.18592205e-01, -5.29263592e-02,\n",
      "        6.33594482e-02,  1.19433802e-01,  6.94065415e-02,  5.84633723e-02,\n",
      "        7.48535413e-02, -5.42511345e-02, -1.02321480e-02, -9.43313232e-02,\n",
      "        2.87959212e-02, -5.17806816e-02, -1.81190204e-03,  2.49202600e-01]), array([-4.85402526e-02, -9.28918049e-02,  2.72228196e-02,  4.97978690e-02,\n",
      "       -2.25850752e-03,  2.88634648e-02, -9.00549938e-02,  8.48199042e-02,\n",
      "       -2.81851093e-02,  2.96294911e-02,  6.98807215e-02, -4.38755043e-02,\n",
      "       -7.61780702e-03,  1.09786093e-01, -5.76210953e-02,  1.17514016e-02,\n",
      "        1.11660175e-01,  6.11487639e-02, -7.80464251e-03, -1.11487055e-01,\n",
      "       -3.55088568e-02,  7.02188450e-02,  7.41280926e-02,  1.41750423e-01,\n",
      "       -8.97261631e-03,  9.89804218e-02, -6.05111942e-04, -3.74682502e-02,\n",
      "        8.61976959e-02, -1.83969123e-01, -8.50662884e-03, -3.35255607e-02,\n",
      "        2.99862130e-02, -1.41035610e-04,  1.10526625e-02,  2.78144367e-02,\n",
      "       -1.28521142e-01,  1.00096657e-02, -1.25329964e-01,  5.93038388e-02,\n",
      "        3.03616331e-02,  1.09412156e-01,  6.02749524e-02,  9.19510623e-02,\n",
      "       -2.71523418e-03,  5.09750222e-02,  1.03682242e-02,  9.76006538e-02,\n",
      "       -4.77933288e-02,  2.03328465e-01, -1.15256622e-01, -5.40691738e-02,\n",
      "        6.08675728e-02,  1.02639779e-01,  6.38437097e-02,  5.07867225e-02,\n",
      "        7.51198704e-02, -5.10043229e-02, -9.85248387e-03, -8.70159666e-02,\n",
      "        2.47114816e-02, -5.51040334e-02, -6.49331355e-03,  2.15008557e-01]), array([-0.09192929, -0.12823874,  0.01923685,  0.05560383, -0.00378334,\n",
      "        0.02865381, -0.11109215,  0.13899535, -0.05197801,  0.01269457,\n",
      "        0.06805155, -0.06843686,  0.02789815,  0.12453719, -0.07459478,\n",
      "        0.00561318,  0.12511525,  0.0848626 ,  0.00705755, -0.1589171 ,\n",
      "       -0.05623969,  0.08615498,  0.07275335,  0.19079424, -0.01455537,\n",
      "        0.12753171,  0.01344413, -0.051728  ,  0.14575329, -0.25714708,\n",
      "       -0.0187454 , -0.03282155,  0.01564981,  0.00166275,  0.02387472,\n",
      "        0.0318465 , -0.18101927,  0.02941472, -0.14071043,  0.08228224,\n",
      "        0.03591721,  0.13294987,  0.07902611,  0.1467067 , -0.00811504,\n",
      "        0.06096544,  0.01540974,  0.1226859 , -0.05266037,  0.24603478,\n",
      "       -0.12311979, -0.05594302,  0.07500165,  0.14486952,  0.08819724,\n",
      "        0.03407123,  0.07911421, -0.07351166, -0.03855499, -0.10937938,\n",
      "        0.02698209, -0.03913886, -0.01892677,  0.29923508])], [array([-0.12144645, -0.15307883,  0.02319898,  0.07499442, -0.01164866,\n",
      "        0.0328696 , -0.13569657,  0.1812034 , -0.06392801,  0.01948284,\n",
      "        0.09337158, -0.08753499,  0.03858336,  0.14447287, -0.08023492,\n",
      "        0.01473026,  0.15844384,  0.08890502,  0.0197903 , -0.19063146,\n",
      "       -0.06305069,  0.11163729,  0.0820257 ,  0.23767805, -0.00922363,\n",
      "        0.1643831 ,  0.01677768, -0.0729273 ,  0.17790319, -0.32092146,\n",
      "       -0.01171769, -0.03615575,  0.01405685,  0.00316906,  0.03133016,\n",
      "        0.04214125, -0.22115064,  0.03666062, -0.17314935,  0.10313381,\n",
      "        0.04579801,  0.16188014,  0.1121131 ,  0.16794979, -0.00658807,\n",
      "        0.07831855,  0.02428093,  0.13659222, -0.06019838,  0.29590405,\n",
      "       -0.13706381, -0.05983061,  0.09000779,  0.17051143,  0.10428912,\n",
      "        0.05316568,  0.08443372, -0.08009291, -0.0344092 , -0.1260954 ,\n",
      "        0.03564219, -0.0427734 , -0.01304923,  0.36143678]), array([-0.07478761, -0.11300908,  0.02799896,  0.06156468, -0.00606807,\n",
      "        0.03092885, -0.1076082 ,  0.12144163, -0.03820506,  0.03160288,\n",
      "        0.08352658, -0.05910543,  0.00498984,  0.12392363, -0.06498208,\n",
      "        0.01751267,  0.13180969,  0.06691728,  0.0031194 , -0.13716359,\n",
      "       -0.04194513,  0.08830398,  0.07886571,  0.18020546, -0.00499732,\n",
      "        0.1260018 ,  0.00253249, -0.05509962,  0.11616865, -0.23502565,\n",
      "       -0.00616457, -0.03538097,  0.02520239,  0.00124826,  0.01788523,\n",
      "        0.03468265, -0.1618245 ,  0.017855  , -0.14822338,  0.07633639,\n",
      "        0.03686114,  0.13124739,  0.08413655,  0.11257778, -0.0018566 ,\n",
      "        0.06380007,  0.01584005,  0.1104454 , -0.0508999 ,  0.23832884,\n",
      "       -0.12391591, -0.05614237,  0.07006116,  0.12492912,  0.07612391,\n",
      "        0.05804534,  0.07785358, -0.05911463, -0.0136253 , -0.10018854,\n",
      "        0.03121344, -0.05308251, -0.00532575,  0.26553788]), array([-0.10536694, -0.1328112 ,  0.02012744,  0.06506518, -0.01010639,\n",
      "        0.02851768, -0.11773036,  0.15721209, -0.05546397,  0.01690331,\n",
      "        0.08100919, -0.07594535,  0.03347492,  0.12534465, -0.06961183,\n",
      "        0.01277997,  0.13746591,  0.07713401,  0.01717007, -0.1653919 ,\n",
      "       -0.0547028 ,  0.09685653,  0.07116549,  0.20620951, -0.00800241,\n",
      "        0.14261878,  0.01455632, -0.06327173,  0.15434883, -0.27843147,\n",
      "       -0.01016627, -0.03136872,  0.01219572,  0.00274949,  0.02718206,\n",
      "        0.03656176, -0.19187031,  0.03180675, -0.1502244 ,  0.08947891,\n",
      "        0.03973438,  0.14044721,  0.09726933,  0.14571325, -0.00571579,\n",
      "        0.06794921,  0.02106612,  0.11850742, -0.05222814,  0.25672633,\n",
      "       -0.11891655, -0.05190907,  0.07809076,  0.14793572,  0.09048125,\n",
      "        0.04612653,  0.07325468, -0.06948862, -0.02985342, -0.10940039,\n",
      "        0.03092318, -0.03711021, -0.01132152,  0.3135826 ]), array([-0.07529056, -0.10820412,  0.02954316,  0.06004617, -0.00489263,\n",
      "        0.03211519, -0.10444152,  0.11983059, -0.04245402,  0.03422525,\n",
      "        0.07667367, -0.05409403,  0.00375444,  0.11935922, -0.06706411,\n",
      "        0.01264718,  0.12599914,  0.07074341,  0.00235131, -0.13331052,\n",
      "       -0.03883804,  0.08339804,  0.07586008,  0.17310885, -0.00487573,\n",
      "        0.11897427,  0.00362211, -0.05227326,  0.11776986, -0.23126653,\n",
      "       -0.00524959, -0.03436635,  0.02080553,  0.00201521,  0.01928308,\n",
      "        0.03543396, -0.15470013,  0.02069807, -0.13977725,  0.077718  ,\n",
      "        0.03582571,  0.12625722,  0.08238837,  0.11055264, -0.000771  ,\n",
      "        0.06114331,  0.01745582,  0.10444894, -0.05012827,  0.22761292,\n",
      "       -0.12044835, -0.05793098,  0.065583  ,  0.12184495,  0.07550387,\n",
      "        0.06051153,  0.0762182 , -0.05382964, -0.01468671, -0.09843456,\n",
      "        0.02985408, -0.04958635, -0.00643891,  0.25877117])], [array([-0.10075533, -0.12699844,  0.01924652,  0.06221746, -0.00966405,\n",
      "        0.02726953, -0.11257765,  0.15033141, -0.05303646,  0.01616351,\n",
      "        0.07746366, -0.07262146,  0.03200984,  0.1198587 , -0.06656512,\n",
      "        0.01222065,  0.13144942,  0.07375807,  0.0164186 , -0.15815319,\n",
      "       -0.05230862,  0.09261738,  0.06805078,  0.19718431, -0.00765217,\n",
      "        0.1363768 ,  0.01391925, -0.06050254,  0.14759343, -0.26624537,\n",
      "       -0.0097213 , -0.02999583,  0.01166196,  0.00262914,  0.02599238,\n",
      "        0.03496155, -0.18347272,  0.03041467, -0.14364952,  0.08556269,\n",
      "        0.03799532,  0.13430026,  0.09301216,  0.1393358 , -0.00546563,\n",
      "        0.06497525,  0.02014413,  0.11332068, -0.04994224,  0.24549019,\n",
      "       -0.11371194, -0.04963714,  0.07467296,  0.141461  ,  0.08652115,\n",
      "        0.04410772,  0.07004854, -0.06644731, -0.02854683, -0.10461225,\n",
      "        0.02956976, -0.035486  , -0.01082598,  0.29985803]), array([-0.10996245, -0.13860371,  0.02100528,  0.06790294, -0.01054716,\n",
      "        0.02976144, -0.12286508,  0.16406882, -0.05788301,  0.01764053,\n",
      "        0.08454237, -0.07925767,  0.03493491,  0.1308115 , -0.07264791,\n",
      "        0.01333737,  0.14346142,  0.08049819,  0.01791895, -0.17260538,\n",
      "       -0.05708865,  0.10108085,  0.07426935,  0.21520324, -0.00835145,\n",
      "        0.14883903,  0.01519118, -0.06603131,  0.16108066, -0.29057516,\n",
      "       -0.01060967, -0.03273686,  0.01272764,  0.0028694 ,  0.02836758,\n",
      "        0.03815639, -0.20023864,  0.033194  , -0.15677636,  0.09338149,\n",
      "        0.04146737,  0.14657276,  0.10151168,  0.15206846, -0.00596511,\n",
      "        0.07091275,  0.0219849 ,  0.12367606, -0.05450604,  0.26792336,\n",
      "       -0.12410306, -0.05417303,  0.08149665,  0.1543879 ,  0.09442758,\n",
      "        0.04813834,  0.07644965, -0.07251931, -0.03115548, -0.11417184,\n",
      "        0.03227186, -0.03872876, -0.01181528,  0.32725937]), array([-0.07930576, -0.11497914,  0.02820391,  0.06392096, -0.00440765,\n",
      "        0.03198102, -0.11031344,  0.12593274, -0.04591544,  0.03133508,\n",
      "        0.07849711, -0.05837317,  0.00684081,  0.1222322 , -0.072336  ,\n",
      "        0.01473127,  0.13458309,  0.07329399,  0.00378241, -0.14147495,\n",
      "       -0.04304416,  0.09215255,  0.07816776,  0.18574205, -0.00691601,\n",
      "        0.1278495 ,  0.00335859, -0.05676414,  0.130799  , -0.24673222,\n",
      "       -0.00629508, -0.03324921,  0.01983656,  0.00376363,  0.02270384,\n",
      "        0.03549595, -0.16816804,  0.02065557, -0.1482101 ,  0.08356941,\n",
      "        0.03602049,  0.13273509,  0.08932717,  0.11833143,  0.00091777,\n",
      "        0.0677267 ,  0.01512465,  0.11062265, -0.04996543,  0.23982674,\n",
      "       -0.12265789, -0.06064217,  0.06960489,  0.12702222,  0.08145715,\n",
      "        0.05580778,  0.07658243, -0.06066876, -0.02072472, -0.10390984,\n",
      "        0.03200495, -0.04722512, -0.01022892,  0.27432915])], [array([-0.1151654 , -0.14516181,  0.02199917,  0.07111583, -0.01104623,\n",
      "        0.03116964, -0.12867854,  0.17183181, -0.06062175,  0.0184752 ,\n",
      "        0.08854252, -0.08300779,  0.03658788,  0.13700091, -0.0760853 ,\n",
      "        0.01396841,  0.15024938,  0.08430698,  0.01876676, -0.18077227,\n",
      "       -0.05978981,  0.10586359,  0.07778342,  0.22538568, -0.00874659,\n",
      "        0.15588142,  0.01590996, -0.06915558,  0.16870231, -0.30432385,\n",
      "       -0.01111165, -0.03428581,  0.01332983,  0.00300519,  0.02970983,\n",
      "        0.03996177, -0.20971302,  0.03476458, -0.16419431,  0.09779988,\n",
      "        0.04342941,  0.15350791,  0.10631476,  0.15926366, -0.00624733,\n",
      "        0.07426805,  0.02302513,  0.12952787, -0.05708502,  0.28060026,\n",
      "       -0.12997504, -0.05673629,  0.08535272,  0.16169282,  0.09889544,\n",
      "        0.05041602,  0.08006692, -0.07595062, -0.0326296 , -0.11957394,\n",
      "        0.03379885, -0.04056122, -0.01237436,  0.34274382]), array([-0.07778822, -0.1101656 ,  0.02531034,  0.05696518, -0.0071211 ,\n",
      "        0.0298418 , -0.102074  ,  0.12297589, -0.04074887,  0.02723526,\n",
      "        0.0774537 , -0.05853335,  0.01179387,  0.11691902, -0.06078548,\n",
      "        0.01334209,  0.12286889,  0.06572919,  0.00580095, -0.13458084,\n",
      "       -0.04267946,  0.08176781,  0.07113184,  0.17086788, -0.00462249,\n",
      "        0.11830395,  0.0069116 , -0.05214972,  0.11415539, -0.22835467,\n",
      "       -0.00677508, -0.03404611,  0.0198489 ,  0.00096426,  0.01786599,\n",
      "        0.03414238, -0.15559481,  0.02115796, -0.13677643,  0.07321801,\n",
      "        0.03632514,  0.1239773 ,  0.07991696,  0.11232103, -0.0045821 ,\n",
      "        0.05673849,  0.01837038,  0.10392062, -0.04979619,  0.22500526,\n",
      "       -0.11555265, -0.05119148,  0.06713326,  0.12300126,  0.07456888,\n",
      "        0.05619866,  0.0730671 , -0.05466188, -0.01357318, -0.09498261,\n",
      "        0.02809633, -0.04836388, -0.00386139,  0.2586469 ]), array([-0.07330108, -0.11113535,  0.02771501,  0.06064675, -0.00592551,\n",
      "        0.03052651, -0.10594726,  0.11922365, -0.03742257,  0.03136441,\n",
      "        0.08238368, -0.05803398,  0.00451757,  0.12215524, -0.06399999,\n",
      "        0.01733237,  0.12987029,  0.06582906,  0.00287716, -0.13483019,\n",
      "       -0.04117337,  0.0869375 ,  0.07786169,  0.17729623, -0.00488442,\n",
      "        0.12398969,  0.00232713, -0.05420696,  0.11399105, -0.23109748,\n",
      "       -0.00602113, -0.03493841,  0.02503034,  0.00120946,  0.01750174,\n",
      "        0.03416683, -0.15911756,  0.01740626, -0.14610397,  0.075074  ,\n",
      "        0.03630054,  0.12926592,  0.08276426,  0.11052203, -0.00177598,\n",
      "        0.06284143,  0.01554283,  0.10877347, -0.05016305,  0.23470687,\n",
      "       -0.12223821, -0.05541003,  0.06895944,  0.12284201,  0.07484737,\n",
      "        0.05739457,  0.07682009, -0.05813427, -0.01320412, -0.0986451 ,\n",
      "        0.03077718, -0.05255894, -0.00516605,  0.26111382]), array([-0.10967193, -0.13823751,  0.02094978,  0.06772354, -0.01051929,\n",
      "        0.02968282, -0.12254047,  0.16363535, -0.05773007,  0.01759392,\n",
      "        0.084319  , -0.07904828,  0.03484262,  0.13046589, -0.07245597,\n",
      "        0.01330213,  0.14308239,  0.08028549,  0.0178716 , -0.17214936,\n",
      "       -0.05693781,  0.1008138 ,  0.07407312,  0.21463466, -0.00832938,\n",
      "        0.1484458 ,  0.01515105, -0.06585685,  0.16065508, -0.28980745,\n",
      "       -0.01058165, -0.03265037,  0.01269401,  0.00286181,  0.02829263,\n",
      "        0.03805558, -0.19970961,  0.03310631, -0.15636215,  0.09313477,\n",
      "        0.04135781,  0.14618552,  0.10124348,  0.15166669, -0.00594935,\n",
      "        0.0707254 ,  0.02192682,  0.12334931, -0.05436203,  0.26721551,\n",
      "       -0.12377518, -0.0540299 ,  0.08128133,  0.15398   ,  0.09417809,\n",
      "        0.04801115,  0.07624767, -0.07232771, -0.03107316, -0.11387019,\n",
      "        0.03218659, -0.03862644, -0.01178407,  0.32639473])], [array([-0.12438482, -0.15701328,  0.02404017,  0.07687972, -0.01175792,\n",
      "        0.03372444, -0.13930473,  0.18583604, -0.06524796,  0.0202592 ,\n",
      "        0.09571619, -0.08951058,  0.03913868,  0.14810083, -0.08287137,\n",
      "        0.01563578,  0.16248045,  0.09121355,  0.02036873, -0.19561041,\n",
      "       -0.06427548,  0.11486074,  0.08471132,  0.24426067, -0.00930866,\n",
      "        0.16854516,  0.01676673, -0.07534931,  0.1823399 , -0.32915823,\n",
      "       -0.01176664, -0.03724034,  0.01464782,  0.00318214,  0.03221811,\n",
      "        0.04309149, -0.22692735,  0.03724798, -0.17846226,  0.10622008,\n",
      "        0.04703882,  0.16613596,  0.11527734,  0.17171933, -0.00618536,\n",
      "        0.08090845,  0.02449785,  0.14031463, -0.06150161,  0.30332376,\n",
      "       -0.1409312 , -0.06169868,  0.09184197,  0.17494637,  0.10647429,\n",
      "        0.05435608,  0.08679784, -0.08243522, -0.03535787, -0.12954224,\n",
      "        0.03663695, -0.04387803, -0.01334117,  0.37069006]), array([-0.10049404, -0.1283953 ,  0.02510993,  0.06410146, -0.00584149,\n",
      "        0.02770635, -0.11622579,  0.15178942, -0.05035718,  0.02192553,\n",
      "        0.0806747 , -0.06974162,  0.02510623,  0.12428305, -0.07447936,\n",
      "        0.01937426,  0.13495674,  0.07824099,  0.01499963, -0.16317442,\n",
      "       -0.04766177,  0.09900693,  0.07841802,  0.20981803, -0.00469301,\n",
      "        0.14014824,  0.00725963, -0.06866792,  0.15207031, -0.27188242,\n",
      "       -0.00621327, -0.03167062,  0.0159269 ,  0.00193553,  0.02619706,\n",
      "        0.03378857, -0.18810085,  0.02896853, -0.1566172 ,  0.0926298 ,\n",
      "        0.03882148,  0.1402467 ,  0.10062988,  0.13671249,  0.00102889,\n",
      "        0.07503837,  0.01616561,  0.11893223, -0.04893872,  0.25112514,\n",
      "       -0.12203579, -0.05403236,  0.07141987,  0.14464347,  0.08415918,\n",
      "        0.04427918,  0.07419874, -0.07269874, -0.02982597, -0.11089427,\n",
      "        0.0324088 , -0.03545899, -0.01141258,  0.30587767]), array([ 0.01673147, -0.05735883,  0.05384787,  0.05260854,  0.00200893,\n",
      "        0.04408671, -0.07926577,  0.01542021,  0.01006961,  0.07931125,\n",
      "        0.09880657, -0.01231083, -0.08109073,  0.13098587, -0.04456879,\n",
      "        0.02374932,  0.121068  ,  0.03746669, -0.04379024, -0.05314096,\n",
      "       -0.01080317,  0.05736688,  0.10159289,  0.09432504,  0.00370522,\n",
      "        0.07547514, -0.02683103, -0.02266717, -0.007394  , -0.1074111 ,\n",
      "        0.00336733, -0.05370843,  0.06624849, -0.00334084, -0.01437637,\n",
      "        0.03412847, -0.069828  , -0.0211043 , -0.13902623,  0.03033778,\n",
      "        0.03149887,  0.10769784,  0.03962449,  0.01661777, -0.00048888,\n",
      "        0.04055386,  0.00868681,  0.08733459, -0.05619802,  0.19512484,\n",
      "       -0.14684347, -0.07025939,  0.05522929,  0.05995286,  0.03971251,\n",
      "        0.11150763,  0.09961836, -0.02081257,  0.04627402, -0.07194539,\n",
      "        0.03063433, -0.11458098,  0.01923028,  0.12741166]), array([ 0.0125781 , -0.06869249,  0.05519537,  0.06287582,  0.00449775,\n",
      "        0.04561604, -0.09406827,  0.02265327,  0.00355654,  0.08070296,\n",
      "        0.10317735, -0.01614215, -0.08235121,  0.1404723 , -0.05901646,\n",
      "        0.02663351,  0.14129438,  0.04707704, -0.04487244, -0.06738368,\n",
      "       -0.01492769,  0.074681  ,  0.11000322,  0.11898939, -0.00092654,\n",
      "        0.09389892, -0.02954288, -0.02939252,  0.01889599, -0.13826484,\n",
      "        0.0016905 , -0.05233919,  0.06621434,  0.00039105, -0.00727922,\n",
      "        0.03563881, -0.09473594, -0.02180136, -0.15760711,  0.0441189 ,\n",
      "        0.03178975,  0.12294415,  0.05357087,  0.03050329,  0.00443604,\n",
      "        0.05545353,  0.00340609,  0.09979104, -0.05669291,  0.22206997,\n",
      "       -0.15694206, -0.08048318,  0.06250767,  0.06970287,  0.05277623,\n",
      "        0.10795874,  0.10446385, -0.03209964,  0.03607312, -0.08477094,\n",
      "        0.03703782, -0.11332137,  0.01086548,  0.15673885])], [array([-0.07550509, -0.11114542,  0.02858121,  0.06202522, -0.003232  ,\n",
      "        0.03086986, -0.10736656,  0.12174092, -0.04288752,  0.03170332,\n",
      "        0.07662908, -0.05522591,  0.00433458,  0.11874461, -0.07189394,\n",
      "        0.01707501,  0.13097093,  0.07128823,  0.00361854, -0.13763539,\n",
      "       -0.03983065,  0.09091013,  0.07808286,  0.18241116, -0.00564787,\n",
      "        0.12414899,  0.00106124, -0.05744778,  0.12632662, -0.23887524,\n",
      "       -0.00514371, -0.03254728,  0.02053229,  0.00314914,  0.02174947,\n",
      "        0.03400092, -0.16332606,  0.01851756, -0.14722459,  0.0823949 ,\n",
      "        0.03503695,  0.12933607,  0.08804334,  0.11275023,  0.00300107,\n",
      "        0.06807835,  0.01314597,  0.10844086, -0.04785217,  0.23250281,\n",
      "       -0.12086091, -0.05984317,  0.06605521,  0.12334601,  0.07723843,\n",
      "        0.05375311,  0.07490801, -0.06053733, -0.0200212 , -0.10174627,\n",
      "        0.03192583, -0.04614001, -0.00955927,  0.26535044]), array([-0.10167556, -0.14385847,  0.02383134,  0.06425218, -0.00507949,\n",
      "        0.03167791, -0.11728303,  0.15126185, -0.06146695,  0.02482437,\n",
      "        0.08536332, -0.07630343,  0.0374786 ,  0.12645331, -0.06924224,\n",
      "        0.00456124,  0.14164205,  0.08378233,  0.00929055, -0.17075499,\n",
      "       -0.06466471,  0.10328089,  0.07210827,  0.21050677, -0.01138487,\n",
      "        0.13839853,  0.0189963 , -0.06434798,  0.14958418, -0.28301937,\n",
      "       -0.01313257, -0.03469539,  0.00834006,  0.00456098,  0.03191014,\n",
      "        0.0434901 , -0.19737917,  0.03196337, -0.14705765,  0.08920146,\n",
      "        0.04447918,  0.14572612,  0.10083077,  0.14511924,  0.00474151,\n",
      "        0.06945742,  0.0211293 ,  0.11668075, -0.06344213,  0.25940158,\n",
      "       -0.12489112, -0.05870584,  0.07425232,  0.14225493,  0.08848305,\n",
      "        0.05842548,  0.08027988, -0.06925461, -0.02356638, -0.11234546,\n",
      "        0.03212315, -0.03524784, -0.0066447 ,  0.32114169])], [array([-0.10451517, -0.13270378,  0.02430863,  0.06514592, -0.00763988,\n",
      "        0.02904274, -0.11922182,  0.15745378, -0.05336124,  0.02152224,\n",
      "        0.08218652, -0.07274114,  0.02809313,  0.12683517, -0.07518171,\n",
      "        0.01870939,  0.13796498,  0.0784919 ,  0.01636232, -0.16637673,\n",
      "       -0.050781  ,  0.10066898,  0.07770804,  0.21388095, -0.00560724,\n",
      "        0.14366638,  0.00831152, -0.06931196,  0.15396426, -0.27985224,\n",
      "       -0.00798015, -0.03365787,  0.01542974,  0.00192342,  0.02762042,\n",
      "        0.03634433, -0.19369975,  0.02973712, -0.15943802,  0.09325545,\n",
      "        0.0410062 ,  0.14379467,  0.10124743,  0.14200828, -0.00056597,\n",
      "        0.07413225,  0.01818677,  0.12250476, -0.05177652,  0.25820988,\n",
      "       -0.12320467, -0.05433006,  0.07485801,  0.14838283,  0.08784323,\n",
      "        0.04623259,  0.0758707 , -0.07280564, -0.03141627, -0.11330492,\n",
      "        0.03260197, -0.03843349, -0.01228594,  0.31473067]), array([-4.59978568e-02, -7.99786473e-02,  3.51247977e-02,  4.76065197e-02,\n",
      "        1.58847218e-03,  2.88534959e-02, -8.27477835e-02,  8.15013071e-02,\n",
      "       -2.27139794e-02,  4.18827748e-02,  6.92489625e-02, -3.29494580e-02,\n",
      "       -1.77636150e-02,  1.03004526e-01, -5.81590123e-02,  1.95888371e-02,\n",
      "        1.02186985e-01,  5.66841767e-02, -7.52315057e-03, -9.95450877e-02,\n",
      "       -2.16641113e-02,  6.77271380e-02,  7.65183270e-02,  1.38088105e-01,\n",
      "        1.56983493e-03,  8.95617058e-02, -8.66961762e-03, -4.60695658e-02,\n",
      "        7.59853950e-02, -1.69484078e-01,  1.17852439e-03, -3.40706641e-02,\n",
      "        2.86679802e-02, -7.06167901e-04,  9.34023317e-03,  2.78211475e-02,\n",
      "       -1.13364315e-01,  9.20902286e-03, -1.24826029e-01,  6.13083749e-02,\n",
      "        2.98911305e-02,  1.04118711e-01,  6.65612202e-02,  6.95512010e-02,\n",
      "        5.24450171e-03,  5.40024855e-02,  9.70377773e-03,  8.64503682e-02,\n",
      "       -4.17663076e-02,  1.81536218e-01, -1.10579857e-01, -5.19860008e-02,\n",
      "        4.66255297e-02,  9.13200217e-02,  5.15153718e-02,  5.99936660e-02,\n",
      "        7.00655282e-02, -4.27015598e-02, -1.43965706e-03, -8.12842709e-02,\n",
      "        2.66416113e-02, -5.16593140e-02,  1.36013764e-04,  1.91887632e-01]), array([-0.06181884, -0.09969623,  0.04330705,  0.05930725,  0.00713327,\n",
      "        0.02825997, -0.09962158,  0.09769727, -0.02428239,  0.03887978,\n",
      "        0.08198197, -0.04400706, -0.01622392,  0.12424435, -0.07312584,\n",
      "        0.03046536,  0.12271436,  0.06516108, -0.00383666, -0.12401631,\n",
      "       -0.02504345,  0.09057852,  0.09560216,  0.17905895,  0.00430553,\n",
      "        0.11441118, -0.01669598, -0.06023219,  0.10382536, -0.20947551,\n",
      "        0.00125915, -0.04045694,  0.03558434,  0.00105356,  0.01814889,\n",
      "        0.02580688, -0.15097075,  0.01444746, -0.15756252,  0.07448189,\n",
      "        0.03493264,  0.12862315,  0.08632636,  0.08682062,  0.00968003,\n",
      "        0.08112189,  0.00631507,  0.10670858, -0.04110929,  0.22485513,\n",
      "       -0.12389254, -0.05362495,  0.05370632,  0.11205836,  0.06189305,\n",
      "        0.05017347,  0.0773076 , -0.06469071, -0.01297136, -0.10076444,\n",
      "        0.03594121, -0.0502701 , -0.00608085,  0.23883993])], [array([-6.26906132e-02, -9.94269997e-02,  2.95866234e-02,  5.35786301e-02,\n",
      "       -5.34319103e-03,  3.16889882e-02, -9.55690568e-02,  1.05204023e-01,\n",
      "       -3.24463611e-02,  3.48667656e-02,  7.75633144e-02, -4.91755001e-02,\n",
      "       -1.89697277e-03,  1.15182154e-01, -5.77424721e-02,  1.45276375e-02,\n",
      "        1.17468754e-01,  6.05675330e-02, -1.10716543e-03, -1.19415061e-01,\n",
      "       -3.61401389e-02,  7.51537463e-02,  7.39588216e-02,  1.54301321e-01,\n",
      "       -2.56228354e-03,  1.06566839e-01,  1.94590135e-03, -4.72415974e-02,\n",
      "        9.21230012e-02, -2.03955242e-01, -4.60802174e-03, -3.70619185e-02,\n",
      "        2.55226827e-02, -1.63856545e-04,  1.26849202e-02,  3.35472592e-02,\n",
      "       -1.37719493e-01,  1.47239414e-02, -1.33494551e-01,  6.56898292e-02,\n",
      "        3.54214497e-02,  1.17584467e-01,  7.16726103e-02,  9.41840623e-02,\n",
      "       -3.47234922e-03,  5.19619013e-02,  1.68326075e-02,  9.81738220e-02,\n",
      "       -4.95711031e-02,  2.11875727e-01, -1.17390397e-01, -5.27294464e-02,\n",
      "        6.18448866e-02,  1.11200924e-01,  6.63756188e-02,  6.41748495e-02,\n",
      "        7.55264896e-02, -4.71987005e-02, -3.74766936e-03, -8.90422538e-02,\n",
      "        2.71829860e-02, -5.70701156e-02,  7.95049748e-04,  2.32170177e-01]), array([-0.08028447, -0.11492987,  0.02719801,  0.06311753, -0.004826  ,\n",
      "        0.03127922, -0.10946728,  0.12673855, -0.04601235,  0.02979938,\n",
      "        0.07771866, -0.05906733,  0.00890554,  0.12093361, -0.07111819,\n",
      "        0.01442436,  0.13308114,  0.0725995 ,  0.00476938, -0.14147307,\n",
      "       -0.04345113,  0.09132104,  0.07662813,  0.18490049, -0.00691116,\n",
      "        0.12735367,  0.00418775, -0.05653866,  0.1308206 , -0.24594498,\n",
      "       -0.00655659, -0.03275989,  0.01904706,  0.00356779,  0.02272275,\n",
      "        0.03510614, -0.16785708,  0.02122237, -0.14649352,  0.08290342,\n",
      "        0.03584681,  0.13163221,  0.08873775,  0.11890029,  0.00034923,\n",
      "        0.06679517,  0.01538816,  0.10985762, -0.04945865,  0.23804557,\n",
      "       -0.12080631, -0.05911737,  0.06940333,  0.12704689,  0.08106848,\n",
      "        0.05434899,  0.0753566 , -0.06057287, -0.02110857, -0.10292076,\n",
      "        0.03153375, -0.04582934, -0.01009025,  0.27385631]), array([-4.27185223e-02, -8.31597773e-02,  3.56567507e-02,  5.48390192e-02,\n",
      "        2.90450962e-03,  3.02830716e-02, -8.97344593e-02,  7.88617050e-02,\n",
      "       -2.61110215e-02,  4.39001764e-02,  7.07519478e-02, -3.32364031e-02,\n",
      "       -2.31867824e-02,  1.07412186e-01, -6.57240925e-02,  2.00026594e-02,\n",
      "        1.15010265e-01,  6.03395333e-02, -1.07480659e-02, -1.02159216e-01,\n",
      "       -2.35392355e-02,  7.72999492e-02,  8.08624141e-02,  1.47405456e-01,\n",
      "       -2.13054895e-03,  9.92337503e-02, -1.14510410e-02, -4.66458197e-02,\n",
      "        8.81691906e-02, -1.82371981e-01,  1.45696744e-04, -3.22092131e-02,\n",
      "        2.94753099e-02,  2.48010355e-03,  1.30121817e-02,  2.85145543e-02,\n",
      "       -1.24088770e-01,  6.29209005e-03, -1.33604443e-01,  6.72916402e-02,\n",
      "        2.82698243e-02,  1.11184753e-01,  7.24516260e-02,  7.40642122e-02,\n",
      "        8.68416202e-03,  6.28293846e-02,  5.78076465e-03,  9.19445148e-02,\n",
      "       -4.14542458e-02,  1.95962586e-01, -1.15265526e-01, -6.02183174e-02,\n",
      "        5.16194901e-02,  9.19611249e-02,  5.87998140e-02,  5.82469124e-02,\n",
      "        7.26290229e-02, -4.80133751e-02, -6.61096652e-03, -8.69476395e-02,\n",
      "        3.05343193e-02, -5.24219705e-02, -6.16931275e-03,  2.01308798e-01])], [array([-6.19284641e-02, -1.22192560e-01,  1.69879678e-02,  3.36420778e-02,\n",
      "        1.00420148e-02,  2.92982878e-02, -9.56945587e-02,  9.87317264e-02,\n",
      "       -4.75789048e-02,  2.11327308e-04,  3.95534630e-02, -5.35677494e-02,\n",
      "        1.71854163e-02,  1.20981084e-01, -8.67161117e-02, -8.66032358e-03,\n",
      "        9.93128400e-02,  1.05160475e-01, -1.57391775e-02, -1.50722183e-01,\n",
      "       -6.23876881e-02,  6.61912225e-02,  7.86208250e-02,  1.57404250e-01,\n",
      "       -3.09720892e-02,  9.26625784e-02,  1.26028939e-02, -2.69559552e-02,\n",
      "        1.26174968e-01, -2.10598722e-01, -3.76334232e-02, -3.54601010e-02,\n",
      "        2.56185783e-02, -3.71895316e-04,  1.68233735e-02,  2.21241834e-02,\n",
      "       -1.57742077e-01,  2.44941395e-02, -1.21057257e-01,  7.02651143e-02,\n",
      "        2.93846577e-02,  1.16231291e-01,  3.91239957e-02,  1.49439352e-01,\n",
      "       -1.07318888e-02,  4.81366171e-02,  2.64945097e-03,  1.33659739e-01,\n",
      "       -5.67816058e-02,  2.21660387e-01, -1.31042162e-01, -6.56326227e-02,\n",
      "        6.70678755e-02,  1.41348617e-01,  8.28227121e-02,  6.12793613e-03,\n",
      "        9.32772085e-02, -8.46398696e-02, -5.79287168e-02, -1.11887340e-01,\n",
      "        1.85799182e-02, -4.15125685e-02, -3.44170472e-02,  2.70720836e-01]), array([-0.0443265 , -0.09576771,  0.02924276,  0.04025062,  0.01656391,\n",
      "        0.03431706, -0.09141532,  0.07627474, -0.04209545,  0.02349239,\n",
      "        0.03333786, -0.0266039 , -0.01688911,  0.1132387 , -0.09034035,\n",
      "       -0.00508659,  0.09693644,  0.10212897, -0.02384088, -0.12142808,\n",
      "       -0.0394527 ,  0.06835263,  0.08132792,  0.14852788, -0.01883032,\n",
      "        0.08531661, -0.00453814, -0.02678126,  0.11767207, -0.19343083,\n",
      "       -0.02606517, -0.03235544,  0.02328994,  0.00302808,  0.01572764,\n",
      "        0.02111631, -0.1313405 ,  0.01576335, -0.11810434,  0.07616938,\n",
      "        0.02370241,  0.11092542,  0.04154057,  0.11474026,  0.0034793 ,\n",
      "        0.05915217, -0.00340672,  0.11624109, -0.04350514,  0.20307223,\n",
      "       -0.13287735, -0.07816035,  0.05636135,  0.10996772,  0.07716591,\n",
      "        0.02525241,  0.09065822, -0.07146854, -0.04780409, -0.1033289 ,\n",
      "        0.02205473, -0.04495453, -0.03341294,  0.23151665]), array([-0.00767477, -0.07400514,  0.04798657,  0.05761485,  0.00084262,\n",
      "        0.04040176, -0.08985715,  0.04473017, -0.00234629,  0.06808518,\n",
      "        0.09663607, -0.02547234, -0.06069621,  0.13151524, -0.05355431,\n",
      "        0.02512363,  0.12836671,  0.04660092, -0.03153954, -0.07819651,\n",
      "       -0.0183286 ,  0.07028212,  0.09949619,  0.1249945 ,  0.00122743,\n",
      "        0.09409872, -0.02187879, -0.03463743,  0.03028555, -0.14738557,\n",
      "        0.00149474, -0.048492  ,  0.05725452, -0.0017519 , -0.00469766,\n",
      "        0.03402962, -0.09934847, -0.01202432, -0.14814866,  0.04616733,\n",
      "        0.03276658,  0.11783496,  0.05556218,  0.04349756,  0.00213374,\n",
      "        0.05253665,  0.00851931,  0.09731875, -0.05419278,  0.21339243,\n",
      "       -0.14412637, -0.06932832,  0.05996789,  0.07880683,  0.05003411,\n",
      "        0.09547332,  0.09505109, -0.0350876 ,  0.0275826 , -0.08299849,\n",
      "        0.03265267, -0.09774118,  0.01051245,  0.16986389])], [array([-0.1261359 , -0.15898978,  0.02409477,  0.07789019, -0.01209845,\n",
      "        0.03413879, -0.14093626,  0.18820034, -0.06639651,  0.02023513,\n",
      "        0.09697699, -0.09091504,  0.0400732 ,  0.15005146, -0.08333306,\n",
      "        0.01529906,  0.16456194,  0.09233796,  0.02055449, -0.19799244,\n",
      "       -0.06548532,  0.11594798,  0.08519298,  0.24685564, -0.00957977,\n",
      "        0.17073051,  0.01742553, -0.0757433 ,  0.18477266, -0.33331336,\n",
      "       -0.01217017, -0.03755184,  0.01459965,  0.00329142,  0.03253992,\n",
      "        0.0437685 , -0.22969004,  0.03807622, -0.17983528,  0.10711618,\n",
      "        0.04756645,  0.16813088,  0.11644217,  0.17443493, -0.00684245,\n",
      "        0.08134271,  0.02521848,  0.14186654, -0.06252286,  0.3073299 ,\n",
      "       -0.14235633, -0.06214087,  0.09348328,  0.1770955 ,  0.1083161 ,\n",
      "        0.05521859,  0.08769398, -0.08318559, -0.03573786, -0.13096439,\n",
      "        0.03701846, -0.04442504, -0.01355307,  0.37539316]), array([-0.10975093, -0.13833709,  0.02096487,  0.06777232, -0.01052687,\n",
      "        0.02970419, -0.12262874,  0.16375322, -0.05777166,  0.01760659,\n",
      "        0.08437974, -0.07910522,  0.03486771,  0.13055988, -0.07250816,\n",
      "        0.01331172,  0.14318546,  0.08034333,  0.01788448, -0.17227336,\n",
      "       -0.05697883,  0.10088642,  0.07412648,  0.21478928, -0.00833538,\n",
      "        0.14855273,  0.01516196, -0.06590429,  0.16077081, -0.2900162 ,\n",
      "       -0.01058927, -0.03267389,  0.01270315,  0.00286388,  0.02831302,\n",
      "        0.038083  , -0.19985346,  0.03313015, -0.15647479,  0.09320186,\n",
      "        0.0413876 ,  0.14629081,  0.10131642,  0.15177595, -0.00595363,\n",
      "        0.07077635,  0.02194261,  0.12343816, -0.05440119,  0.26740798,\n",
      "       -0.12386434, -0.05406882,  0.08133988,  0.15409092,  0.09424594,\n",
      "        0.04804574,  0.07630259, -0.07237982, -0.03109554, -0.11395222,\n",
      "        0.03220978, -0.03865426, -0.01179256,  0.32662986]), array([-0.11159107, -0.14291423,  0.0307489 ,  0.07828758, -0.00674125,\n",
      "        0.03614869, -0.13508863,  0.16760127, -0.06481661,  0.03295352,\n",
      "        0.08787789, -0.07497905,  0.02082341,  0.14352375, -0.08981571,\n",
      "        0.01249888,  0.15845716,  0.09561935,  0.01204772, -0.18032233,\n",
      "       -0.0527025 ,  0.11030498,  0.08823279,  0.23255276, -0.00951481,\n",
      "        0.15909457,  0.00961806, -0.07023132,  0.17829797, -0.31400878,\n",
      "       -0.00805466, -0.03514872,  0.01534737,  0.0052512 ,  0.03300455,\n",
      "        0.04309272, -0.21034439,  0.03428261, -0.17210677,  0.10826168,\n",
      "        0.04285972,  0.15987345,  0.11269299,  0.15761761,  0.00147403,\n",
      "        0.08411713,  0.02138394,  0.13200258, -0.05835935,  0.28910229,\n",
      "       -0.14155339, -0.07129327,  0.08311035,  0.1613695 ,  0.10189182,\n",
      "        0.05976082,  0.08742692, -0.07503392, -0.03531549, -0.12798097,\n",
      "        0.03769349, -0.04332062, -0.01766065,  0.34722267]), array([-0.11371014, -0.14362035,  0.02212724,  0.07034394, -0.01064659,\n",
      "        0.03084844, -0.12749071,  0.17002169, -0.05956964,  0.01868792,\n",
      "        0.08760267, -0.08175885,  0.03558609,  0.13552029, -0.07601812,\n",
      "        0.01456336,  0.14868013,  0.08350403,  0.01862942, -0.17901791,\n",
      "       -0.05861146,  0.10523532,  0.07773009,  0.22373452, -0.00841537,\n",
      "        0.15422268,  0.01511712, -0.06918454,  0.1668229 , -0.3011571 ,\n",
      "       -0.01066908, -0.03410448,  0.01351458,  0.00286469,  0.02946974,\n",
      "        0.03940179, -0.2076455 ,  0.03396292, -0.16360731,  0.09734539,\n",
      "        0.04305461,  0.15207191,  0.10562506,  0.15693899, -0.00543746,\n",
      "        0.07426447,  0.02228706,  0.12849551, -0.05621763,  0.2775085 ,\n",
      "       -0.12912152, -0.05655829,  0.08387502,  0.16008206,  0.0972571 ,\n",
      "        0.04970992,  0.0794738 , -0.07557305, -0.03238395, -0.11864229,\n",
      "        0.03360317, -0.04015592, -0.01220089,  0.33912319]), array([ 0.01921719, -0.04608441,  0.05133967,  0.04138295,  0.00072774,\n",
      "        0.04295635, -0.06396466,  0.01027517,  0.00962499,  0.07410853,\n",
      "        0.08737251, -0.00693527, -0.07545952,  0.11655557, -0.03378014,\n",
      "        0.01836272,  0.10103636,  0.03121604, -0.04174924, -0.0406627 ,\n",
      "       -0.00896204,  0.04162333,  0.08838899,  0.06876451,  0.00724794,\n",
      "        0.05437123, -0.02184574, -0.01629312, -0.02430012, -0.08168901,\n",
      "        0.00389417, -0.05352944,  0.05969971, -0.00466637, -0.01822495,\n",
      "        0.03198125, -0.04876849, -0.01879727, -0.11689367,  0.01996843,\n",
      "        0.02996212,  0.09014297,  0.02806509,  0.00537428, -0.00443204,\n",
      "        0.02520247,  0.01260119,  0.07262509, -0.05364681,  0.16284092,\n",
      "       -0.13209875, -0.0615683 ,  0.04704391,  0.05043802,  0.03076121,\n",
      "        0.11144251,  0.09154492, -0.01053775,  0.05193095, -0.058362  ,\n",
      "        0.02405263, -0.10990805,  0.02564213,  0.1003903 ])]]\n",
      "attention score tensor([-0.0142, -0.0167, -0.0200], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.3343, 0.3334, 0.3323], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0164, -0.0151, -0.0176, -0.0154], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.2499, 0.2503, 0.2496, 0.2502], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0201, -0.0191, -0.0183], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.3330, 0.3334, 0.3336], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0184, -0.0179, -0.0173, -0.0190], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.2499, 0.2501, 0.2502, 0.2498], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0162, -0.0165, -0.0051, -0.0060], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.2487, 0.2486, 0.2515, 0.2512], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0170, -0.0168], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.4999, 0.5001], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0080, -0.0057, -0.0104], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.3333, 0.3341, 0.3325], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0017, -0.0041, -0.0027], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.3337, 0.3329, 0.3334], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0024, -0.0017,  0.0004], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.3330, 0.3332, 0.3339], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "attention score tensor([-0.0159, -0.0171, -0.0160, -0.0166, -0.0066],\n",
      "       grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.1997, 0.1995, 0.1997, 0.1996, 0.2016], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n",
      "shape subgraph embedding  torch.Size([10, 64])\n",
      "shape topk_subgraph_embedding  torch.Size([10, 1, 64])\n",
      "shape topk_subgraph_embedding transformed torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from similarity import calculate_similarity_matrix, testt\n",
    "\n",
    "\n",
    "# AP Clustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Experiment(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels, k = 1):\n",
    "        super(Experiment, self).__init__()\n",
    "        \n",
    "        # save number of subgraphs, default 1\n",
    "        self.k_subgraph = k\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # embeddings for subgraph\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # attention layer\n",
    "        self.query_layer = Linear(hidden_channels,hidden_channels)\n",
    "        self.key_layer = Linear(hidden_channels,hidden_channels)\n",
    "        self.value_layer = Linear(hidden_channels,hidden_channels)\n",
    "        \n",
    "        # classification layer\n",
    "        self.lin = Linear(hidden_channels*2, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, ptr):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        # embedding = embedding.relu()\n",
    "        # embedding = self.conv3(embedding, edge_index)\n",
    "        # embedding = embedding.relu()\n",
    "        \n",
    "        # generate subgraph based on embeddings\n",
    "        feature_emb = embedding.detach()\n",
    "        \n",
    "        subgraph_edge_index, communities, S, batch_communities = self.subgraph_generator(feature_emb, edge_index, batch, ptr)\n",
    "        subgraph_embedding = self.conv4(embedding, subgraph_edge_index)\n",
    "        subgraph_embedding = subgraph_embedding.relu()\n",
    "        subgraph_embedding = self.conv5(subgraph_embedding, subgraph_edge_index)\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        # apply readout layer/pooling for each subgraphs\n",
    "        subgraph_pool_embedding = self.subgraph_pooling(subgraph_embedding, communities, batch, ptr, batch_communities)\n",
    "        \n",
    "        # apply selective (top k) attention\n",
    "        topk_subgraph_embedding = self.selectk_subgraph(embedding, subgraph_pool_embedding, self.k_subgraph)\n",
    "        \n",
    "        # print('get topk subgraph embedding', topk_subgraph_embedding)\n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        \n",
    "        \n",
    "        subgraph_embedding = global_max_pool(subgraph_embedding, batch)\n",
    "        \n",
    "        print('shape subgraph embedding ', subgraph_embedding.shape)\n",
    "        print('shape topk_subgraph_embedding ', topk_subgraph_embedding.shape)\n",
    "        print('shape topk_subgraph_embedding transformed', topk_subgraph_embedding.view(len(embedding), -1).shape)\n",
    "        \n",
    "        # print('pre transform (original subgraph_embedding)', subgraph_embedding)\n",
    "        # print('pre transform topk subgraph embedding', topk_subgraph_embedding.view(2, -1))\n",
    "        # h = torch.cat((embedding, topk_subgraph_embedding.view(2, -1)), 1)\n",
    "        # h = torch.cat((embedding, subgraph_embedding), 1)\n",
    "        combined_embeddings = torch.cat((embedding, topk_subgraph_embedding.view(len(embedding), -1)), 1)\n",
    "        \n",
    "        \n",
    "        h = F.dropout(combined_embeddings, p=0.3, training=self.training)\n",
    "        h = self.lin(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.3, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h, S, communities, topk_subgraph_embedding.view(len(embedding), -1)\n",
    "    \n",
    "    def selectk_subgraph(self, embs, sub_embs, k = 1):\n",
    "        # calculate attention and select top k subgraph\n",
    "        \n",
    "        topk_subgraphs_all = []\n",
    "\n",
    "        for i, (emb, sub_emb) in enumerate(zip(embs, sub_embs)):\n",
    "            sub = torch.tensor(sub_emb)\n",
    "            sub = sub.to(torch.float32)\n",
    "\n",
    "            # transform\n",
    "            query = self.query_layer(emb)\n",
    "            key = self.key_layer(sub)\n",
    "            value = self.value_layer(sub)\n",
    "\n",
    "            # att score\n",
    "            attention_score = torch.matmul(query, key.transpose(0,1))\n",
    "            attention_weight = F.softmax(attention_score, dim=0)\n",
    "\n",
    "            print(f'attention score {attention_score}')\n",
    "            print(f'attention weight {attention_weight}')\n",
    "\n",
    "            print('select top k')\n",
    "            topk_subgraph_embeddings = None\n",
    "            \n",
    "            if (k <= len(sub)):\n",
    "                topk_scores, topk_indices = torch.topk(attention_weight, k)\n",
    "                topk_subgraph_embeddings = sub[topk_indices]\n",
    "            else:\n",
    "                print('too big')\n",
    "                \n",
    "            topk_subgraphs_all.append(topk_subgraph_embeddings)\n",
    "        \n",
    "        return torch.stack(topk_subgraphs_all)\n",
    "    \n",
    "    def subgraph_generator(self, embeddings, batch_edge_index, batch, ptr):\n",
    "        '''\n",
    "        Return subgraph_edge_index (edge_index of created subgraph)\n",
    "        '''\n",
    "        graph_counter = 0\n",
    "        edge_index = [[],[]]\n",
    "        subgraph_edge_index = [[],[]]\n",
    "        # Gs = []\n",
    "        sub_created = False\n",
    "        graph_bound = {}\n",
    "        all_communities = []\n",
    "        batch_communities = {}\n",
    "        S = []\n",
    "\n",
    "        for i in range(len(ptr)-1):\n",
    "            graph_bound[i] = [ptr[i].item(), ptr[i+1].item()]\n",
    "        \n",
    "        for i, (src, dst) in enumerate(zip(batch_edge_index[0], batch_edge_index[1])):\n",
    "            lower_bound = graph_bound[graph_counter][0]\n",
    "            upper_bound = graph_bound[graph_counter][1]\n",
    "            if ((src >= lower_bound and src < upper_bound) or\n",
    "                (dst >= lower_bound and dst < upper_bound)):\n",
    "                \n",
    "                edge_index[0].append(src - lower_bound)\n",
    "                edge_index[1].append(dst - lower_bound)\n",
    "            else:\n",
    "                sub_created = True\n",
    "                \n",
    "            if (i == len(batch_edge_index[0]) - 1) or sub_created:\n",
    "                sub_created = False\n",
    "                \n",
    "                embs = []\n",
    "                # make new graph\n",
    "                for i, (b, emb) in enumerate(zip(batch, embeddings)):\n",
    "                    if (b == graph_counter):\n",
    "                        embs.append(emb)\n",
    "                \n",
    "                G = data_transformation(edge_index, embs)\n",
    "                # dont need this at the moment\n",
    "                # Gs.append(G)\n",
    "                \n",
    "                # Calculate similarity matrix\n",
    "                S = calculate_similarity_matrix(G)\n",
    "                \n",
    "                # AP Clustering        \n",
    "                clustering = AffinityPropagation(affinity='precomputed', damping=0.8, random_state=42, convergence_iter=15, max_iter=1000)\n",
    "                clustering.fit(S)\n",
    "                \n",
    "                print('clustering label', clustering.labels_)\n",
    "                \n",
    "                # Get community\n",
    "                communities = {}\n",
    "                for lab in clustering.labels_:\n",
    "                    communities[lab] = []\n",
    "                    all_communities.append(lab)\n",
    "                for nd, clust in enumerate(clustering.labels_):\n",
    "                    communities[clust].append(nd)\n",
    "                print(communities)\n",
    "                \n",
    "                edge_index = [[],[]]\n",
    "                batch_communities[graph_counter] = communities\n",
    "                \n",
    "                graph_counter+=1\n",
    "                \n",
    "                # Make subgraph edge_index\n",
    "                for c in communities:\n",
    "                    w = G.subgraph(communities[c])\n",
    "                    for sub in w.edges:\n",
    "                        subgraph_edge_index[0].append(sub[0] + lower_bound)\n",
    "                        subgraph_edge_index[1].append(sub[1] + lower_bound)\n",
    "                \n",
    "                print()\n",
    "                # break # sementara aja\n",
    "        \n",
    "        # print('batch communities', batch_communities)\n",
    "        return torch.tensor(subgraph_edge_index), all_communities, S, batch_communities\n",
    "    \n",
    "        \n",
    "    def subgraph_pooling(self, embeddings, communities, batch, ptr, batch_communities):\n",
    "        # batch communities: batch (or graph in this batch) -> communities -> member\n",
    "        pool_type = 'mean'\n",
    "        curr_batch = 0\n",
    "        emb_temp = None\n",
    "        emb_pool = []\n",
    "        all_emb_pool = []\n",
    "        print('batch communities', batch_communities)\n",
    "        \n",
    "        print('batch loop')\n",
    "        print('')\n",
    "        \n",
    "        # LOOP THROUGH BATCH\n",
    "        for b in batch_communities:\n",
    "            print(f'==== BATCH {b} ====')\n",
    "            print('lower bound', ptr[b].item())\n",
    "            print('len communities on this batch', len(batch_communities[b]))\n",
    "            \n",
    "            # initialize array\n",
    "            emb_temp = [[] for _ in range(len(batch_communities[b]))]\n",
    "            emb_pool = [[] for _ in range(len(batch_communities[b]))]\n",
    "            for comm in batch_communities[b]:\n",
    "                for member in batch_communities[b][comm]:\n",
    "                    # emb_temp[comm].append(member + ptr[b].item())\n",
    "                    index_used = member + ptr[b].item()\n",
    "                    emb_temp[comm].append(embeddings[index_used].detach().tolist())\n",
    "                    # print('embtemp-log', emb_temp)\n",
    "                    # print(comm, \"-\",member)\n",
    "                print('break new community', comm)\n",
    "\n",
    "                # Pooling per sub graph                \n",
    "                if pool_type == 'mean': # mean pool\n",
    "                    emb_pool[comm] = np.array(emb_temp[comm]).mean(axis=0)\n",
    "                elif pool_type == 'add': # add pool\n",
    "                    emb_pool[comm] = np.array(emb_temp[comm]).sum(axis=0)\n",
    "                else:\n",
    "                    print('TODO: fill later')\n",
    "                \n",
    "            print(\"pool subgraph === \", np.array(emb_pool))\n",
    "            print(\"Pool size \", np.array(emb_pool).shape)\n",
    "            print()\n",
    "            all_emb_pool.append(emb_pool.copy())\n",
    "        \n",
    "        print('')\n",
    "        print('====== ALL SUBGRAPH POOLING RESULT ======')\n",
    "        print(all_emb_pool)\n",
    "        \n",
    "        return all_emb_pool\n",
    "\n",
    "experiment = Experiment(dataset, 64)\n",
    "emb, h, S, communities, sub_emb = experiment(batch1.x, batch1.edge_index, batch1.batch, batch1.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1253, -0.0275],\n",
       "        [ 0.1351, -0.0011],\n",
       "        [ 0.1076, -0.0756],\n",
       "        [ 0.1343, -0.0447],\n",
       "        [ 0.1359, -0.0559],\n",
       "        [ 0.1900, -0.0916],\n",
       "        [ 0.1417, -0.0782],\n",
       "        [ 0.1174, -0.0663],\n",
       "        [ 0.1419, -0.0372],\n",
       "        [ 0.1469, -0.0010]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention score tensor([0.0384, 0.0401, 0.0506], grad_fn=<SqueezeBackward4>)\n",
      "attention weight tensor([0.3318, 0.3324, 0.3359], grad_fn=<SoftmaxBackward0>)\n",
      "select top k\n"
     ]
    }
   ],
   "source": [
    "def selectk_subgraph():\n",
    "    query_layer = Linear(64,64)\n",
    "    key_layer = Linear(64,64)\n",
    "    value_layer = Linear(64,64)\n",
    "    sub = torch.tensor(sub_emb[0])\n",
    "    sub = sub.to(torch.float32)\n",
    "\n",
    "    # transform\n",
    "    query = query_layer(emb[0])\n",
    "    key = key_layer(sub)\n",
    "    value = value_layer(sub)\n",
    "\n",
    "    # att score\n",
    "    attention_score = torch.matmul(query, key.transpose(0,1))\n",
    "    attention_weight = F.softmax(attention_score, dim=0)\n",
    "\n",
    "    print(f'attention score {attention_score}')\n",
    "    print(f'attention weight {attention_weight}')\n",
    "\n",
    "    print('select top k')\n",
    "    topk_subgraph_embeddings = None\n",
    "    k = 2\n",
    "    if (k < len(sub)):\n",
    "        topk_scores, topk_indices = torch.topk(attention_weight, k)\n",
    "        topk_subgraph_embeddings = sub[topk_indices]\n",
    "    else:\n",
    "        print('too big')\n",
    "    return topk_subgraph_embeddings\n",
    "    print(topk_subgraph_embeddings)\n",
    "tk = selectk_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0899, -0.1282,  0.0192,  0.0541, -0.0026,  0.0289, -0.1105,\n",
      "           0.1363, -0.0516,  0.0120,  0.0660, -0.0674,  0.0270,  0.1252,\n",
      "          -0.0760,  0.0043,  0.1235,  0.0869,  0.0051, -0.1587, -0.0569,\n",
      "           0.0846,  0.0735,  0.1890, -0.0159,  0.1254,  0.0133, -0.0498,\n",
      "           0.1450, -0.2546, -0.0205, -0.0333,  0.0164,  0.0015,  0.0234,\n",
      "           0.0311, -0.1800,  0.0291, -0.1397,  0.0814,  0.0354,  0.1323,\n",
      "           0.0760,  0.1478, -0.0086,  0.0600,  0.0144,  0.1243, -0.0531,\n",
      "           0.2455, -0.1247, -0.0571,  0.0749,  0.1452,  0.0883,  0.0319,\n",
      "           0.0807, -0.0748, -0.0405, -0.1101,  0.0264, -0.0398, -0.0205,\n",
      "           0.2983],\n",
      "         [-0.0753, -0.1144,  0.0271,  0.0615, -0.0065,  0.0311, -0.1082,\n",
      "           0.1212, -0.0399,  0.0299,  0.0830, -0.0601,  0.0067,  0.1248,\n",
      "          -0.0647,  0.0151,  0.1325,  0.0685,  0.0026, -0.1387, -0.0442,\n",
      "           0.0874,  0.0781,  0.1792, -0.0068,  0.1261,  0.0045, -0.0527,\n",
      "           0.1178, -0.2363, -0.0077, -0.0352,  0.0249,  0.0014,  0.0180,\n",
      "           0.0346, -0.1630,  0.0188, -0.1462,  0.0756,  0.0366,  0.1313,\n",
      "           0.0826,  0.1163, -0.0037,  0.0621,  0.0164,  0.1111, -0.0522,\n",
      "           0.2405, -0.1244, -0.0564,  0.0722,  0.1263,  0.0785,  0.0573,\n",
      "           0.0786, -0.0594, -0.0146, -0.1008,  0.0304, -0.0533, -0.0063,\n",
      "           0.2683]],\n",
      "\n",
      "        [[-0.0899, -0.1282,  0.0192,  0.0541, -0.0026,  0.0289, -0.1105,\n",
      "           0.1363, -0.0516,  0.0120,  0.0660, -0.0674,  0.0270,  0.1252,\n",
      "          -0.0760,  0.0043,  0.1235,  0.0869,  0.0051, -0.1587, -0.0569,\n",
      "           0.0846,  0.0735,  0.1890, -0.0159,  0.1254,  0.0133, -0.0498,\n",
      "           0.1450, -0.2546, -0.0205, -0.0333,  0.0164,  0.0015,  0.0234,\n",
      "           0.0311, -0.1800,  0.0291, -0.1397,  0.0814,  0.0354,  0.1323,\n",
      "           0.0760,  0.1478, -0.0086,  0.0600,  0.0144,  0.1243, -0.0531,\n",
      "           0.2455, -0.1247, -0.0571,  0.0749,  0.1452,  0.0883,  0.0319,\n",
      "           0.0807, -0.0748, -0.0405, -0.1101,  0.0264, -0.0398, -0.0205,\n",
      "           0.2983],\n",
      "         [-0.0753, -0.1144,  0.0271,  0.0615, -0.0065,  0.0311, -0.1082,\n",
      "           0.1212, -0.0399,  0.0299,  0.0830, -0.0601,  0.0067,  0.1248,\n",
      "          -0.0647,  0.0151,  0.1325,  0.0685,  0.0026, -0.1387, -0.0442,\n",
      "           0.0874,  0.0781,  0.1792, -0.0068,  0.1261,  0.0045, -0.0527,\n",
      "           0.1178, -0.2363, -0.0077, -0.0352,  0.0249,  0.0014,  0.0180,\n",
      "           0.0346, -0.1630,  0.0188, -0.1462,  0.0756,  0.0366,  0.1313,\n",
      "           0.0826,  0.1163, -0.0037,  0.0621,  0.0164,  0.1111, -0.0522,\n",
      "           0.2405, -0.1244, -0.0564,  0.0722,  0.1263,  0.0785,  0.0573,\n",
      "           0.0786, -0.0594, -0.0146, -0.1008,  0.0304, -0.0533, -0.0063,\n",
      "           0.2683]]])\n",
      "tensor([[-0.0899, -0.1282,  0.0192,  0.0541, -0.0026,  0.0289, -0.1105,  0.1363,\n",
      "         -0.0516,  0.0120,  0.0660, -0.0674,  0.0270,  0.1252, -0.0760,  0.0043,\n",
      "          0.1235,  0.0869,  0.0051, -0.1587, -0.0569,  0.0846,  0.0735,  0.1890,\n",
      "         -0.0159,  0.1254,  0.0133, -0.0498,  0.1450, -0.2546, -0.0205, -0.0333,\n",
      "          0.0164,  0.0015,  0.0234,  0.0311, -0.1800,  0.0291, -0.1397,  0.0814,\n",
      "          0.0354,  0.1323,  0.0760,  0.1478, -0.0086,  0.0600,  0.0144,  0.1243,\n",
      "         -0.0531,  0.2455, -0.1247, -0.0571,  0.0749,  0.1452,  0.0883,  0.0319,\n",
      "          0.0807, -0.0748, -0.0405, -0.1101,  0.0264, -0.0398, -0.0205,  0.2983,\n",
      "         -0.0753, -0.1144,  0.0271,  0.0615, -0.0065,  0.0311, -0.1082,  0.1212,\n",
      "         -0.0399,  0.0299,  0.0830, -0.0601,  0.0067,  0.1248, -0.0647,  0.0151,\n",
      "          0.1325,  0.0685,  0.0026, -0.1387, -0.0442,  0.0874,  0.0781,  0.1792,\n",
      "         -0.0068,  0.1261,  0.0045, -0.0527,  0.1178, -0.2363, -0.0077, -0.0352,\n",
      "          0.0249,  0.0014,  0.0180,  0.0346, -0.1630,  0.0188, -0.1462,  0.0756,\n",
      "          0.0366,  0.1313,  0.0826,  0.1163, -0.0037,  0.0621,  0.0164,  0.1111,\n",
      "         -0.0522,  0.2405, -0.1244, -0.0564,  0.0722,  0.1263,  0.0785,  0.0573,\n",
      "          0.0786, -0.0594, -0.0146, -0.1008,  0.0304, -0.0533, -0.0063,  0.2683],\n",
      "        [-0.0899, -0.1282,  0.0192,  0.0541, -0.0026,  0.0289, -0.1105,  0.1363,\n",
      "         -0.0516,  0.0120,  0.0660, -0.0674,  0.0270,  0.1252, -0.0760,  0.0043,\n",
      "          0.1235,  0.0869,  0.0051, -0.1587, -0.0569,  0.0846,  0.0735,  0.1890,\n",
      "         -0.0159,  0.1254,  0.0133, -0.0498,  0.1450, -0.2546, -0.0205, -0.0333,\n",
      "          0.0164,  0.0015,  0.0234,  0.0311, -0.1800,  0.0291, -0.1397,  0.0814,\n",
      "          0.0354,  0.1323,  0.0760,  0.1478, -0.0086,  0.0600,  0.0144,  0.1243,\n",
      "         -0.0531,  0.2455, -0.1247, -0.0571,  0.0749,  0.1452,  0.0883,  0.0319,\n",
      "          0.0807, -0.0748, -0.0405, -0.1101,  0.0264, -0.0398, -0.0205,  0.2983,\n",
      "         -0.0753, -0.1144,  0.0271,  0.0615, -0.0065,  0.0311, -0.1082,  0.1212,\n",
      "         -0.0399,  0.0299,  0.0830, -0.0601,  0.0067,  0.1248, -0.0647,  0.0151,\n",
      "          0.1325,  0.0685,  0.0026, -0.1387, -0.0442,  0.0874,  0.0781,  0.1792,\n",
      "         -0.0068,  0.1261,  0.0045, -0.0527,  0.1178, -0.2363, -0.0077, -0.0352,\n",
      "          0.0249,  0.0014,  0.0180,  0.0346, -0.1630,  0.0188, -0.1462,  0.0756,\n",
      "          0.0366,  0.1313,  0.0826,  0.1163, -0.0037,  0.0621,  0.0164,  0.1111,\n",
      "         -0.0522,  0.2405, -0.1244, -0.0564,  0.0722,  0.1263,  0.0785,  0.0573,\n",
      "          0.0786, -0.0594, -0.0146, -0.1008,  0.0304, -0.0533, -0.0063,  0.2683]])\n"
     ]
    }
   ],
   "source": [
    "tks = torch.stack([tk, tk])\n",
    "print(tks)\n",
    "print(tks.view(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(communities) == \n",
    "batch1.batch.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3, 0, 1, 1, 2, 1, 2, 2, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4,\n",
       "       4], dtype=int64)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = AffinityPropagation(affinity='precomputed', damping=0.7, random_state=42, convergence_iter=15, max_iter=3000)\n",
    "clustering.fit(S)\n",
    "clustering.labels_\n",
    "# clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUTAG(188)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expTrain(train_loader, val_loader, test_loader, epoch = 2):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "    experiment = Experiment(dataset, 64)\n",
    "\n",
    "    # Train\n",
    "    print('process training')\n",
    "    for _ in range(epoch):\n",
    "        loss = round(train_base(experiment, train_loader, True).item(), 5)\n",
    "        train_acc = round(test_base(experiment, train_loader, True), 5)\n",
    "        val_acc = round(test_base(experiment, val_loader, True), 5)\n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; test_acc: {val_acc}')\n",
    "\n",
    "    # Test\n",
    "    print('process testing')\n",
    "    test = test_base(experiment, test_loader, True)\n",
    "    print(f'Accuracy: {test}')\n",
    "\n",
    "# expTrain(train_loader, val_loader, test_loader, epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseTrain(train_loader, val_loader, test_loader, epoch = 10):\n",
    "    base = Base(dataset, 64)\n",
    "\n",
    "    # Train\n",
    "    for _ in range(epoch):\n",
    "        loss = round(train_base(base, train_loader).item(), 5)\n",
    "        train_acc = round(test_base(base, train_loader), 5)\n",
    "        val_acc = round(test_base(base, val_loader), 5)\n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; val_acc: {val_acc}; test: {round(test_base(base, test_loader), 2)}')\n",
    "\n",
    "    # Test\n",
    "    test = test_base(base, test_loader)\n",
    "    print(f'Accuracy: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:round(len(dataset) * 0.8)]\n",
    "test_dataset = dataset[round(len(dataset) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0/10\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.69358; train_acc: 0.7125; val_acc: 0.675; test: 0.81\n",
      "epoch 1; loss: 0.51878; train_acc: 0.72083; val_acc: 0.675; test: 0.73\n",
      "epoch 2; loss: 0.57897; train_acc: 0.71944; val_acc: 0.6375; test: 0.73\n",
      "epoch 3; loss: 0.55901; train_acc: 0.72778; val_acc: 0.6875; test: 0.74\n",
      "epoch 4; loss: 0.58857; train_acc: 0.70556; val_acc: 0.575; test: 0.68\n",
      "epoch 5; loss: 0.49834; train_acc: 0.7125; val_acc: 0.6625; test: 0.72\n",
      "epoch 6; loss: 0.55777; train_acc: 0.73472; val_acc: 0.7125; test: 0.77\n",
      "epoch 7; loss: 0.59016; train_acc: 0.74306; val_acc: 0.725; test: 0.76\n",
      "epoch 8; loss: 0.52072; train_acc: 0.74722; val_acc: 0.6625; test: 0.77\n",
      "epoch 9; loss: 0.58987; train_acc: 0.7125; val_acc: 0.75; test: 0.77\n",
      "Accuracy: 0.77\n",
      "=== Experiment model ===\n",
      "process training\n",
      "epoch 0; loss: 0.67796; train_acc: 0.475; test_acc: 0.575\n",
      "epoch 1; loss: 0.66832; train_acc: 0.65417; test_acc: 0.7125\n",
      "epoch 2; loss: 0.7253; train_acc: 0.60972; test_acc: 0.6625\n",
      "epoch 3; loss: 0.65472; train_acc: 0.67639; test_acc: 0.6\n",
      "epoch 4; loss: 0.55065; train_acc: 0.69861; test_acc: 0.625\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_dataset\n",
    "test_dataset\n",
    "k = 10\n",
    "\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "k_counter = 0\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(train_dataset)))):\n",
    "    # print('Fold {}'.format(fold + 1))\n",
    "    # print(f'Fold',fold,'Train_idx',train_idx,'Val_idx',val_idx)\n",
    "    print(f'Fold {fold}/{k}')\n",
    "    #if k_counter > 2:\n",
    "    #    break\n",
    "    \n",
    "    fold_train = []\n",
    "    for key in train_idx:\n",
    "        fold_train.append(train_dataset[key])\n",
    "\n",
    "    fold_val = [] \n",
    "    for key in val_idx:\n",
    "        fold_val.append(train_dataset[key])\n",
    "\n",
    "    tr = DataLoader(fold_train, batch_size=batch_size, shuffle=True)\n",
    "    vd = DataLoader(fold_val, batch_size=batch_size, shuffle=True)\n",
    "    ts = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Base model\n",
    "    print(\"=== Base model ===\")\n",
    "    baseTrain(tr, vd, ts, 10)\n",
    "    print(\"=== Experiment model ===\")\n",
    "    expTrain(tr, vd, ts, 10)\n",
    "    \n",
    "    k_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
