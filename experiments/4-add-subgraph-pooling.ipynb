{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from preprocessing import data_transformation\n",
    "from similarity import calculate_similarity_matrix\n",
    "\n",
    "from model import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='datasets/', name='MUTAG')\n",
    "torch.manual_seed(1234)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split: Train test validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```train_dataset```: for training model<br/>\n",
    "```val_dataset```: evaluate model for hyperparameter tunning<br/>\n",
    "```test_dataset```: testing model after complete training<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, ts, vl = 0.8, 0.1, 0.1\n",
    "dslen = len(dataset)\n",
    "tri = round(tr*dslen)\n",
    "tsi = round((tr+ts)*dslen)\n",
    "train_dataset = dataset[:tri]\n",
    "test_dataset = dataset[tri:tsi]\n",
    "val_dataset = dataset[tsi:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)\n",
    "test_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)\n",
    "val_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper 128\n",
    "batch_size = 2\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 92], x=[40, 7], edge_attr=[92, 4], y=[2], batch=[40], ptr=[3])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "edge_index tensor([[ 0,  0,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  5,  5,  5,  6,  6,  6,\n",
      "          7,  8,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 13, 13, 14, 14, 14, 15,\n",
      "         15, 16, 17, 17, 18, 18, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 23, 23,\n",
      "         23, 24, 24, 25, 25, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30,\n",
      "         30, 31, 31, 31, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 37, 37, 37,\n",
      "         38, 39],\n",
      "        [ 1,  5,  0,  2,  1,  3, 11,  2,  4,  9,  3,  5,  0,  4,  6,  5,  7,  8,\n",
      "          6,  6,  3, 10,  9, 11, 15,  2, 10, 12, 11, 13, 12, 14, 13, 15, 16, 10,\n",
      "         14, 14, 18, 22, 17, 19, 18, 20, 19, 21, 30, 20, 22, 23, 17, 21, 21, 24,\n",
      "         28, 23, 25, 24, 26, 25, 27, 26, 28, 36, 23, 27, 29, 28, 30, 34, 20, 29,\n",
      "         31, 30, 32, 37, 31, 33, 32, 34, 29, 33, 35, 34, 36, 27, 35, 31, 38, 39,\n",
      "         37, 37]])\n",
      "batch tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.]])\n",
      "ptr tensor([ 0, 17, 40])\n"
     ]
    }
   ],
   "source": [
    "batch1 = None\n",
    "for batch in train_loader:\n",
    "    batch1 = batch\n",
    "    break\n",
    "print(batch1)\n",
    "print(batch1.batch)\n",
    "print(\"edge_index\", batch1.edge_index)\n",
    "print(\"batch\",batch1.edge_attr)\n",
    "print(\"ptr\",batch1.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([0, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([0, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n",
      "tensor([0, 0])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([0, 0])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "val loader\n",
      "tensor([0, 0])\n",
      "tensor([0, 1])\n",
      "tensor([1, 0])\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 1])\n",
      "tensor([0, 0])\n",
      "tensor([1])\n",
      "test loader\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([1, 0])\n",
      "tensor([1, 1])\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print('train loader')\n",
    "for data in train_loader:\n",
    "    print(data.y)\n",
    "    \n",
    "print('val loader')\n",
    "for data in val_loader:\n",
    "    print(data.y)\n",
    "    \n",
    "print('test loader')\n",
    "for data in test_loader:\n",
    "    print(data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(Base, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # classification layer\n",
    "        \n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv3(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        h = self.lin(embedding)\n",
    "        h = h.relu()\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base(\n",
       "  (conv1): GCNConv(7, 64)\n",
       "  (conv2): GCNConv(64, 64)\n",
       "  (conv3): GCNConv(64, 64)\n",
       "  (lin): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (lin2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = Base(dataset, 64)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4234, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_base(model, loader, experiment_mode=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(h, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss\n",
    "    #     print(h[0])\n",
    "    # print(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_base(model, loader, experiment_mode=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        pred = h.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct/len(loader.dataset)\n",
    "\n",
    "base = Base(dataset, 64)\n",
    "train_base(base, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = 100\n",
    "\n",
    "# base = Base(dataset, 64)\n",
    "# train_base(base, train_loader)\n",
    "\n",
    "# # Train\n",
    "# for _ in range(epoch):\n",
    "#     loss = round(train_base(base, train_loader).item(), 2)\n",
    "#     train_acc = round(test_base(base, train_loader), 2)\n",
    "#     val_acc = round(test_base(base, val_loader), 2)\n",
    "    \n",
    "#     print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; test_acc: {val_acc}')\n",
    "\n",
    "# # Test\n",
    "# test = test_base(base, test_loader)\n",
    "# print(f'Accuracy: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 92], x=[40, 7], edge_attr=[92, 4], y=[2], batch=[40], ptr=[3])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "edge_index tensor([[ 0,  0,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  5,  5,  5,  6,  6,  6,\n",
      "          7,  8,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 13, 13, 14, 14, 14, 15,\n",
      "         15, 16, 17, 17, 18, 18, 19, 19, 20, 20, 20, 21, 21, 21, 22, 22, 23, 23,\n",
      "         23, 24, 24, 25, 25, 26, 26, 27, 27, 27, 28, 28, 28, 29, 29, 29, 30, 30,\n",
      "         30, 31, 31, 31, 32, 32, 33, 33, 34, 34, 34, 35, 35, 36, 36, 37, 37, 37,\n",
      "         38, 39],\n",
      "        [ 1,  5,  0,  2,  1,  3, 11,  2,  4,  9,  3,  5,  0,  4,  6,  5,  7,  8,\n",
      "          6,  6,  3, 10,  9, 11, 15,  2, 10, 12, 11, 13, 12, 14, 13, 15, 16, 10,\n",
      "         14, 14, 18, 22, 17, 19, 18, 20, 19, 21, 30, 20, 22, 23, 17, 21, 21, 24,\n",
      "         28, 23, 25, 24, 26, 25, 27, 26, 28, 36, 23, 27, 29, 28, 30, 34, 20, 29,\n",
      "         31, 30, 32, 37, 31, 33, 32, 34, 29, 33, 35, 34, 36, 27, 35, 31, 38, 39,\n",
      "         37, 37]])\n",
      "batch tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.]])\n",
      "ptr tensor([ 0, 17, 40])\n"
     ]
    }
   ],
   "source": [
    "batch1 = None\n",
    "for batch in train_loader:\n",
    "    batch1 = batch\n",
    "    break\n",
    "print(batch1)\n",
    "print(batch1.batch)\n",
    "print(\"edge_index\", batch1.edge_index)\n",
    "print(\"batch\",batch1.edge_attr)\n",
    "print(\"ptr\",batch1.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39)\n",
      "tensor(39)\n",
      "tensor([[ 0,  0,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  5,  5,  5,  6,  6,  6,\n",
      "          7,  8,  9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 13, 13, 14, 14, 14, 15,\n",
      "         15, 16],\n",
      "        [ 1,  5,  0,  2,  1,  3, 11,  2,  4,  9,  3,  5,  0,  4,  6,  5,  7,  8,\n",
      "          6,  6,  3, 10,  9, 11, 15,  2, 10, 12, 11, 13, 12, 14, 13, 15, 16, 10,\n",
      "         14, 14]])\n",
      "tensor([ 0, 17, 40]) ; len: 3\n"
     ]
    }
   ],
   "source": [
    "print(max(batch1.edge_index[0]))\n",
    "print(max(batch1.edge_index[1]))\n",
    "print((dataset[0].edge_index))\n",
    "print((batch1.ptr), '; len:', len(batch1.ptr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below --> Subgraph extractor with batch information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper 128\n",
    "batch_size = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "batch1 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering label [0 0 0 0 0 0 2 0 0 2 2 1 1 1 1 2 1]\n",
      "{0: [0, 1, 2, 3, 4, 5, 7, 8], 2: [6, 9, 10, 15], 1: [11, 12, 13, 14, 16]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1]\n",
      "\n",
      "clustering label [0 1 1 3 0 0 2 2 2 2 2 3 3 1 3 3 3 3 3 2 1 3 3]\n",
      "{0: [0, 4, 5], 1: [1, 2, 13, 20], 3: [3, 11, 12, 14, 15, 16, 17, 18, 21, 22], 2: [6, 7, 8, 9, 10, 19]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3]\n",
      "\n",
      "clustering label [0 0 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2]\n",
      "{0: [0, 1, 2, 3], 1: [4, 5, 6], 2: [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "clustering label [0 0 0 0 1 1 1 1 1 2 1 1 0 0 3 1 2 2 3 3 2 1 1]\n",
      "{0: [0, 1, 2, 3, 12, 13], 1: [4, 5, 6, 7, 8, 10, 11, 15, 21, 22], 2: [9, 16, 17, 20], 3: [14, 18, 19]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1]\n",
      "\n",
      "clustering label [0 3 1 1 0 0 0 2 3 3 1 3 3 2 2 2]\n",
      "{0: [0, 4, 5, 6], 3: [1, 8, 9, 11, 12], 1: [2, 3, 10], 2: [7, 13, 14, 15]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 2, 2, 2]\n",
      "\n",
      "clustering label [0 1 0 1 1 0 1 1 1 2 2 2 2 2 2 2 2]\n",
      "{0: [0, 2, 5], 1: [1, 3, 4, 6, 7, 8], 2: [9, 10, 11, 12, 13, 14, 15, 16]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "clustering label [0 0 0 0 2 2 1 1 1 2 1 0 0 2 1 1]\n",
      "{0: [0, 1, 2, 3, 11, 12], 2: [4, 5, 9, 13], 1: [6, 7, 8, 10, 14, 15]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1]\n",
      "\n",
      "clustering label [1 0 0 0 2 2 2 0 1 1 1 1 1 1 1 2 1 1 1 2 2 2 0 0 0]\n",
      "{1: [0, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], 0: [1, 2, 3, 7, 22, 23, 24], 2: [4, 5, 6, 15, 19, 20, 21]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 0, 0]\n",
      "\n",
      "clustering label [1 0 0 2 1 1 1 2 3 3 3]\n",
      "{1: [0, 4, 5, 6], 0: [1, 2], 2: [3, 7], 3: [8, 9, 10]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 2, 3, 3, 3]\n",
      "\n",
      "clustering label [0 1 1 1 0 0 0 2 2 3 3 3 3 2 2 3 3]\n",
      "{0: [0, 4, 5, 6], 1: [1, 2, 3], 2: [7, 8, 13, 14], 3: [9, 10, 11, 12, 15, 16]}\n",
      "all com [0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 3, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 3, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 3, 1, 2, 2, 3, 3, 2, 1, 1, 0, 3, 1, 1, 0, 0, 0, 2, 3, 3, 1, 3, 3, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 2, 3, 3, 3, 0, 1, 1, 1, 0, 0, 0, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3]\n",
      "\n",
      "batch communities {0: {0: [0, 1, 2, 3, 4, 5, 7, 8], 2: [6, 9, 10, 15], 1: [11, 12, 13, 14, 16]}, 1: {0: [0, 4, 5], 1: [1, 2, 13, 20], 3: [3, 11, 12, 14, 15, 16, 17, 18, 21, 22], 2: [6, 7, 8, 9, 10, 19]}, 2: {0: [0, 1, 2, 3], 1: [4, 5, 6], 2: [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]}, 3: {0: [0, 1, 2, 3, 12, 13], 1: [4, 5, 6, 7, 8, 10, 11, 15, 21, 22], 2: [9, 16, 17, 20], 3: [14, 18, 19]}, 4: {0: [0, 4, 5, 6], 3: [1, 8, 9, 11, 12], 1: [2, 3, 10], 2: [7, 13, 14, 15]}, 5: {0: [0, 2, 5], 1: [1, 3, 4, 6, 7, 8], 2: [9, 10, 11, 12, 13, 14, 15, 16]}, 6: {0: [0, 1, 2, 3, 11, 12], 2: [4, 5, 9, 13], 1: [6, 7, 8, 10, 14, 15]}, 7: {1: [0, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18], 0: [1, 2, 3, 7, 22, 23, 24], 2: [4, 5, 6, 15, 19, 20, 21]}, 8: {1: [0, 4, 5, 6], 0: [1, 2], 2: [3, 7], 3: [8, 9, 10]}, 9: {0: [0, 4, 5, 6], 1: [1, 2, 3], 2: [7, 8, 13, 14], 3: [9, 10, 11, 12, 15, 16]}}\n",
      "batch loop\n",
      "\n",
      "==== BATCH 0 ====\n",
      "lower bound 0\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 2\n",
      "break new community 1\n",
      "pool subgraph ===  [[-7.13079805e-02 -1.06299196e-01  2.83601729e-02  5.57242841e-02\n",
      "  -5.24456015e-03  3.03573050e-02 -1.00384892e-01  1.16899168e-01\n",
      "  -3.58921189e-02  3.15075531e-02  7.81057272e-02 -5.37340463e-02\n",
      "   4.42506466e-03  1.16599278e-01 -6.20746617e-02  1.73391757e-02\n",
      "   1.21321341e-01  6.42146282e-02  3.56211793e-03 -1.30183586e-01\n",
      "  -3.80475083e-02  8.14759494e-02  7.51192719e-02  1.68375585e-01\n",
      "  -2.49571478e-03  1.14458229e-01  2.42939830e-03 -5.37478190e-02\n",
      "   1.05898074e-01 -2.19778559e-01 -4.78154444e-03 -3.56793813e-02\n",
      "   2.34372258e-02 -1.23886944e-04  1.58505100e-02  3.34608613e-02\n",
      "  -1.49960813e-01  1.71618282e-02 -1.40344288e-01  7.24917182e-02\n",
      "   3.63402329e-02  1.22698031e-01  7.89134665e-02  1.03688332e-01\n",
      "  -1.44760875e-03  5.81526724e-02  1.60458458e-02  1.03602199e-01\n",
      "  -4.90078963e-02  2.20424643e-01 -1.18592205e-01 -5.29263592e-02\n",
      "   6.33594482e-02  1.19433802e-01  6.94065415e-02  5.84633723e-02\n",
      "   7.48535413e-02 -5.42511345e-02 -1.02321480e-02 -9.43313232e-02\n",
      "   2.87959212e-02 -5.17806816e-02 -1.81190204e-03  2.49202600e-01]\n",
      " [-8.98994364e-02 -1.28153260e-01  1.91843715e-02  5.41176651e-02\n",
      "  -2.58179540e-03  2.88590256e-02 -1.10499360e-01  1.36333321e-01\n",
      "  -5.16270146e-02  1.19583161e-02  6.59656808e-02 -6.74092039e-02\n",
      "   2.69917501e-02  1.25158092e-01 -7.60258630e-02  4.25959588e-03\n",
      "   1.23503178e-01  8.68897840e-02  5.14223436e-03 -1.58654514e-01\n",
      "  -5.68885267e-02  8.46192375e-02  7.35151246e-02  1.88998348e-01\n",
      "  -1.59159072e-02  1.25404501e-01  1.33125498e-02 -4.98141931e-02\n",
      "   1.44997604e-01 -2.54628134e-01 -2.05246838e-02 -3.33079200e-02\n",
      "   1.64167561e-02  1.46256714e-03  2.33829122e-02  3.11316811e-02\n",
      "  -1.80046692e-01  2.91348573e-02 -1.39745352e-01  8.14014308e-02\n",
      "   3.54018148e-02  1.32327047e-01  7.59846084e-02  1.47814944e-01\n",
      "  -8.63054981e-03  5.99928413e-02  1.44099286e-02  1.24261303e-01\n",
      "  -5.30728161e-02  2.45498908e-01 -1.24702699e-01 -5.70738368e-02\n",
      "   7.48712450e-02  1.45179699e-01  8.83052200e-02  3.19480976e-02\n",
      "   8.07433277e-02 -7.47500226e-02 -4.04816411e-02 -1.10058045e-01\n",
      "   2.63869192e-02 -3.97762284e-02 -2.05184769e-02  2.98322940e-01]\n",
      " [-7.52932564e-02 -1.14350688e-01  2.71005542e-02  6.15129136e-02\n",
      "  -6.53678854e-03  3.10866875e-02 -1.08237511e-01  1.21214853e-01\n",
      "  -3.99168720e-02  2.98835263e-02  8.30124523e-02 -6.01088405e-02\n",
      "   6.72333268e-03  1.24778423e-01 -6.47426723e-02  1.50631350e-02\n",
      "   1.32453021e-01  6.84516029e-02  2.59067328e-03 -1.38689811e-01\n",
      "  -4.41716197e-02  8.73775603e-02  7.81189865e-02  1.79175248e-01\n",
      "  -6.75429502e-03  1.26134640e-01  4.49985731e-03 -5.27272956e-02\n",
      "   1.17777533e-01 -2.36259894e-01 -7.69912417e-03 -3.51819554e-02\n",
      "   2.48848116e-02  1.41503764e-03  1.79571854e-02  3.46156391e-02\n",
      "  -1.63015688e-01  1.87666831e-02 -1.46249816e-01  7.55671626e-02\n",
      "   3.66465203e-02  1.31265074e-01  8.25793119e-02  1.16289359e-01\n",
      "  -3.65853822e-03  6.20902693e-02  1.63989356e-02  1.11139504e-01\n",
      "  -5.21830125e-02  2.40461051e-01 -1.24399997e-01 -5.63770523e-02\n",
      "   7.21876733e-02  1.26331044e-01  7.84710869e-02  5.72666340e-02\n",
      "   7.86481984e-02 -5.93911745e-02 -1.46327438e-02 -1.00754617e-01\n",
      "   3.03884563e-02 -5.32611106e-02 -6.31677778e-03  2.68286336e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 1 ====\n",
      "lower bound 17\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 3\n",
      "break new community 2\n",
      "pool subgraph ===  [[-0.12144645 -0.15307883  0.02319898  0.07499442 -0.01164866  0.0328696\n",
      "  -0.13569657  0.1812034  -0.06392801  0.01948284  0.09337158 -0.08753499\n",
      "   0.03858336  0.14447287 -0.08023492  0.01473026  0.15844384  0.08890502\n",
      "   0.0197903  -0.19063146 -0.06305069  0.11163729  0.0820257   0.23767805\n",
      "  -0.00922363  0.1643831   0.01677768 -0.0729273   0.17790319 -0.32092146\n",
      "  -0.01171769 -0.03615575  0.01405685  0.00316906  0.03133016  0.04214125\n",
      "  -0.22115064  0.03666062 -0.17314935  0.10313381  0.04579801  0.16188014\n",
      "   0.1121131   0.16794979 -0.00658807  0.07831855  0.02428093  0.13659222\n",
      "  -0.06019838  0.29590405 -0.13706381 -0.05983061  0.09000779  0.17051143\n",
      "   0.10428912  0.05316568  0.08443372 -0.08009291 -0.0344092  -0.1260954\n",
      "   0.03564219 -0.0427734  -0.01304923  0.36143678]\n",
      " [-0.07478761 -0.11300908  0.02799896  0.06156468 -0.00606807  0.03092885\n",
      "  -0.1076082   0.12144163 -0.03820506  0.03160288  0.08352658 -0.05910543\n",
      "   0.00498984  0.12392363 -0.06498208  0.01751267  0.13180969  0.06691728\n",
      "   0.0031194  -0.13716359 -0.04194513  0.08830398  0.07886571  0.18020546\n",
      "  -0.00499732  0.1260018   0.00253249 -0.05509962  0.11616865 -0.23502565\n",
      "  -0.00616457 -0.03538097  0.02520239  0.00124826  0.01788523  0.03468265\n",
      "  -0.1618245   0.017855   -0.14822338  0.07633639  0.03686114  0.13124739\n",
      "   0.08413655  0.11257778 -0.0018566   0.06380007  0.01584005  0.1104454\n",
      "  -0.0508999   0.23832884 -0.12391591 -0.05614237  0.07006116  0.12492912\n",
      "   0.07612391  0.05804534  0.07785358 -0.05911463 -0.0136253  -0.10018854\n",
      "   0.03121344 -0.05308251 -0.00532575  0.26553788]\n",
      " [-0.10536694 -0.1328112   0.02012744  0.06506518 -0.01010639  0.02851768\n",
      "  -0.11773036  0.15721209 -0.05546397  0.01690331  0.08100919 -0.07594535\n",
      "   0.03347492  0.12534465 -0.06961183  0.01277997  0.13746591  0.07713401\n",
      "   0.01717007 -0.1653919  -0.0547028   0.09685653  0.07116549  0.20620951\n",
      "  -0.00800241  0.14261878  0.01455632 -0.06327173  0.15434883 -0.27843147\n",
      "  -0.01016627 -0.03136872  0.01219572  0.00274949  0.02718206  0.03656176\n",
      "  -0.19187031  0.03180675 -0.1502244   0.08947891  0.03973438  0.14044721\n",
      "   0.09726933  0.14571325 -0.00571579  0.06794921  0.02106612  0.11850742\n",
      "  -0.05222814  0.25672633 -0.11891655 -0.05190907  0.07809076  0.14793572\n",
      "   0.09048125  0.04612653  0.07325468 -0.06948862 -0.02985342 -0.10940039\n",
      "   0.03092318 -0.03711021 -0.01132152  0.3135826 ]\n",
      " [-0.07529056 -0.10820412  0.02954316  0.06004617 -0.00489263  0.03211519\n",
      "  -0.10444152  0.11983059 -0.04245402  0.03422525  0.07667367 -0.05409403\n",
      "   0.00375444  0.11935922 -0.06706411  0.01264718  0.12599914  0.07074341\n",
      "   0.00235131 -0.13331052 -0.03883804  0.08339804  0.07586008  0.17310885\n",
      "  -0.00487573  0.11897427  0.00362211 -0.05227326  0.11776986 -0.23126653\n",
      "  -0.00524959 -0.03436635  0.02080553  0.00201521  0.01928308  0.03543396\n",
      "  -0.15470013  0.02069807 -0.13977725  0.077718    0.03582571  0.12625722\n",
      "   0.08238837  0.11055264 -0.000771    0.06114331  0.01745582  0.10444894\n",
      "  -0.05012827  0.22761292 -0.12044835 -0.05793098  0.065583    0.12184495\n",
      "   0.07550387  0.06051153  0.0762182  -0.05382964 -0.01468671 -0.09843456\n",
      "   0.02985408 -0.04958635 -0.00643891  0.25877117]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 2 ====\n",
      "lower bound 40\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "pool subgraph ===  [[-0.10075533 -0.12699844  0.01924652  0.06221746 -0.00966405  0.02726953\n",
      "  -0.11257765  0.15033141 -0.05303646  0.01616351  0.07746366 -0.07262146\n",
      "   0.03200984  0.1198587  -0.06656512  0.01222065  0.13144942  0.07375807\n",
      "   0.0164186  -0.15815319 -0.05230862  0.09261738  0.06805078  0.19718431\n",
      "  -0.00765217  0.1363768   0.01391925 -0.06050254  0.14759343 -0.26624537\n",
      "  -0.0097213  -0.02999583  0.01166196  0.00262914  0.02599238  0.03496155\n",
      "  -0.18347272  0.03041467 -0.14364952  0.08556269  0.03799532  0.13430026\n",
      "   0.09301216  0.1393358  -0.00546563  0.06497525  0.02014413  0.11332068\n",
      "  -0.04994224  0.24549019 -0.11371194 -0.04963714  0.07467296  0.141461\n",
      "   0.08652115  0.04410772  0.07004854 -0.06644731 -0.02854683 -0.10461225\n",
      "   0.02956976 -0.035486   -0.01082598  0.29985803]\n",
      " [-0.10996245 -0.13860371  0.02100528  0.06790294 -0.01054716  0.02976144\n",
      "  -0.12286508  0.16406882 -0.05788301  0.01764053  0.08454237 -0.07925767\n",
      "   0.03493491  0.1308115  -0.07264791  0.01333737  0.14346142  0.08049819\n",
      "   0.01791895 -0.17260538 -0.05708865  0.10108085  0.07426935  0.21520324\n",
      "  -0.00835145  0.14883903  0.01519118 -0.06603131  0.16108066 -0.29057516\n",
      "  -0.01060967 -0.03273686  0.01272764  0.0028694   0.02836758  0.03815639\n",
      "  -0.20023864  0.033194   -0.15677636  0.09338149  0.04146737  0.14657276\n",
      "   0.10151168  0.15206846 -0.00596511  0.07091275  0.0219849   0.12367606\n",
      "  -0.05450604  0.26792336 -0.12410306 -0.05417303  0.08149665  0.1543879\n",
      "   0.09442758  0.04813834  0.07644965 -0.07251931 -0.03115548 -0.11417184\n",
      "   0.03227186 -0.03872876 -0.01181528  0.32725937]\n",
      " [-0.07930576 -0.11497914  0.02820391  0.06392096 -0.00440765  0.03198102\n",
      "  -0.11031344  0.12593274 -0.04591544  0.03133508  0.07849711 -0.05837317\n",
      "   0.00684081  0.1222322  -0.072336    0.01473127  0.13458309  0.07329399\n",
      "   0.00378241 -0.14147495 -0.04304416  0.09215255  0.07816776  0.18574205\n",
      "  -0.00691601  0.1278495   0.00335859 -0.05676414  0.130799   -0.24673222\n",
      "  -0.00629508 -0.03324921  0.01983656  0.00376363  0.02270384  0.03549595\n",
      "  -0.16816804  0.02065557 -0.1482101   0.08356941  0.03602049  0.13273509\n",
      "   0.08932717  0.11833143  0.00091777  0.0677267   0.01512465  0.11062265\n",
      "  -0.04996543  0.23982674 -0.12265789 -0.06064217  0.06960489  0.12702222\n",
      "   0.08145715  0.05580778  0.07658243 -0.06066876 -0.02072472 -0.10390984\n",
      "   0.03200495 -0.04722512 -0.01022892  0.27432915]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 3 ====\n",
      "lower bound 57\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "break new community 3\n",
      "pool subgraph ===  [[-0.1151654  -0.14516181  0.02199917  0.07111583 -0.01104623  0.03116964\n",
      "  -0.12867854  0.17183181 -0.06062175  0.0184752   0.08854252 -0.08300779\n",
      "   0.03658788  0.13700091 -0.0760853   0.01396841  0.15024938  0.08430698\n",
      "   0.01876676 -0.18077227 -0.05978981  0.10586359  0.07778342  0.22538568\n",
      "  -0.00874659  0.15588142  0.01590996 -0.06915558  0.16870231 -0.30432385\n",
      "  -0.01111165 -0.03428581  0.01332983  0.00300519  0.02970983  0.03996177\n",
      "  -0.20971302  0.03476458 -0.16419431  0.09779988  0.04342941  0.15350791\n",
      "   0.10631476  0.15926366 -0.00624733  0.07426805  0.02302513  0.12952787\n",
      "  -0.05708502  0.28060026 -0.12997504 -0.05673629  0.08535272  0.16169282\n",
      "   0.09889544  0.05041602  0.08006692 -0.07595062 -0.0326296  -0.11957394\n",
      "   0.03379885 -0.04056122 -0.01237436  0.34274382]\n",
      " [-0.07778822 -0.1101656   0.02531034  0.05696518 -0.0071211   0.0298418\n",
      "  -0.102074    0.12297589 -0.04074887  0.02723526  0.0774537  -0.05853335\n",
      "   0.01179387  0.11691902 -0.06078548  0.01334209  0.12286889  0.06572919\n",
      "   0.00580095 -0.13458084 -0.04267946  0.08176781  0.07113184  0.17086788\n",
      "  -0.00462249  0.11830395  0.0069116  -0.05214972  0.11415539 -0.22835467\n",
      "  -0.00677508 -0.03404611  0.0198489   0.00096426  0.01786599  0.03414238\n",
      "  -0.15559481  0.02115796 -0.13677643  0.07321801  0.03632514  0.1239773\n",
      "   0.07991696  0.11232103 -0.0045821   0.05673849  0.01837038  0.10392062\n",
      "  -0.04979619  0.22500526 -0.11555265 -0.05119148  0.06713326  0.12300126\n",
      "   0.07456888  0.05619866  0.0730671  -0.05466188 -0.01357318 -0.09498261\n",
      "   0.02809633 -0.04836388 -0.00386139  0.2586469 ]\n",
      " [-0.07330108 -0.11113535  0.02771501  0.06064675 -0.00592551  0.03052651\n",
      "  -0.10594726  0.11922365 -0.03742257  0.03136441  0.08238368 -0.05803398\n",
      "   0.00451757  0.12215524 -0.06399999  0.01733237  0.12987029  0.06582906\n",
      "   0.00287716 -0.13483019 -0.04117337  0.0869375   0.07786169  0.17729623\n",
      "  -0.00488442  0.12398969  0.00232713 -0.05420696  0.11399105 -0.23109748\n",
      "  -0.00602113 -0.03493841  0.02503034  0.00120946  0.01750174  0.03416683\n",
      "  -0.15911756  0.01740626 -0.14610397  0.075074    0.03630054  0.12926592\n",
      "   0.08276426  0.11052203 -0.00177598  0.06284143  0.01554283  0.10877347\n",
      "  -0.05016305  0.23470687 -0.12223821 -0.05541003  0.06895944  0.12284201\n",
      "   0.07484737  0.05739457  0.07682009 -0.05813427 -0.01320412 -0.0986451\n",
      "   0.03077718 -0.05255894 -0.00516605  0.26111382]\n",
      " [-0.10967193 -0.13823751  0.02094978  0.06772354 -0.01051929  0.02968282\n",
      "  -0.12254047  0.16363535 -0.05773007  0.01759392  0.084319   -0.07904828\n",
      "   0.03484262  0.13046589 -0.07245597  0.01330213  0.14308239  0.08028549\n",
      "   0.0178716  -0.17214936 -0.05693781  0.1008138   0.07407312  0.21463466\n",
      "  -0.00832938  0.1484458   0.01515105 -0.06585685  0.16065508 -0.28980745\n",
      "  -0.01058165 -0.03265037  0.01269401  0.00286181  0.02829263  0.03805558\n",
      "  -0.19970961  0.03310631 -0.15636215  0.09313477  0.04135781  0.14618552\n",
      "   0.10124348  0.15166669 -0.00594935  0.0707254   0.02192682  0.12334931\n",
      "  -0.05436203  0.26721551 -0.12377518 -0.0540299   0.08128133  0.15398\n",
      "   0.09417809  0.04801115  0.07624767 -0.07232771 -0.03107316 -0.11387019\n",
      "   0.03218659 -0.03862644 -0.01178407  0.32639473]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 4 ====\n",
      "lower bound 80\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 3\n",
      "break new community 1\n",
      "break new community 2\n",
      "pool subgraph ===  [[-1.24384822e-01 -1.57013278e-01  2.40401737e-02  7.68797249e-02\n",
      "  -1.17579196e-02  3.37244389e-02 -1.39304729e-01  1.85836036e-01\n",
      "  -6.52479567e-02  2.02592001e-02  9.57161896e-02 -8.95105805e-02\n",
      "   3.91386785e-02  1.48100831e-01 -8.28713737e-02  1.56357787e-02\n",
      "   1.62480447e-01  9.12135486e-02  2.03687348e-02 -1.95610408e-01\n",
      "  -6.42754845e-02  1.14860740e-01  8.47113170e-02  2.44260672e-01\n",
      "  -9.30865633e-03  1.68545164e-01  1.67667347e-02 -7.53493067e-02\n",
      "   1.82339903e-01 -3.29158232e-01 -1.17666400e-02 -3.72403385e-02\n",
      "   1.46478217e-02  3.18213558e-03  3.22181061e-02  4.30914899e-02\n",
      "  -2.26927351e-01  3.72479795e-02 -1.78462256e-01  1.06220083e-01\n",
      "   4.70388243e-02  1.66135963e-01  1.15277341e-01  1.71719328e-01\n",
      "  -6.18536258e-03  8.09084540e-02  2.44978503e-02  1.40314635e-01\n",
      "  -6.15016138e-02  3.03323757e-01 -1.40931204e-01 -6.16986798e-02\n",
      "   9.18419659e-02  1.74946371e-01  1.06474290e-01  5.43560823e-02\n",
      "   8.67978446e-02 -8.24352242e-02 -3.53578692e-02 -1.29542237e-01\n",
      "   3.66369458e-02 -4.38780328e-02 -1.33411651e-02  3.70690055e-01]\n",
      " [-6.77110177e-02 -1.09709683e-01  2.99669846e-02  6.18770520e-02\n",
      "  -5.86738018e-03  3.23863483e-02 -1.06618832e-01  1.13136222e-01\n",
      "  -3.47174459e-02  3.55876672e-02  8.59746387e-02 -5.63550595e-02\n",
      "  -1.88406557e-03  1.26147253e-01 -6.33758282e-02  1.72771908e-02\n",
      "   1.32931836e-01  6.48733936e-02 -1.08584544e-03 -1.31168072e-01\n",
      "  -4.05330854e-02  8.64519440e-02  8.11674893e-02  1.74129220e-01\n",
      "  -5.00815878e-03  1.23595320e-01  7.48295647e-04 -5.17975924e-02\n",
      "   1.07061112e-01 -2.26866044e-01 -5.83429805e-03 -3.70732273e-02\n",
      "   2.88724719e-02  1.18300338e-03  1.54464257e-02  3.50589373e-02\n",
      "  -1.55969446e-01  1.48595963e-02 -1.48244450e-01  7.26718269e-02\n",
      "   3.66124921e-02  1.30743424e-01  8.07367812e-02  1.06271235e-01\n",
      "  -2.52920956e-03  6.20312716e-02  1.55755659e-02  1.09435389e-01\n",
      "  -5.20421391e-02  2.38120834e-01 -1.26848914e-01 -5.78647802e-02\n",
      "   7.04281094e-02  1.20502348e-01  7.46574365e-02  6.31983392e-02\n",
      "   8.05118680e-02 -5.60571042e-02 -8.56346389e-03 -9.85832810e-02\n",
      "   3.13607641e-02 -5.90967213e-02 -3.57718083e-03  2.56879325e-01]\n",
      " [ 1.54403466e-02 -4.96700238e-02  5.00457091e-02  4.47302428e-02\n",
      "   1.81519185e-03  4.24110936e-02 -6.79537188e-02  1.44710751e-02\n",
      "   4.65634465e-03  7.15423841e-02  8.50124508e-02 -8.42344540e-03\n",
      "  -7.27364477e-02  1.15924302e-01 -3.95889976e-02  1.81619443e-02\n",
      "   1.05996225e-01  3.50970691e-02 -4.02774708e-02 -4.62760888e-02\n",
      "  -1.08348045e-02  4.79330211e-02  8.83827414e-02  7.74851274e-02\n",
      "   5.11849293e-03  6.03216104e-02 -2.17859852e-02 -1.87643443e-02\n",
      "  -9.77589213e-03 -9.40211480e-02  3.16078329e-03 -5.06328633e-02\n",
      "   5.63103054e-02 -2.46793532e-03 -1.38286538e-02  3.15917232e-02\n",
      "  -5.85757671e-02 -1.75546538e-02 -1.20205412e-01  2.61276725e-02\n",
      "   2.88737710e-02  9.33884121e-02  3.37145203e-02  1.23726855e-02\n",
      "  -1.90452748e-03  3.13205109e-02  1.02617595e-02  7.51700001e-02\n",
      "  -5.19600483e-02  1.68613922e-01 -1.30872911e-01 -6.43052338e-02\n",
      "   4.85052411e-02  5.33220973e-02  3.60130970e-02  1.05489172e-01\n",
      "   9.00078230e-02 -1.53715141e-02  4.46295757e-02 -6.22323854e-02\n",
      "   2.58502658e-02 -1.04279865e-01  2.03082489e-02  1.10812282e-01]\n",
      " [-4.26611200e-02 -7.93765396e-02  3.40897307e-02  4.61095430e-02\n",
      "  -2.24703108e-04  2.91033372e-02 -8.10297459e-02  7.86333213e-02\n",
      "  -1.98327299e-02  4.05066028e-02  7.15781771e-02 -3.36246422e-02\n",
      "  -1.74963801e-02  1.03979817e-01 -5.26618831e-02  1.89754002e-02\n",
      "   1.01666309e-01  5.27927198e-02 -8.25853609e-03 -9.69366699e-02\n",
      "  -2.32774463e-02  6.50750183e-02  7.46521875e-02  1.31680599e-01\n",
      "   2.12926734e-03  8.76023278e-02 -6.95166038e-03 -4.29227393e-02\n",
      "   6.72815286e-02 -1.62996309e-01  1.89741794e-04 -3.54699068e-02\n",
      "   3.03200904e-02 -1.59128073e-03  6.30816817e-03  2.77033862e-02\n",
      "  -1.10053371e-01  7.70609044e-03 -1.22999093e-01  5.57967003e-02\n",
      "   3.04504406e-02  1.02800713e-01  6.22153647e-02  6.72391923e-02\n",
      "   1.56294173e-03  4.92827490e-02  1.09065678e-02  8.56426314e-02\n",
      "  -4.30220962e-02  1.80615723e-01 -1.10490113e-01 -4.94279370e-02\n",
      "   4.86814879e-02  9.04909074e-02  5.07113487e-02  6.26089193e-02\n",
      "   7.10773543e-02 -4.09180694e-02  4.28937040e-03 -7.78677493e-02\n",
      "   2.57183928e-02 -5.65479361e-02  3.90944537e-03  1.86617267e-01]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 5 ====\n",
      "lower bound 96\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "pool subgraph ===  [[-0.09600318 -0.12320472  0.02387209  0.062078   -0.0057293   0.02748483\n",
      "  -0.11242087  0.14661277 -0.04937686  0.02278885  0.07642018 -0.06633225\n",
      "   0.0228461   0.11888048 -0.07336942  0.01840862  0.1306556   0.07572515\n",
      "   0.01479097 -0.15598486 -0.0449645   0.09529797  0.07481033  0.20136737\n",
      "  -0.00533233  0.13428924  0.00662362 -0.06630489  0.1462414  -0.26284722\n",
      "  -0.0062384  -0.03057907  0.01472148  0.00175201  0.02611302  0.03433074\n",
      "  -0.18020807  0.02663437 -0.1507987   0.09046717  0.03770706  0.13442842\n",
      "   0.09657163  0.13128513  0.00215801  0.0715681   0.01608665  0.1144436\n",
      "  -0.04770635  0.24134946 -0.11840198 -0.05444699  0.06826667  0.13885608\n",
      "   0.0808443   0.04452474  0.07141651 -0.06841658 -0.02975559 -0.10741046\n",
      "   0.031472   -0.03532218 -0.01137375  0.29419413]\n",
      " [-0.04603344 -0.10082983  0.0389743   0.06361131 -0.00374329  0.03781396\n",
      "  -0.10559234  0.09035339 -0.02358858  0.05093199  0.09539889 -0.04678536\n",
      "  -0.02634474  0.13575678 -0.06209148  0.02064349  0.13907607  0.06079854\n",
      "  -0.01423545 -0.1160794  -0.03422673  0.08397836  0.09262471  0.16211729\n",
      "  -0.00306315  0.11802127 -0.00783151 -0.0465479   0.08060391 -0.20632162\n",
      "  -0.00343578 -0.04400267  0.04205298  0.00041271  0.00762898  0.03664751\n",
      "  -0.14083244  0.00455288 -0.15546121  0.06497801  0.03692595  0.13250571\n",
      "   0.07431967  0.08622686 -0.00162168  0.06042738  0.01384513  0.10999573\n",
      "  -0.05622069  0.24152974 -0.14126144 -0.06601841  0.07079712  0.10960519\n",
      "   0.06933676  0.08096319  0.09116847 -0.04979933  0.00664475 -0.09712116\n",
      "   0.03333407 -0.07913559  0.00249949  0.23483633]\n",
      " [-0.09579358 -0.13448275  0.02215793  0.0604322  -0.00510524  0.02957397\n",
      "  -0.11024943  0.14255376 -0.05736396  0.02281703  0.07994399 -0.0716917\n",
      "   0.03495627  0.11876574 -0.06509182  0.0048264   0.13283131  0.07831761\n",
      "   0.00924301 -0.16012888 -0.06012723  0.09665844  0.0676895   0.19754427\n",
      "  -0.01047917  0.13033762  0.01755907 -0.06040132  0.14088497 -0.26569044\n",
      "  -0.01214755 -0.03239205  0.00807594  0.00417712  0.0296757   0.04041317\n",
      "  -0.18512483  0.03003033 -0.13840694  0.08385815  0.04151006  0.13662172\n",
      "   0.09452868  0.13640863  0.00378047  0.06519101  0.01986448  0.1097678\n",
      "  -0.05887891  0.24360671 -0.11696799 -0.05471904  0.07001857  0.13404349\n",
      "   0.08328125  0.05410295  0.07498621 -0.0651009  -0.02256185 -0.10538482\n",
      "   0.03010058 -0.03324641 -0.00653899  0.30130491]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 6 ====\n",
      "lower bound 113\n",
      "len communities on this batch 3\n",
      "break new community 0\n",
      "break new community 2\n",
      "break new community 1\n",
      "pool subgraph ===  [[-1.04515166e-01 -1.32703776e-01  2.43086303e-02  6.51459154e-02\n",
      "  -7.63988018e-03  2.90427391e-02 -1.19221819e-01  1.57453783e-01\n",
      "  -5.33612414e-02  2.15222413e-02  8.21865201e-02 -7.27411434e-02\n",
      "   2.80931258e-02  1.26835171e-01 -7.51817090e-02  1.87093917e-02\n",
      "   1.37964984e-01  7.84919038e-02  1.63623152e-02 -1.66376735e-01\n",
      "  -5.07810029e-02  1.00668982e-01  7.77080394e-02  2.13880954e-01\n",
      "  -5.60723714e-03  1.43666382e-01  8.31151878e-03 -6.93119603e-02\n",
      "   1.53964261e-01 -2.79852244e-01 -7.98015056e-03 -3.36578659e-02\n",
      "   1.54297352e-02  1.92342292e-03  2.76204164e-02  3.63443311e-02\n",
      "  -1.93699752e-01  2.97371152e-02 -1.59438024e-01  9.32554491e-02\n",
      "   4.10062000e-02  1.43794672e-01  1.01247426e-01  1.42008285e-01\n",
      "  -5.65965020e-04  7.41322531e-02  1.81867713e-02  1.22504756e-01\n",
      "  -5.17765190e-02  2.58209882e-01 -1.23204667e-01 -5.43300615e-02\n",
      "   7.48580111e-02  1.48382826e-01  8.78432306e-02  4.62325861e-02\n",
      "   7.58706977e-02 -7.28056369e-02 -3.14162672e-02 -1.13304918e-01\n",
      "   3.26019743e-02 -3.84334897e-02 -1.22859411e-02  3.14730674e-01]\n",
      " [-4.80131631e-02 -8.26441211e-02  3.51565294e-02  4.82059761e-02\n",
      "   1.26514427e-03  2.90758954e-02 -8.45265215e-02  8.47292203e-02\n",
      "  -2.31219806e-02  4.12685275e-02  7.08965727e-02 -3.45934858e-02\n",
      "  -1.64690254e-02  1.04865746e-01 -5.87422041e-02  2.06702215e-02\n",
      "   1.03989776e-01  5.71064334e-02 -6.67965979e-03 -1.02780008e-01\n",
      "  -2.27727874e-02  6.96573649e-02  7.75690104e-02  1.41957926e-01\n",
      "   1.90052557e-03  9.20587232e-02 -8.59155172e-03 -4.77016851e-02\n",
      "   7.77329834e-02 -1.73831481e-01  8.60811454e-04 -3.49107695e-02\n",
      "   2.90878667e-02 -9.29671408e-04  9.54249315e-03  2.81055787e-02\n",
      "  -1.17223830e-01  9.52067475e-03 -1.28117154e-01  6.23011586e-02\n",
      "   3.08416992e-02  1.06610543e-01  6.80156158e-02  7.20352321e-02\n",
      "   5.01145698e-03  5.51096977e-02  9.92651625e-03  8.89823586e-02\n",
      "  -4.25400989e-02  1.85727435e-01 -1.12082686e-01 -5.18087273e-02\n",
      "   4.79804886e-02  9.42180442e-02  5.26744674e-02  5.99049140e-02\n",
      "   7.12086384e-02 -4.45745290e-02 -1.80278191e-03 -8.28954466e-02\n",
      "   2.71434427e-02 -5.24369733e-02  2.70138960e-04  1.97279801e-01]\n",
      " [-4.97810948e-02 -8.42667390e-02  4.19431753e-02  5.26293796e-02\n",
      "   9.05896421e-03  2.45266338e-02 -8.55869297e-02  7.71717802e-02\n",
      "  -1.78637765e-02  3.54891175e-02  7.32947458e-02 -3.59097072e-02\n",
      "  -1.97523641e-02  1.11788893e-01 -6.38928730e-02  2.73111758e-02\n",
      "   1.07371427e-01  5.65382056e-02 -6.61946199e-03 -1.04377792e-01\n",
      "  -1.94943048e-02  7.86633911e-02  8.75356570e-02  1.53485367e-01\n",
      "   5.37819992e-03  9.77027826e-02 -1.76403190e-02 -5.03704804e-02\n",
      "   8.67672128e-02 -1.76349727e-01  2.12220324e-03 -3.69948000e-02\n",
      "   3.43352905e-02  1.48812775e-03  1.53860482e-02  2.06183987e-02\n",
      "  -1.28998134e-01  1.26667274e-02 -1.37999106e-01  6.20938931e-02\n",
      "   2.97669093e-02  1.12424858e-01  7.46109644e-02  7.03728152e-02\n",
      "   8.46324931e-03  7.38576688e-02  4.43177589e-03  9.14999079e-02\n",
      "  -3.46804420e-02  1.96999814e-01 -1.09171841e-01 -4.60415967e-02\n",
      "   4.54402780e-02  9.46480092e-02  5.25211571e-02  4.40855208e-02\n",
      "   6.83588386e-02 -5.68176825e-02 -8.77829827e-03 -8.76141917e-02\n",
      "   3.27708898e-02 -4.53019412e-02 -4.68872348e-03  2.02396132e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 7 ====\n",
      "lower bound 129\n",
      "len communities on this batch 3\n",
      "break new community 1\n",
      "break new community 0\n",
      "break new community 2\n",
      "pool subgraph ===  [[-6.44912692e-02 -1.02831191e-01  2.92026286e-02  5.98660644e-02\n",
      "  -2.65858336e-03  3.15278816e-02 -1.01647688e-01  1.07010746e-01\n",
      "  -3.90616474e-02  3.38772630e-02  7.43889894e-02 -4.95265265e-02\n",
      "  -2.83774201e-03  1.15162967e-01 -6.79503764e-02  1.49071283e-02\n",
      "   1.26876295e-01  6.65137917e-02 -1.49749419e-03 -1.24950611e-01\n",
      "  -3.75140347e-02  8.55982538e-02  7.62556153e-02  1.67115859e-01\n",
      "  -6.02360575e-03  1.15716733e-01 -4.63538404e-04 -5.06036111e-02\n",
      "   1.12857911e-01 -2.20664831e-01 -5.11195075e-03 -3.28141430e-02\n",
      "   2.22561198e-02  3.71819066e-03  1.91036037e-02  3.29158546e-02\n",
      "  -1.50916938e-01  1.47401589e-02 -1.40051418e-01  7.52887438e-02\n",
      "   3.29017586e-02  1.22972754e-01  8.05395405e-02  1.01637446e-01\n",
      "   2.12854446e-03  6.31065778e-02  1.20564577e-02  1.02261546e-01\n",
      "  -4.66630246e-02  2.21611381e-01 -1.17412955e-01 -5.96481274e-02\n",
      "   6.38946135e-02  1.12724543e-01  7.38809300e-02  5.64282850e-02\n",
      "   7.41901525e-02 -5.44744357e-02 -1.46502177e-02 -9.53514012e-02\n",
      "   3.07699812e-02 -4.98373711e-02 -8.26872473e-03  2.44626396e-01]\n",
      " [-8.02844693e-02 -1.14929866e-01  2.71980082e-02  6.31175305e-02\n",
      "  -4.82599812e-03  3.12792188e-02 -1.09467278e-01  1.26738546e-01\n",
      "  -4.60123532e-02  2.97993780e-02  7.77186643e-02 -5.90673345e-02\n",
      "   8.90553743e-03  1.20933609e-01 -7.11181858e-02  1.44243578e-02\n",
      "   1.33081144e-01  7.25994977e-02  4.76938351e-03 -1.41473068e-01\n",
      "  -4.34511341e-02  9.13210423e-02  7.66281337e-02  1.84900487e-01\n",
      "  -6.91116157e-03  1.27353672e-01  4.18774521e-03 -5.65386631e-02\n",
      "   1.30820597e-01 -2.45944981e-01 -6.55658964e-03 -3.27598906e-02\n",
      "   1.90470618e-02  3.56778833e-03  2.27227473e-02  3.51061374e-02\n",
      "  -1.67857075e-01  2.12223662e-02 -1.46493516e-01  8.29034177e-02\n",
      "   3.58468130e-02  1.31632208e-01  8.87377513e-02  1.18900292e-01\n",
      "   3.49232377e-04  6.67951669e-02  1.53881640e-02  1.09857616e-01\n",
      "  -4.94586541e-02  2.38045573e-01 -1.20806307e-01 -5.91173741e-02\n",
      "   6.94033304e-02  1.27046886e-01  8.10684812e-02  5.43489856e-02\n",
      "   7.53565986e-02 -6.05728735e-02 -2.11085682e-02 -1.02920756e-01\n",
      "   3.15337532e-02 -4.58293393e-02 -1.00902537e-02  2.73856311e-01]\n",
      " [-5.06498762e-02 -8.70122505e-02  3.39368481e-02  5.52254213e-02\n",
      "   2.95781825e-03  2.91140793e-02 -9.14777773e-02  8.77759638e-02\n",
      "  -3.10900203e-02  4.00199693e-02  6.77588875e-02 -3.59915378e-02\n",
      "  -1.60793758e-02  1.05439828e-01 -6.86770204e-02  1.94598963e-02\n",
      "   1.14790806e-01  6.38030342e-02 -6.74482801e-03 -1.09117935e-01\n",
      "  -2.53991056e-02  7.98981137e-02  7.88080149e-02  1.54596480e-01\n",
      "  -2.56730084e-03  1.02266753e-01 -9.35609705e-03 -4.99507583e-02\n",
      "   1.00107248e-01 -1.92923861e-01 -1.95453343e-04 -3.02231703e-02\n",
      "   2.50053608e-02  3.10445719e-03  1.62781022e-02  2.82300389e-02\n",
      "  -1.31342417e-01  9.98481283e-03 -1.33687492e-01  7.22401653e-02\n",
      "   2.83205714e-02  1.12314713e-01  7.68827998e-02  8.15962755e-02\n",
      "   9.61473651e-03  6.54449676e-02  5.91658092e-03  9.30734905e-02\n",
      "  -4.02826348e-02  1.97167533e-01 -1.12435162e-01 -5.94214967e-02\n",
      "   5.14922089e-02  9.69014721e-02  6.15220357e-02  5.29379951e-02\n",
      "   7.01071519e-02 -5.13733120e-02 -1.26867446e-02 -8.93344017e-02\n",
      "   3.05624258e-02 -4.54881364e-02 -8.82551274e-03  2.12014388e-01]]\n",
      "Pool size  (3, 64)\n",
      "\n",
      "==== BATCH 8 ====\n",
      "lower bound 154\n",
      "len communities on this batch 4\n",
      "break new community 1\n",
      "break new community 0\n",
      "break new community 2\n",
      "break new community 3\n",
      "pool subgraph ===  [[-8.84151869e-02 -1.16517060e-01  2.57166978e-02  5.84009737e-02\n",
      "  -2.64925818e-03  2.67421892e-02 -1.07537214e-01  1.36546414e-01\n",
      "  -4.60859593e-02  2.46627470e-02  7.11291470e-02 -5.94496224e-02\n",
      "   1.62589671e-02  1.13895997e-01 -7.55863003e-02  1.97853781e-02\n",
      "   1.23639818e-01  7.56965969e-02  1.17853782e-02 -1.49260275e-01\n",
      "  -3.99515182e-02  9.19604599e-02  7.66967684e-02  1.94453463e-01\n",
      "  -5.31165954e-03  1.26039673e-01  2.24576896e-03 -6.49815425e-02\n",
      "   1.39259040e-01 -2.48894319e-01 -5.43448515e-03 -3.04724909e-02\n",
      "   1.69428173e-02  6.67657965e-04  2.49330504e-02  3.20536718e-02\n",
      "  -1.70952804e-01  2.34709531e-02 -1.48049168e-01  8.90361778e-02\n",
      "   3.60492393e-02  1.28650539e-01  9.22078900e-02  1.23454656e-01\n",
      "   6.10661018e-03  7.13658929e-02  1.27998325e-02  1.12266704e-01\n",
      "  -4.56271172e-02  2.29565628e-01 -1.17514398e-01 -5.58682196e-02\n",
      "   6.25709817e-02  1.32616401e-01  7.52198026e-02  4.14807890e-02\n",
      "   7.11597651e-02 -6.77525606e-02 -3.10195414e-02 -1.05831325e-01\n",
      "   3.02708037e-02 -3.44827622e-02 -1.29867769e-02  2.79715203e-01]\n",
      " [-6.19284641e-02 -1.22192560e-01  1.69879678e-02  3.36420778e-02\n",
      "   1.00420148e-02  2.92982878e-02 -9.56945587e-02  9.87317264e-02\n",
      "  -4.75789048e-02  2.11327308e-04  3.95534630e-02 -5.35677494e-02\n",
      "   1.71854163e-02  1.20981084e-01 -8.67161117e-02 -8.66032358e-03\n",
      "   9.93128400e-02  1.05160475e-01 -1.57391775e-02 -1.50722183e-01\n",
      "  -6.23876881e-02  6.61912225e-02  7.86208250e-02  1.57404250e-01\n",
      "  -3.09720892e-02  9.26625784e-02  1.26028939e-02 -2.69559552e-02\n",
      "   1.26174968e-01 -2.10598722e-01 -3.76334232e-02 -3.54601010e-02\n",
      "   2.56185783e-02 -3.71895316e-04  1.68233735e-02  2.21241834e-02\n",
      "  -1.57742077e-01  2.44941395e-02 -1.21057257e-01  7.02651143e-02\n",
      "   2.93846577e-02  1.16231291e-01  3.91239957e-02  1.49439352e-01\n",
      "  -1.07318888e-02  4.81366171e-02  2.64945097e-03  1.33659739e-01\n",
      "  -5.67816058e-02  2.21660387e-01 -1.31042162e-01 -6.56326227e-02\n",
      "   6.70678755e-02  1.41348617e-01  8.28227121e-02  6.12793613e-03\n",
      "   9.32772085e-02 -8.46398696e-02 -5.79287168e-02 -1.11887340e-01\n",
      "   1.85799182e-02 -4.15125685e-02 -3.44170472e-02  2.70720836e-01]\n",
      " [-3.86177991e-02 -1.00205552e-01  2.03381870e-02  1.82264671e-02\n",
      "   3.25322701e-02  3.09578292e-02 -8.72291476e-02  7.00375512e-02\n",
      "  -3.28310188e-02  9.65110073e-03  1.71900447e-02 -3.44955828e-02\n",
      "  -2.57341785e-03  1.28035884e-01 -9.71344188e-02 -1.40076326e-02\n",
      "   7.83285573e-02  1.13181196e-01 -3.79904015e-02 -1.23566959e-01\n",
      "  -5.65303322e-02  4.36852761e-02  8.30805711e-02  1.39337778e-01\n",
      "  -3.08017358e-02  7.51539469e-02  2.27702991e-03 -1.41628091e-02\n",
      "   1.08933106e-01 -1.75757244e-01 -5.57885095e-02 -4.26459163e-02\n",
      "   3.14291269e-02  4.50571606e-04  6.63061789e-03  1.72757162e-02\n",
      "  -1.37629554e-01  2.05336995e-02 -1.10486243e-01  5.79382088e-02\n",
      "   2.17674188e-02  1.09936558e-01  9.06419824e-03  1.40220061e-01\n",
      "  -8.50801705e-03  4.16547563e-02 -7.01827405e-03  1.42755806e-01\n",
      "  -4.50542029e-02  2.03885294e-01 -1.41671680e-01 -7.37040974e-02\n",
      "   5.66254314e-02  1.29998293e-01  7.78296739e-02 -9.11010313e-03\n",
      "   1.02849048e-01 -9.02532972e-02 -7.09953457e-02 -1.05356365e-01\n",
      "   2.05768952e-02 -4.49189339e-02 -4.56927568e-02  2.35503718e-01]\n",
      " [ 1.63548840e-02 -6.41699905e-02  5.70329676e-02  5.97710622e-02\n",
      "   2.42154424e-03  4.63693825e-02 -8.84203563e-02  1.84322235e-02\n",
      "   9.87734490e-03  8.44037881e-02  1.07305601e-01 -1.57311264e-02\n",
      "  -8.69241382e-02  1.42295542e-01 -5.05174684e-02  2.69669878e-02\n",
      "   1.34938518e-01  4.13440925e-02 -4.64871811e-02 -6.03221953e-02\n",
      "  -1.24795012e-02  6.64183386e-02  1.11046515e-01  1.09374327e-01\n",
      "   2.52364308e-03  8.79154727e-02 -3.01454042e-02 -2.64909131e-02\n",
      "   1.05851330e-04 -1.23373883e-01  3.45801516e-03 -5.58109097e-02\n",
      "   7.17137853e-02 -2.51505505e-03 -1.34085299e-02  3.60896581e-02\n",
      "  -8.17411840e-02 -2.28951387e-02 -1.53825407e-01  3.59944763e-02\n",
      "   3.29395421e-02  1.19311084e-01  4.67021416e-02  2.20241838e-02\n",
      "   1.49992132e-03  4.92287030e-02  7.43892773e-03  9.71216559e-02\n",
      "  -5.92393614e-02  2.17354586e-01 -1.58788443e-01 -7.74176915e-02\n",
      "   6.14821377e-02  6.60348982e-02  4.49764964e-02  1.15475198e-01\n",
      "   1.06630035e-01 -2.67742338e-02  4.51141869e-02 -8.04208716e-02\n",
      "   3.44970978e-02 -1.20354300e-01  1.69791821e-02  1.44458378e-01]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "==== BATCH 9 ====\n",
      "lower bound 165\n",
      "len communities on this batch 4\n",
      "break new community 0\n",
      "break new community 1\n",
      "break new community 2\n",
      "break new community 3\n",
      "pool subgraph ===  [[-1.26135895e-01 -1.58989776e-01  2.40947655e-02  7.78901931e-02\n",
      "  -1.20984490e-02  3.41387889e-02 -1.40936263e-01  1.88200336e-01\n",
      "  -6.63965102e-02  2.02351296e-02  9.69769862e-02 -9.09150373e-02\n",
      "   4.00732039e-02  1.50051463e-01 -8.33330564e-02  1.52990578e-02\n",
      "   1.64561942e-01  9.23379604e-02  2.05544909e-02 -1.97992444e-01\n",
      "  -6.54853173e-02  1.15947977e-01  8.51929840e-02  2.46855639e-01\n",
      "  -9.57977062e-03  1.70730513e-01  1.74255299e-02 -7.57432953e-02\n",
      "   1.84772655e-01 -3.33313361e-01 -1.21701707e-02 -3.75518445e-02\n",
      "   1.45996499e-02  3.29141907e-03  3.25399237e-02  4.37684953e-02\n",
      "  -2.29690041e-01  3.80762215e-02 -1.79835279e-01  1.07116178e-01\n",
      "   4.75664502e-02  1.68130882e-01  1.16442170e-01  1.74434930e-01\n",
      "  -6.84244744e-03  8.13427130e-02  2.52184756e-02  1.41866537e-01\n",
      "  -6.25228602e-02  3.07329904e-01 -1.42356331e-01 -6.21408718e-02\n",
      "   9.34832823e-02  1.77095503e-01  1.08316099e-01  5.52185886e-02\n",
      "   8.76939818e-02 -8.31855852e-02 -3.57378577e-02 -1.30964391e-01\n",
      "   3.70184560e-02 -4.44250405e-02 -1.35530692e-02  3.75393160e-01]\n",
      " [-1.09750931e-01 -1.38337086e-01  2.09648733e-02  6.77723164e-02\n",
      "  -1.05268682e-02  2.97041933e-02 -1.22628736e-01  1.63753216e-01\n",
      "  -5.77716579e-02  1.76065943e-02  8.43797425e-02 -7.91052158e-02\n",
      "   3.48677138e-02  1.30559877e-01 -7.25081638e-02  1.33117164e-02\n",
      "   1.43185462e-01  8.03433284e-02  1.78844755e-02 -1.72273358e-01\n",
      "  -5.69788292e-02  1.00886419e-01  7.41264795e-02  2.14789276e-01\n",
      "  -8.33538128e-03  1.48552731e-01  1.51619613e-02 -6.59042895e-02\n",
      "   1.60770809e-01 -2.90016204e-01 -1.05892659e-02 -3.26738904e-02\n",
      "   1.27031530e-02  2.86388025e-03  2.83130153e-02  3.80829995e-02\n",
      "  -1.99853465e-01  3.31301522e-02 -1.56474789e-01  9.32018608e-02\n",
      "   4.13876039e-02  1.46290814e-01  1.01316417e-01  1.51775951e-01\n",
      "  -5.95363090e-03  7.07763496e-02  2.19426136e-02  1.23438157e-01\n",
      "  -5.44011891e-02  2.67407979e-01 -1.23864335e-01 -5.40688212e-02\n",
      "   8.13398808e-02  1.54090916e-01  9.42459355e-02  4.80457395e-02\n",
      "   7.63025905e-02 -7.23798176e-02 -3.10955420e-02 -1.13952217e-01\n",
      "   3.22097832e-02 -3.86542641e-02 -1.17925567e-02  3.26629857e-01]\n",
      " [-8.92843474e-02 -1.30980348e-01  2.98365219e-02  7.03118676e-02\n",
      "  -8.00592545e-03  3.46670882e-02 -1.23334987e-01  1.42400854e-01\n",
      "  -4.63450507e-02  3.28295915e-02  9.41156968e-02 -6.99740513e-02\n",
      "   1.08410390e-02  1.40473751e-01 -7.33299069e-02  1.78226370e-02\n",
      "   1.50369631e-01  7.70448688e-02  5.53203002e-03 -1.59183587e-01\n",
      "  -5.03666387e-02  1.00600627e-01  8.69844444e-02  2.06480538e-01\n",
      "  -6.79327012e-03  1.45138290e-01  5.84721123e-03 -6.22281292e-02\n",
      "   1.37264914e-01 -2.72511331e-01 -8.09386838e-03 -3.91877829e-02\n",
      "   2.60298685e-02  2.02306634e-03  2.16558841e-02  3.95703278e-02\n",
      "  -1.87639579e-01  2.26543527e-02 -1.66492008e-01  8.75648391e-02\n",
      "   4.19581523e-02  1.49608418e-01  9.64939939e-02  1.33151117e-01\n",
      "  -3.81411531e-03  7.16518983e-02  1.90964537e-02  1.25539662e-01\n",
      "  -5.80240861e-02  2.72767201e-01 -1.38859339e-01 -6.25935784e-02\n",
      "   8.13796232e-02  1.44634264e-01  8.92765876e-02  6.40360694e-02\n",
      "   8.71705692e-02 -6.77123563e-02 -1.75646599e-02 -1.14152655e-01\n",
      "   3.49003137e-02 -5.78031251e-02 -6.89603807e-03  3.07803247e-01]\n",
      " [-6.43823681e-02 -1.01380389e-01  2.97052845e-02  5.46809311e-02\n",
      "  -5.61067582e-03  3.20433003e-02 -9.72467127e-02  1.07632851e-01\n",
      "  -3.35378367e-02  3.48995812e-02  7.89397980e-02 -5.05432725e-02\n",
      "  -1.05168857e-03  1.17257395e-01 -5.82072027e-02  1.43454357e-02\n",
      "   1.19720116e-01  6.18098459e-02 -9.31584276e-04 -1.21944082e-01\n",
      "  -3.72497359e-02  7.63179008e-02  7.44868293e-02  1.57114780e-01\n",
      "  -2.74958562e-03  1.08886226e-01  2.54243791e-03 -4.77603109e-02\n",
      "   9.47474663e-02 -2.08203447e-01 -4.97441622e-03 -3.72585192e-02\n",
      "   2.55233344e-02 -1.04917097e-04  1.29383476e-02  3.42477858e-02\n",
      "  -1.40526809e-01  1.55449059e-02 -1.34945050e-01  6.66541612e-02\n",
      "   3.59062112e-02  1.19631939e-01  7.30087695e-02  9.69832813e-02\n",
      "  -4.08874413e-03  5.25301571e-02  1.75344377e-02  9.97965199e-02\n",
      "  -5.06311121e-02  2.16056009e-01 -1.19003091e-01 -5.32081580e-02\n",
      "   6.35297323e-02  1.13436559e-01  6.82148263e-02  6.50670553e-02\n",
      "   7.63928990e-02 -4.81258727e-02 -4.10732130e-03 -9.05568178e-02\n",
      "   2.76996354e-02 -5.75795329e-02  6.14459316e-04  2.36917953e-01]]\n",
      "Pool size  (4, 64)\n",
      "\n",
      "\n",
      "====== ALL SUBGRAPH POOLING RESULT ======\n",
      "[[array([-7.13079805e-02, -1.06299196e-01,  2.83601729e-02,  5.57242841e-02,\n",
      "       -5.24456015e-03,  3.03573050e-02, -1.00384892e-01,  1.16899168e-01,\n",
      "       -3.58921189e-02,  3.15075531e-02,  7.81057272e-02, -5.37340463e-02,\n",
      "        4.42506466e-03,  1.16599278e-01, -6.20746617e-02,  1.73391757e-02,\n",
      "        1.21321341e-01,  6.42146282e-02,  3.56211793e-03, -1.30183586e-01,\n",
      "       -3.80475083e-02,  8.14759494e-02,  7.51192719e-02,  1.68375585e-01,\n",
      "       -2.49571478e-03,  1.14458229e-01,  2.42939830e-03, -5.37478190e-02,\n",
      "        1.05898074e-01, -2.19778559e-01, -4.78154444e-03, -3.56793813e-02,\n",
      "        2.34372258e-02, -1.23886944e-04,  1.58505100e-02,  3.34608613e-02,\n",
      "       -1.49960813e-01,  1.71618282e-02, -1.40344288e-01,  7.24917182e-02,\n",
      "        3.63402329e-02,  1.22698031e-01,  7.89134665e-02,  1.03688332e-01,\n",
      "       -1.44760875e-03,  5.81526724e-02,  1.60458458e-02,  1.03602199e-01,\n",
      "       -4.90078963e-02,  2.20424643e-01, -1.18592205e-01, -5.29263592e-02,\n",
      "        6.33594482e-02,  1.19433802e-01,  6.94065415e-02,  5.84633723e-02,\n",
      "        7.48535413e-02, -5.42511345e-02, -1.02321480e-02, -9.43313232e-02,\n",
      "        2.87959212e-02, -5.17806816e-02, -1.81190204e-03,  2.49202600e-01]), array([-0.08989944, -0.12815326,  0.01918437,  0.05411767, -0.0025818 ,\n",
      "        0.02885903, -0.11049936,  0.13633332, -0.05162701,  0.01195832,\n",
      "        0.06596568, -0.0674092 ,  0.02699175,  0.12515809, -0.07602586,\n",
      "        0.0042596 ,  0.12350318,  0.08688978,  0.00514223, -0.15865451,\n",
      "       -0.05688853,  0.08461924,  0.07351512,  0.18899835, -0.01591591,\n",
      "        0.1254045 ,  0.01331255, -0.04981419,  0.1449976 , -0.25462813,\n",
      "       -0.02052468, -0.03330792,  0.01641676,  0.00146257,  0.02338291,\n",
      "        0.03113168, -0.18004669,  0.02913486, -0.13974535,  0.08140143,\n",
      "        0.03540181,  0.13232705,  0.07598461,  0.14781494, -0.00863055,\n",
      "        0.05999284,  0.01440993,  0.1242613 , -0.05307282,  0.24549891,\n",
      "       -0.1247027 , -0.05707384,  0.07487125,  0.1451797 ,  0.08830522,\n",
      "        0.0319481 ,  0.08074333, -0.07475002, -0.04048164, -0.11005805,\n",
      "        0.02638692, -0.03977623, -0.02051848,  0.29832294]), array([-0.07529326, -0.11435069,  0.02710055,  0.06151291, -0.00653679,\n",
      "        0.03108669, -0.10823751,  0.12121485, -0.03991687,  0.02988353,\n",
      "        0.08301245, -0.06010884,  0.00672333,  0.12477842, -0.06474267,\n",
      "        0.01506313,  0.13245302,  0.0684516 ,  0.00259067, -0.13868981,\n",
      "       -0.04417162,  0.08737756,  0.07811899,  0.17917525, -0.0067543 ,\n",
      "        0.12613464,  0.00449986, -0.0527273 ,  0.11777753, -0.23625989,\n",
      "       -0.00769912, -0.03518196,  0.02488481,  0.00141504,  0.01795719,\n",
      "        0.03461564, -0.16301569,  0.01876668, -0.14624982,  0.07556716,\n",
      "        0.03664652,  0.13126507,  0.08257931,  0.11628936, -0.00365854,\n",
      "        0.06209027,  0.01639894,  0.1111395 , -0.05218301,  0.24046105,\n",
      "       -0.1244    , -0.05637705,  0.07218767,  0.12633104,  0.07847109,\n",
      "        0.05726663,  0.0786482 , -0.05939117, -0.01463274, -0.10075462,\n",
      "        0.03038846, -0.05326111, -0.00631678,  0.26828634])], [array([-0.12144645, -0.15307883,  0.02319898,  0.07499442, -0.01164866,\n",
      "        0.0328696 , -0.13569657,  0.1812034 , -0.06392801,  0.01948284,\n",
      "        0.09337158, -0.08753499,  0.03858336,  0.14447287, -0.08023492,\n",
      "        0.01473026,  0.15844384,  0.08890502,  0.0197903 , -0.19063146,\n",
      "       -0.06305069,  0.11163729,  0.0820257 ,  0.23767805, -0.00922363,\n",
      "        0.1643831 ,  0.01677768, -0.0729273 ,  0.17790319, -0.32092146,\n",
      "       -0.01171769, -0.03615575,  0.01405685,  0.00316906,  0.03133016,\n",
      "        0.04214125, -0.22115064,  0.03666062, -0.17314935,  0.10313381,\n",
      "        0.04579801,  0.16188014,  0.1121131 ,  0.16794979, -0.00658807,\n",
      "        0.07831855,  0.02428093,  0.13659222, -0.06019838,  0.29590405,\n",
      "       -0.13706381, -0.05983061,  0.09000779,  0.17051143,  0.10428912,\n",
      "        0.05316568,  0.08443372, -0.08009291, -0.0344092 , -0.1260954 ,\n",
      "        0.03564219, -0.0427734 , -0.01304923,  0.36143678]), array([-0.07478761, -0.11300908,  0.02799896,  0.06156468, -0.00606807,\n",
      "        0.03092885, -0.1076082 ,  0.12144163, -0.03820506,  0.03160288,\n",
      "        0.08352658, -0.05910543,  0.00498984,  0.12392363, -0.06498208,\n",
      "        0.01751267,  0.13180969,  0.06691728,  0.0031194 , -0.13716359,\n",
      "       -0.04194513,  0.08830398,  0.07886571,  0.18020546, -0.00499732,\n",
      "        0.1260018 ,  0.00253249, -0.05509962,  0.11616865, -0.23502565,\n",
      "       -0.00616457, -0.03538097,  0.02520239,  0.00124826,  0.01788523,\n",
      "        0.03468265, -0.1618245 ,  0.017855  , -0.14822338,  0.07633639,\n",
      "        0.03686114,  0.13124739,  0.08413655,  0.11257778, -0.0018566 ,\n",
      "        0.06380007,  0.01584005,  0.1104454 , -0.0508999 ,  0.23832884,\n",
      "       -0.12391591, -0.05614237,  0.07006116,  0.12492912,  0.07612391,\n",
      "        0.05804534,  0.07785358, -0.05911463, -0.0136253 , -0.10018854,\n",
      "        0.03121344, -0.05308251, -0.00532575,  0.26553788]), array([-0.10536694, -0.1328112 ,  0.02012744,  0.06506518, -0.01010639,\n",
      "        0.02851768, -0.11773036,  0.15721209, -0.05546397,  0.01690331,\n",
      "        0.08100919, -0.07594535,  0.03347492,  0.12534465, -0.06961183,\n",
      "        0.01277997,  0.13746591,  0.07713401,  0.01717007, -0.1653919 ,\n",
      "       -0.0547028 ,  0.09685653,  0.07116549,  0.20620951, -0.00800241,\n",
      "        0.14261878,  0.01455632, -0.06327173,  0.15434883, -0.27843147,\n",
      "       -0.01016627, -0.03136872,  0.01219572,  0.00274949,  0.02718206,\n",
      "        0.03656176, -0.19187031,  0.03180675, -0.1502244 ,  0.08947891,\n",
      "        0.03973438,  0.14044721,  0.09726933,  0.14571325, -0.00571579,\n",
      "        0.06794921,  0.02106612,  0.11850742, -0.05222814,  0.25672633,\n",
      "       -0.11891655, -0.05190907,  0.07809076,  0.14793572,  0.09048125,\n",
      "        0.04612653,  0.07325468, -0.06948862, -0.02985342, -0.10940039,\n",
      "        0.03092318, -0.03711021, -0.01132152,  0.3135826 ]), array([-0.07529056, -0.10820412,  0.02954316,  0.06004617, -0.00489263,\n",
      "        0.03211519, -0.10444152,  0.11983059, -0.04245402,  0.03422525,\n",
      "        0.07667367, -0.05409403,  0.00375444,  0.11935922, -0.06706411,\n",
      "        0.01264718,  0.12599914,  0.07074341,  0.00235131, -0.13331052,\n",
      "       -0.03883804,  0.08339804,  0.07586008,  0.17310885, -0.00487573,\n",
      "        0.11897427,  0.00362211, -0.05227326,  0.11776986, -0.23126653,\n",
      "       -0.00524959, -0.03436635,  0.02080553,  0.00201521,  0.01928308,\n",
      "        0.03543396, -0.15470013,  0.02069807, -0.13977725,  0.077718  ,\n",
      "        0.03582571,  0.12625722,  0.08238837,  0.11055264, -0.000771  ,\n",
      "        0.06114331,  0.01745582,  0.10444894, -0.05012827,  0.22761292,\n",
      "       -0.12044835, -0.05793098,  0.065583  ,  0.12184495,  0.07550387,\n",
      "        0.06051153,  0.0762182 , -0.05382964, -0.01468671, -0.09843456,\n",
      "        0.02985408, -0.04958635, -0.00643891,  0.25877117])], [array([-0.10075533, -0.12699844,  0.01924652,  0.06221746, -0.00966405,\n",
      "        0.02726953, -0.11257765,  0.15033141, -0.05303646,  0.01616351,\n",
      "        0.07746366, -0.07262146,  0.03200984,  0.1198587 , -0.06656512,\n",
      "        0.01222065,  0.13144942,  0.07375807,  0.0164186 , -0.15815319,\n",
      "       -0.05230862,  0.09261738,  0.06805078,  0.19718431, -0.00765217,\n",
      "        0.1363768 ,  0.01391925, -0.06050254,  0.14759343, -0.26624537,\n",
      "       -0.0097213 , -0.02999583,  0.01166196,  0.00262914,  0.02599238,\n",
      "        0.03496155, -0.18347272,  0.03041467, -0.14364952,  0.08556269,\n",
      "        0.03799532,  0.13430026,  0.09301216,  0.1393358 , -0.00546563,\n",
      "        0.06497525,  0.02014413,  0.11332068, -0.04994224,  0.24549019,\n",
      "       -0.11371194, -0.04963714,  0.07467296,  0.141461  ,  0.08652115,\n",
      "        0.04410772,  0.07004854, -0.06644731, -0.02854683, -0.10461225,\n",
      "        0.02956976, -0.035486  , -0.01082598,  0.29985803]), array([-0.10996245, -0.13860371,  0.02100528,  0.06790294, -0.01054716,\n",
      "        0.02976144, -0.12286508,  0.16406882, -0.05788301,  0.01764053,\n",
      "        0.08454237, -0.07925767,  0.03493491,  0.1308115 , -0.07264791,\n",
      "        0.01333737,  0.14346142,  0.08049819,  0.01791895, -0.17260538,\n",
      "       -0.05708865,  0.10108085,  0.07426935,  0.21520324, -0.00835145,\n",
      "        0.14883903,  0.01519118, -0.06603131,  0.16108066, -0.29057516,\n",
      "       -0.01060967, -0.03273686,  0.01272764,  0.0028694 ,  0.02836758,\n",
      "        0.03815639, -0.20023864,  0.033194  , -0.15677636,  0.09338149,\n",
      "        0.04146737,  0.14657276,  0.10151168,  0.15206846, -0.00596511,\n",
      "        0.07091275,  0.0219849 ,  0.12367606, -0.05450604,  0.26792336,\n",
      "       -0.12410306, -0.05417303,  0.08149665,  0.1543879 ,  0.09442758,\n",
      "        0.04813834,  0.07644965, -0.07251931, -0.03115548, -0.11417184,\n",
      "        0.03227186, -0.03872876, -0.01181528,  0.32725937]), array([-0.07930576, -0.11497914,  0.02820391,  0.06392096, -0.00440765,\n",
      "        0.03198102, -0.11031344,  0.12593274, -0.04591544,  0.03133508,\n",
      "        0.07849711, -0.05837317,  0.00684081,  0.1222322 , -0.072336  ,\n",
      "        0.01473127,  0.13458309,  0.07329399,  0.00378241, -0.14147495,\n",
      "       -0.04304416,  0.09215255,  0.07816776,  0.18574205, -0.00691601,\n",
      "        0.1278495 ,  0.00335859, -0.05676414,  0.130799  , -0.24673222,\n",
      "       -0.00629508, -0.03324921,  0.01983656,  0.00376363,  0.02270384,\n",
      "        0.03549595, -0.16816804,  0.02065557, -0.1482101 ,  0.08356941,\n",
      "        0.03602049,  0.13273509,  0.08932717,  0.11833143,  0.00091777,\n",
      "        0.0677267 ,  0.01512465,  0.11062265, -0.04996543,  0.23982674,\n",
      "       -0.12265789, -0.06064217,  0.06960489,  0.12702222,  0.08145715,\n",
      "        0.05580778,  0.07658243, -0.06066876, -0.02072472, -0.10390984,\n",
      "        0.03200495, -0.04722512, -0.01022892,  0.27432915])], [array([-0.1151654 , -0.14516181,  0.02199917,  0.07111583, -0.01104623,\n",
      "        0.03116964, -0.12867854,  0.17183181, -0.06062175,  0.0184752 ,\n",
      "        0.08854252, -0.08300779,  0.03658788,  0.13700091, -0.0760853 ,\n",
      "        0.01396841,  0.15024938,  0.08430698,  0.01876676, -0.18077227,\n",
      "       -0.05978981,  0.10586359,  0.07778342,  0.22538568, -0.00874659,\n",
      "        0.15588142,  0.01590996, -0.06915558,  0.16870231, -0.30432385,\n",
      "       -0.01111165, -0.03428581,  0.01332983,  0.00300519,  0.02970983,\n",
      "        0.03996177, -0.20971302,  0.03476458, -0.16419431,  0.09779988,\n",
      "        0.04342941,  0.15350791,  0.10631476,  0.15926366, -0.00624733,\n",
      "        0.07426805,  0.02302513,  0.12952787, -0.05708502,  0.28060026,\n",
      "       -0.12997504, -0.05673629,  0.08535272,  0.16169282,  0.09889544,\n",
      "        0.05041602,  0.08006692, -0.07595062, -0.0326296 , -0.11957394,\n",
      "        0.03379885, -0.04056122, -0.01237436,  0.34274382]), array([-0.07778822, -0.1101656 ,  0.02531034,  0.05696518, -0.0071211 ,\n",
      "        0.0298418 , -0.102074  ,  0.12297589, -0.04074887,  0.02723526,\n",
      "        0.0774537 , -0.05853335,  0.01179387,  0.11691902, -0.06078548,\n",
      "        0.01334209,  0.12286889,  0.06572919,  0.00580095, -0.13458084,\n",
      "       -0.04267946,  0.08176781,  0.07113184,  0.17086788, -0.00462249,\n",
      "        0.11830395,  0.0069116 , -0.05214972,  0.11415539, -0.22835467,\n",
      "       -0.00677508, -0.03404611,  0.0198489 ,  0.00096426,  0.01786599,\n",
      "        0.03414238, -0.15559481,  0.02115796, -0.13677643,  0.07321801,\n",
      "        0.03632514,  0.1239773 ,  0.07991696,  0.11232103, -0.0045821 ,\n",
      "        0.05673849,  0.01837038,  0.10392062, -0.04979619,  0.22500526,\n",
      "       -0.11555265, -0.05119148,  0.06713326,  0.12300126,  0.07456888,\n",
      "        0.05619866,  0.0730671 , -0.05466188, -0.01357318, -0.09498261,\n",
      "        0.02809633, -0.04836388, -0.00386139,  0.2586469 ]), array([-0.07330108, -0.11113535,  0.02771501,  0.06064675, -0.00592551,\n",
      "        0.03052651, -0.10594726,  0.11922365, -0.03742257,  0.03136441,\n",
      "        0.08238368, -0.05803398,  0.00451757,  0.12215524, -0.06399999,\n",
      "        0.01733237,  0.12987029,  0.06582906,  0.00287716, -0.13483019,\n",
      "       -0.04117337,  0.0869375 ,  0.07786169,  0.17729623, -0.00488442,\n",
      "        0.12398969,  0.00232713, -0.05420696,  0.11399105, -0.23109748,\n",
      "       -0.00602113, -0.03493841,  0.02503034,  0.00120946,  0.01750174,\n",
      "        0.03416683, -0.15911756,  0.01740626, -0.14610397,  0.075074  ,\n",
      "        0.03630054,  0.12926592,  0.08276426,  0.11052203, -0.00177598,\n",
      "        0.06284143,  0.01554283,  0.10877347, -0.05016305,  0.23470687,\n",
      "       -0.12223821, -0.05541003,  0.06895944,  0.12284201,  0.07484737,\n",
      "        0.05739457,  0.07682009, -0.05813427, -0.01320412, -0.0986451 ,\n",
      "        0.03077718, -0.05255894, -0.00516605,  0.26111382]), array([-0.10967193, -0.13823751,  0.02094978,  0.06772354, -0.01051929,\n",
      "        0.02968282, -0.12254047,  0.16363535, -0.05773007,  0.01759392,\n",
      "        0.084319  , -0.07904828,  0.03484262,  0.13046589, -0.07245597,\n",
      "        0.01330213,  0.14308239,  0.08028549,  0.0178716 , -0.17214936,\n",
      "       -0.05693781,  0.1008138 ,  0.07407312,  0.21463466, -0.00832938,\n",
      "        0.1484458 ,  0.01515105, -0.06585685,  0.16065508, -0.28980745,\n",
      "       -0.01058165, -0.03265037,  0.01269401,  0.00286181,  0.02829263,\n",
      "        0.03805558, -0.19970961,  0.03310631, -0.15636215,  0.09313477,\n",
      "        0.04135781,  0.14618552,  0.10124348,  0.15166669, -0.00594935,\n",
      "        0.0707254 ,  0.02192682,  0.12334931, -0.05436203,  0.26721551,\n",
      "       -0.12377518, -0.0540299 ,  0.08128133,  0.15398   ,  0.09417809,\n",
      "        0.04801115,  0.07624767, -0.07232771, -0.03107316, -0.11387019,\n",
      "        0.03218659, -0.03862644, -0.01178407,  0.32639473])], [array([-0.12438482, -0.15701328,  0.02404017,  0.07687972, -0.01175792,\n",
      "        0.03372444, -0.13930473,  0.18583604, -0.06524796,  0.0202592 ,\n",
      "        0.09571619, -0.08951058,  0.03913868,  0.14810083, -0.08287137,\n",
      "        0.01563578,  0.16248045,  0.09121355,  0.02036873, -0.19561041,\n",
      "       -0.06427548,  0.11486074,  0.08471132,  0.24426067, -0.00930866,\n",
      "        0.16854516,  0.01676673, -0.07534931,  0.1823399 , -0.32915823,\n",
      "       -0.01176664, -0.03724034,  0.01464782,  0.00318214,  0.03221811,\n",
      "        0.04309149, -0.22692735,  0.03724798, -0.17846226,  0.10622008,\n",
      "        0.04703882,  0.16613596,  0.11527734,  0.17171933, -0.00618536,\n",
      "        0.08090845,  0.02449785,  0.14031463, -0.06150161,  0.30332376,\n",
      "       -0.1409312 , -0.06169868,  0.09184197,  0.17494637,  0.10647429,\n",
      "        0.05435608,  0.08679784, -0.08243522, -0.03535787, -0.12954224,\n",
      "        0.03663695, -0.04387803, -0.01334117,  0.37069006]), array([-0.06771102, -0.10970968,  0.02996698,  0.06187705, -0.00586738,\n",
      "        0.03238635, -0.10661883,  0.11313622, -0.03471745,  0.03558767,\n",
      "        0.08597464, -0.05635506, -0.00188407,  0.12614725, -0.06337583,\n",
      "        0.01727719,  0.13293184,  0.06487339, -0.00108585, -0.13116807,\n",
      "       -0.04053309,  0.08645194,  0.08116749,  0.17412922, -0.00500816,\n",
      "        0.12359532,  0.0007483 , -0.05179759,  0.10706111, -0.22686604,\n",
      "       -0.0058343 , -0.03707323,  0.02887247,  0.001183  ,  0.01544643,\n",
      "        0.03505894, -0.15596945,  0.0148596 , -0.14824445,  0.07267183,\n",
      "        0.03661249,  0.13074342,  0.08073678,  0.10627124, -0.00252921,\n",
      "        0.06203127,  0.01557557,  0.10943539, -0.05204214,  0.23812083,\n",
      "       -0.12684891, -0.05786478,  0.07042811,  0.12050235,  0.07465744,\n",
      "        0.06319834,  0.08051187, -0.0560571 , -0.00856346, -0.09858328,\n",
      "        0.03136076, -0.05909672, -0.00357718,  0.25687932]), array([ 0.01544035, -0.04967002,  0.05004571,  0.04473024,  0.00181519,\n",
      "        0.04241109, -0.06795372,  0.01447108,  0.00465634,  0.07154238,\n",
      "        0.08501245, -0.00842345, -0.07273645,  0.1159243 , -0.039589  ,\n",
      "        0.01816194,  0.10599623,  0.03509707, -0.04027747, -0.04627609,\n",
      "       -0.0108348 ,  0.04793302,  0.08838274,  0.07748513,  0.00511849,\n",
      "        0.06032161, -0.02178599, -0.01876434, -0.00977589, -0.09402115,\n",
      "        0.00316078, -0.05063286,  0.05631031, -0.00246794, -0.01382865,\n",
      "        0.03159172, -0.05857577, -0.01755465, -0.12020541,  0.02612767,\n",
      "        0.02887377,  0.09338841,  0.03371452,  0.01237269, -0.00190453,\n",
      "        0.03132051,  0.01026176,  0.07517   , -0.05196005,  0.16861392,\n",
      "       -0.13087291, -0.06430523,  0.04850524,  0.0533221 ,  0.0360131 ,\n",
      "        0.10548917,  0.09000782, -0.01537151,  0.04462958, -0.06223239,\n",
      "        0.02585027, -0.10427986,  0.02030825,  0.11081228]), array([-0.04266112, -0.07937654,  0.03408973,  0.04610954, -0.0002247 ,\n",
      "        0.02910334, -0.08102975,  0.07863332, -0.01983273,  0.0405066 ,\n",
      "        0.07157818, -0.03362464, -0.01749638,  0.10397982, -0.05266188,\n",
      "        0.0189754 ,  0.10166631,  0.05279272, -0.00825854, -0.09693667,\n",
      "       -0.02327745,  0.06507502,  0.07465219,  0.1316806 ,  0.00212927,\n",
      "        0.08760233, -0.00695166, -0.04292274,  0.06728153, -0.16299631,\n",
      "        0.00018974, -0.03546991,  0.03032009, -0.00159128,  0.00630817,\n",
      "        0.02770339, -0.11005337,  0.00770609, -0.12299909,  0.0557967 ,\n",
      "        0.03045044,  0.10280071,  0.06221536,  0.06723919,  0.00156294,\n",
      "        0.04928275,  0.01090657,  0.08564263, -0.0430221 ,  0.18061572,\n",
      "       -0.11049011, -0.04942794,  0.04868149,  0.09049091,  0.05071135,\n",
      "        0.06260892,  0.07107735, -0.04091807,  0.00428937, -0.07786775,\n",
      "        0.02571839, -0.05654794,  0.00390945,  0.18661727])], [array([-0.09600318, -0.12320472,  0.02387209,  0.062078  , -0.0057293 ,\n",
      "        0.02748483, -0.11242087,  0.14661277, -0.04937686,  0.02278885,\n",
      "        0.07642018, -0.06633225,  0.0228461 ,  0.11888048, -0.07336942,\n",
      "        0.01840862,  0.1306556 ,  0.07572515,  0.01479097, -0.15598486,\n",
      "       -0.0449645 ,  0.09529797,  0.07481033,  0.20136737, -0.00533233,\n",
      "        0.13428924,  0.00662362, -0.06630489,  0.1462414 , -0.26284722,\n",
      "       -0.0062384 , -0.03057907,  0.01472148,  0.00175201,  0.02611302,\n",
      "        0.03433074, -0.18020807,  0.02663437, -0.1507987 ,  0.09046717,\n",
      "        0.03770706,  0.13442842,  0.09657163,  0.13128513,  0.00215801,\n",
      "        0.0715681 ,  0.01608665,  0.1144436 , -0.04770635,  0.24134946,\n",
      "       -0.11840198, -0.05444699,  0.06826667,  0.13885608,  0.0808443 ,\n",
      "        0.04452474,  0.07141651, -0.06841658, -0.02975559, -0.10741046,\n",
      "        0.031472  , -0.03532218, -0.01137375,  0.29419413]), array([-0.04603344, -0.10082983,  0.0389743 ,  0.06361131, -0.00374329,\n",
      "        0.03781396, -0.10559234,  0.09035339, -0.02358858,  0.05093199,\n",
      "        0.09539889, -0.04678536, -0.02634474,  0.13575678, -0.06209148,\n",
      "        0.02064349,  0.13907607,  0.06079854, -0.01423545, -0.1160794 ,\n",
      "       -0.03422673,  0.08397836,  0.09262471,  0.16211729, -0.00306315,\n",
      "        0.11802127, -0.00783151, -0.0465479 ,  0.08060391, -0.20632162,\n",
      "       -0.00343578, -0.04400267,  0.04205298,  0.00041271,  0.00762898,\n",
      "        0.03664751, -0.14083244,  0.00455288, -0.15546121,  0.06497801,\n",
      "        0.03692595,  0.13250571,  0.07431967,  0.08622686, -0.00162168,\n",
      "        0.06042738,  0.01384513,  0.10999573, -0.05622069,  0.24152974,\n",
      "       -0.14126144, -0.06601841,  0.07079712,  0.10960519,  0.06933676,\n",
      "        0.08096319,  0.09116847, -0.04979933,  0.00664475, -0.09712116,\n",
      "        0.03333407, -0.07913559,  0.00249949,  0.23483633]), array([-0.09579358, -0.13448275,  0.02215793,  0.0604322 , -0.00510524,\n",
      "        0.02957397, -0.11024943,  0.14255376, -0.05736396,  0.02281703,\n",
      "        0.07994399, -0.0716917 ,  0.03495627,  0.11876574, -0.06509182,\n",
      "        0.0048264 ,  0.13283131,  0.07831761,  0.00924301, -0.16012888,\n",
      "       -0.06012723,  0.09665844,  0.0676895 ,  0.19754427, -0.01047917,\n",
      "        0.13033762,  0.01755907, -0.06040132,  0.14088497, -0.26569044,\n",
      "       -0.01214755, -0.03239205,  0.00807594,  0.00417712,  0.0296757 ,\n",
      "        0.04041317, -0.18512483,  0.03003033, -0.13840694,  0.08385815,\n",
      "        0.04151006,  0.13662172,  0.09452868,  0.13640863,  0.00378047,\n",
      "        0.06519101,  0.01986448,  0.1097678 , -0.05887891,  0.24360671,\n",
      "       -0.11696799, -0.05471904,  0.07001857,  0.13404349,  0.08328125,\n",
      "        0.05410295,  0.07498621, -0.0651009 , -0.02256185, -0.10538482,\n",
      "        0.03010058, -0.03324641, -0.00653899,  0.30130491])], [array([-0.10451517, -0.13270378,  0.02430863,  0.06514592, -0.00763988,\n",
      "        0.02904274, -0.11922182,  0.15745378, -0.05336124,  0.02152224,\n",
      "        0.08218652, -0.07274114,  0.02809313,  0.12683517, -0.07518171,\n",
      "        0.01870939,  0.13796498,  0.0784919 ,  0.01636232, -0.16637673,\n",
      "       -0.050781  ,  0.10066898,  0.07770804,  0.21388095, -0.00560724,\n",
      "        0.14366638,  0.00831152, -0.06931196,  0.15396426, -0.27985224,\n",
      "       -0.00798015, -0.03365787,  0.01542974,  0.00192342,  0.02762042,\n",
      "        0.03634433, -0.19369975,  0.02973712, -0.15943802,  0.09325545,\n",
      "        0.0410062 ,  0.14379467,  0.10124743,  0.14200828, -0.00056597,\n",
      "        0.07413225,  0.01818677,  0.12250476, -0.05177652,  0.25820988,\n",
      "       -0.12320467, -0.05433006,  0.07485801,  0.14838283,  0.08784323,\n",
      "        0.04623259,  0.0758707 , -0.07280564, -0.03141627, -0.11330492,\n",
      "        0.03260197, -0.03843349, -0.01228594,  0.31473067]), array([-0.04801316, -0.08264412,  0.03515653,  0.04820598,  0.00126514,\n",
      "        0.0290759 , -0.08452652,  0.08472922, -0.02312198,  0.04126853,\n",
      "        0.07089657, -0.03459349, -0.01646903,  0.10486575, -0.0587422 ,\n",
      "        0.02067022,  0.10398978,  0.05710643, -0.00667966, -0.10278001,\n",
      "       -0.02277279,  0.06965736,  0.07756901,  0.14195793,  0.00190053,\n",
      "        0.09205872, -0.00859155, -0.04770169,  0.07773298, -0.17383148,\n",
      "        0.00086081, -0.03491077,  0.02908787, -0.00092967,  0.00954249,\n",
      "        0.02810558, -0.11722383,  0.00952067, -0.12811715,  0.06230116,\n",
      "        0.0308417 ,  0.10661054,  0.06801562,  0.07203523,  0.00501146,\n",
      "        0.0551097 ,  0.00992652,  0.08898236, -0.0425401 ,  0.18572743,\n",
      "       -0.11208269, -0.05180873,  0.04798049,  0.09421804,  0.05267447,\n",
      "        0.05990491,  0.07120864, -0.04457453, -0.00180278, -0.08289545,\n",
      "        0.02714344, -0.05243697,  0.00027014,  0.1972798 ]), array([-0.04978109, -0.08426674,  0.04194318,  0.05262938,  0.00905896,\n",
      "        0.02452663, -0.08558693,  0.07717178, -0.01786378,  0.03548912,\n",
      "        0.07329475, -0.03590971, -0.01975236,  0.11178889, -0.06389287,\n",
      "        0.02731118,  0.10737143,  0.05653821, -0.00661946, -0.10437779,\n",
      "       -0.0194943 ,  0.07866339,  0.08753566,  0.15348537,  0.0053782 ,\n",
      "        0.09770278, -0.01764032, -0.05037048,  0.08676721, -0.17634973,\n",
      "        0.0021222 , -0.0369948 ,  0.03433529,  0.00148813,  0.01538605,\n",
      "        0.0206184 , -0.12899813,  0.01266673, -0.13799911,  0.06209389,\n",
      "        0.02976691,  0.11242486,  0.07461096,  0.07037282,  0.00846325,\n",
      "        0.07385767,  0.00443178,  0.09149991, -0.03468044,  0.19699981,\n",
      "       -0.10917184, -0.0460416 ,  0.04544028,  0.09464801,  0.05252116,\n",
      "        0.04408552,  0.06835884, -0.05681768, -0.0087783 , -0.08761419,\n",
      "        0.03277089, -0.04530194, -0.00468872,  0.20239613])], [array([-0.06449127, -0.10283119,  0.02920263,  0.05986606, -0.00265858,\n",
      "        0.03152788, -0.10164769,  0.10701075, -0.03906165,  0.03387726,\n",
      "        0.07438899, -0.04952653, -0.00283774,  0.11516297, -0.06795038,\n",
      "        0.01490713,  0.12687629,  0.06651379, -0.00149749, -0.12495061,\n",
      "       -0.03751403,  0.08559825,  0.07625562,  0.16711586, -0.00602361,\n",
      "        0.11571673, -0.00046354, -0.05060361,  0.11285791, -0.22066483,\n",
      "       -0.00511195, -0.03281414,  0.02225612,  0.00371819,  0.0191036 ,\n",
      "        0.03291585, -0.15091694,  0.01474016, -0.14005142,  0.07528874,\n",
      "        0.03290176,  0.12297275,  0.08053954,  0.10163745,  0.00212854,\n",
      "        0.06310658,  0.01205646,  0.10226155, -0.04666302,  0.22161138,\n",
      "       -0.11741295, -0.05964813,  0.06389461,  0.11272454,  0.07388093,\n",
      "        0.05642829,  0.07419015, -0.05447444, -0.01465022, -0.0953514 ,\n",
      "        0.03076998, -0.04983737, -0.00826872,  0.2446264 ]), array([-0.08028447, -0.11492987,  0.02719801,  0.06311753, -0.004826  ,\n",
      "        0.03127922, -0.10946728,  0.12673855, -0.04601235,  0.02979938,\n",
      "        0.07771866, -0.05906733,  0.00890554,  0.12093361, -0.07111819,\n",
      "        0.01442436,  0.13308114,  0.0725995 ,  0.00476938, -0.14147307,\n",
      "       -0.04345113,  0.09132104,  0.07662813,  0.18490049, -0.00691116,\n",
      "        0.12735367,  0.00418775, -0.05653866,  0.1308206 , -0.24594498,\n",
      "       -0.00655659, -0.03275989,  0.01904706,  0.00356779,  0.02272275,\n",
      "        0.03510614, -0.16785708,  0.02122237, -0.14649352,  0.08290342,\n",
      "        0.03584681,  0.13163221,  0.08873775,  0.11890029,  0.00034923,\n",
      "        0.06679517,  0.01538816,  0.10985762, -0.04945865,  0.23804557,\n",
      "       -0.12080631, -0.05911737,  0.06940333,  0.12704689,  0.08106848,\n",
      "        0.05434899,  0.0753566 , -0.06057287, -0.02110857, -0.10292076,\n",
      "        0.03153375, -0.04582934, -0.01009025,  0.27385631]), array([-5.06498762e-02, -8.70122505e-02,  3.39368481e-02,  5.52254213e-02,\n",
      "        2.95781825e-03,  2.91140793e-02, -9.14777773e-02,  8.77759638e-02,\n",
      "       -3.10900203e-02,  4.00199693e-02,  6.77588875e-02, -3.59915378e-02,\n",
      "       -1.60793758e-02,  1.05439828e-01, -6.86770204e-02,  1.94598963e-02,\n",
      "        1.14790806e-01,  6.38030342e-02, -6.74482801e-03, -1.09117935e-01,\n",
      "       -2.53991056e-02,  7.98981137e-02,  7.88080149e-02,  1.54596480e-01,\n",
      "       -2.56730084e-03,  1.02266753e-01, -9.35609705e-03, -4.99507583e-02,\n",
      "        1.00107248e-01, -1.92923861e-01, -1.95453343e-04, -3.02231703e-02,\n",
      "        2.50053608e-02,  3.10445719e-03,  1.62781022e-02,  2.82300389e-02,\n",
      "       -1.31342417e-01,  9.98481283e-03, -1.33687492e-01,  7.22401653e-02,\n",
      "        2.83205714e-02,  1.12314713e-01,  7.68827998e-02,  8.15962755e-02,\n",
      "        9.61473651e-03,  6.54449676e-02,  5.91658092e-03,  9.30734905e-02,\n",
      "       -4.02826348e-02,  1.97167533e-01, -1.12435162e-01, -5.94214967e-02,\n",
      "        5.14922089e-02,  9.69014721e-02,  6.15220357e-02,  5.29379951e-02,\n",
      "        7.01071519e-02, -5.13733120e-02, -1.26867446e-02, -8.93344017e-02,\n",
      "        3.05624258e-02, -4.54881364e-02, -8.82551274e-03,  2.12014388e-01])], [array([-0.08841519, -0.11651706,  0.0257167 ,  0.05840097, -0.00264926,\n",
      "        0.02674219, -0.10753721,  0.13654641, -0.04608596,  0.02466275,\n",
      "        0.07112915, -0.05944962,  0.01625897,  0.113896  , -0.0755863 ,\n",
      "        0.01978538,  0.12363982,  0.0756966 ,  0.01178538, -0.14926028,\n",
      "       -0.03995152,  0.09196046,  0.07669677,  0.19445346, -0.00531166,\n",
      "        0.12603967,  0.00224577, -0.06498154,  0.13925904, -0.24889432,\n",
      "       -0.00543449, -0.03047249,  0.01694282,  0.00066766,  0.02493305,\n",
      "        0.03205367, -0.1709528 ,  0.02347095, -0.14804917,  0.08903618,\n",
      "        0.03604924,  0.12865054,  0.09220789,  0.12345466,  0.00610661,\n",
      "        0.07136589,  0.01279983,  0.1122667 , -0.04562712,  0.22956563,\n",
      "       -0.1175144 , -0.05586822,  0.06257098,  0.1326164 ,  0.0752198 ,\n",
      "        0.04148079,  0.07115977, -0.06775256, -0.03101954, -0.10583133,\n",
      "        0.0302708 , -0.03448276, -0.01298678,  0.2797152 ]), array([-6.19284641e-02, -1.22192560e-01,  1.69879678e-02,  3.36420778e-02,\n",
      "        1.00420148e-02,  2.92982878e-02, -9.56945587e-02,  9.87317264e-02,\n",
      "       -4.75789048e-02,  2.11327308e-04,  3.95534630e-02, -5.35677494e-02,\n",
      "        1.71854163e-02,  1.20981084e-01, -8.67161117e-02, -8.66032358e-03,\n",
      "        9.93128400e-02,  1.05160475e-01, -1.57391775e-02, -1.50722183e-01,\n",
      "       -6.23876881e-02,  6.61912225e-02,  7.86208250e-02,  1.57404250e-01,\n",
      "       -3.09720892e-02,  9.26625784e-02,  1.26028939e-02, -2.69559552e-02,\n",
      "        1.26174968e-01, -2.10598722e-01, -3.76334232e-02, -3.54601010e-02,\n",
      "        2.56185783e-02, -3.71895316e-04,  1.68233735e-02,  2.21241834e-02,\n",
      "       -1.57742077e-01,  2.44941395e-02, -1.21057257e-01,  7.02651143e-02,\n",
      "        2.93846577e-02,  1.16231291e-01,  3.91239957e-02,  1.49439352e-01,\n",
      "       -1.07318888e-02,  4.81366171e-02,  2.64945097e-03,  1.33659739e-01,\n",
      "       -5.67816058e-02,  2.21660387e-01, -1.31042162e-01, -6.56326227e-02,\n",
      "        6.70678755e-02,  1.41348617e-01,  8.28227121e-02,  6.12793613e-03,\n",
      "        9.32772085e-02, -8.46398696e-02, -5.79287168e-02, -1.11887340e-01,\n",
      "        1.85799182e-02, -4.15125685e-02, -3.44170472e-02,  2.70720836e-01]), array([-0.0386178 , -0.10020555,  0.02033819,  0.01822647,  0.03253227,\n",
      "        0.03095783, -0.08722915,  0.07003755, -0.03283102,  0.0096511 ,\n",
      "        0.01719004, -0.03449558, -0.00257342,  0.12803588, -0.09713442,\n",
      "       -0.01400763,  0.07832856,  0.1131812 , -0.0379904 , -0.12356696,\n",
      "       -0.05653033,  0.04368528,  0.08308057,  0.13933778, -0.03080174,\n",
      "        0.07515395,  0.00227703, -0.01416281,  0.10893311, -0.17575724,\n",
      "       -0.05578851, -0.04264592,  0.03142913,  0.00045057,  0.00663062,\n",
      "        0.01727572, -0.13762955,  0.0205337 , -0.11048624,  0.05793821,\n",
      "        0.02176742,  0.10993656,  0.0090642 ,  0.14022006, -0.00850802,\n",
      "        0.04165476, -0.00701827,  0.14275581, -0.0450542 ,  0.20388529,\n",
      "       -0.14167168, -0.0737041 ,  0.05662543,  0.12999829,  0.07782967,\n",
      "       -0.0091101 ,  0.10284905, -0.0902533 , -0.07099535, -0.10535637,\n",
      "        0.0205769 , -0.04491893, -0.04569276,  0.23550372]), array([ 1.63548840e-02, -6.41699905e-02,  5.70329676e-02,  5.97710622e-02,\n",
      "        2.42154424e-03,  4.63693825e-02, -8.84203563e-02,  1.84322235e-02,\n",
      "        9.87734490e-03,  8.44037881e-02,  1.07305601e-01, -1.57311264e-02,\n",
      "       -8.69241382e-02,  1.42295542e-01, -5.05174684e-02,  2.69669878e-02,\n",
      "        1.34938518e-01,  4.13440925e-02, -4.64871811e-02, -6.03221953e-02,\n",
      "       -1.24795012e-02,  6.64183386e-02,  1.11046515e-01,  1.09374327e-01,\n",
      "        2.52364308e-03,  8.79154727e-02, -3.01454042e-02, -2.64909131e-02,\n",
      "        1.05851330e-04, -1.23373883e-01,  3.45801516e-03, -5.58109097e-02,\n",
      "        7.17137853e-02, -2.51505505e-03, -1.34085299e-02,  3.60896581e-02,\n",
      "       -8.17411840e-02, -2.28951387e-02, -1.53825407e-01,  3.59944763e-02,\n",
      "        3.29395421e-02,  1.19311084e-01,  4.67021416e-02,  2.20241838e-02,\n",
      "        1.49992132e-03,  4.92287030e-02,  7.43892773e-03,  9.71216559e-02,\n",
      "       -5.92393614e-02,  2.17354586e-01, -1.58788443e-01, -7.74176915e-02,\n",
      "        6.14821377e-02,  6.60348982e-02,  4.49764964e-02,  1.15475198e-01,\n",
      "        1.06630035e-01, -2.67742338e-02,  4.51141869e-02, -8.04208716e-02,\n",
      "        3.44970978e-02, -1.20354300e-01,  1.69791821e-02,  1.44458378e-01])], [array([-0.1261359 , -0.15898978,  0.02409477,  0.07789019, -0.01209845,\n",
      "        0.03413879, -0.14093626,  0.18820034, -0.06639651,  0.02023513,\n",
      "        0.09697699, -0.09091504,  0.0400732 ,  0.15005146, -0.08333306,\n",
      "        0.01529906,  0.16456194,  0.09233796,  0.02055449, -0.19799244,\n",
      "       -0.06548532,  0.11594798,  0.08519298,  0.24685564, -0.00957977,\n",
      "        0.17073051,  0.01742553, -0.0757433 ,  0.18477266, -0.33331336,\n",
      "       -0.01217017, -0.03755184,  0.01459965,  0.00329142,  0.03253992,\n",
      "        0.0437685 , -0.22969004,  0.03807622, -0.17983528,  0.10711618,\n",
      "        0.04756645,  0.16813088,  0.11644217,  0.17443493, -0.00684245,\n",
      "        0.08134271,  0.02521848,  0.14186654, -0.06252286,  0.3073299 ,\n",
      "       -0.14235633, -0.06214087,  0.09348328,  0.1770955 ,  0.1083161 ,\n",
      "        0.05521859,  0.08769398, -0.08318559, -0.03573786, -0.13096439,\n",
      "        0.03701846, -0.04442504, -0.01355307,  0.37539316]), array([-0.10975093, -0.13833709,  0.02096487,  0.06777232, -0.01052687,\n",
      "        0.02970419, -0.12262874,  0.16375322, -0.05777166,  0.01760659,\n",
      "        0.08437974, -0.07910522,  0.03486771,  0.13055988, -0.07250816,\n",
      "        0.01331172,  0.14318546,  0.08034333,  0.01788448, -0.17227336,\n",
      "       -0.05697883,  0.10088642,  0.07412648,  0.21478928, -0.00833538,\n",
      "        0.14855273,  0.01516196, -0.06590429,  0.16077081, -0.2900162 ,\n",
      "       -0.01058927, -0.03267389,  0.01270315,  0.00286388,  0.02831302,\n",
      "        0.038083  , -0.19985346,  0.03313015, -0.15647479,  0.09320186,\n",
      "        0.0413876 ,  0.14629081,  0.10131642,  0.15177595, -0.00595363,\n",
      "        0.07077635,  0.02194261,  0.12343816, -0.05440119,  0.26740798,\n",
      "       -0.12386434, -0.05406882,  0.08133988,  0.15409092,  0.09424594,\n",
      "        0.04804574,  0.07630259, -0.07237982, -0.03109554, -0.11395222,\n",
      "        0.03220978, -0.03865426, -0.01179256,  0.32662986]), array([-0.08928435, -0.13098035,  0.02983652,  0.07031187, -0.00800593,\n",
      "        0.03466709, -0.12333499,  0.14240085, -0.04634505,  0.03282959,\n",
      "        0.0941157 , -0.06997405,  0.01084104,  0.14047375, -0.07332991,\n",
      "        0.01782264,  0.15036963,  0.07704487,  0.00553203, -0.15918359,\n",
      "       -0.05036664,  0.10060063,  0.08698444,  0.20648054, -0.00679327,\n",
      "        0.14513829,  0.00584721, -0.06222813,  0.13726491, -0.27251133,\n",
      "       -0.00809387, -0.03918778,  0.02602987,  0.00202307,  0.02165588,\n",
      "        0.03957033, -0.18763958,  0.02265435, -0.16649201,  0.08756484,\n",
      "        0.04195815,  0.14960842,  0.09649399,  0.13315112, -0.00381412,\n",
      "        0.0716519 ,  0.01909645,  0.12553966, -0.05802409,  0.2727672 ,\n",
      "       -0.13885934, -0.06259358,  0.08137962,  0.14463426,  0.08927659,\n",
      "        0.06403607,  0.08717057, -0.06771236, -0.01756466, -0.11415266,\n",
      "        0.03490031, -0.05780313, -0.00689604,  0.30780325]), array([-6.43823681e-02, -1.01380389e-01,  2.97052845e-02,  5.46809311e-02,\n",
      "       -5.61067582e-03,  3.20433003e-02, -9.72467127e-02,  1.07632851e-01,\n",
      "       -3.35378367e-02,  3.48995812e-02,  7.89397980e-02, -5.05432725e-02,\n",
      "       -1.05168857e-03,  1.17257395e-01, -5.82072027e-02,  1.43454357e-02,\n",
      "        1.19720116e-01,  6.18098459e-02, -9.31584276e-04, -1.21944082e-01,\n",
      "       -3.72497359e-02,  7.63179008e-02,  7.44868293e-02,  1.57114780e-01,\n",
      "       -2.74958562e-03,  1.08886226e-01,  2.54243791e-03, -4.77603109e-02,\n",
      "        9.47474663e-02, -2.08203447e-01, -4.97441622e-03, -3.72585192e-02,\n",
      "        2.55233344e-02, -1.04917097e-04,  1.29383476e-02,  3.42477858e-02,\n",
      "       -1.40526809e-01,  1.55449059e-02, -1.34945050e-01,  6.66541612e-02,\n",
      "        3.59062112e-02,  1.19631939e-01,  7.30087695e-02,  9.69832813e-02,\n",
      "       -4.08874413e-03,  5.25301571e-02,  1.75344377e-02,  9.97965199e-02,\n",
      "       -5.06311121e-02,  2.16056009e-01, -1.19003091e-01, -5.32081580e-02,\n",
      "        6.35297323e-02,  1.13436559e-01,  6.82148263e-02,  6.50670553e-02,\n",
      "        7.63928990e-02, -4.81258727e-02, -4.10732130e-03, -9.05568178e-02,\n",
      "        2.76996354e-02, -5.75795329e-02,  6.14459316e-04,  2.36917953e-01])]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from similarity import calculate_similarity_matrix, testt\n",
    "\n",
    "\n",
    "# AP Clustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Experiment(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(Experiment, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # embeddings for subgraph\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # classification layer\n",
    "        self.lin = Linear(hidden_channels*2, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, ptr):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        # embedding = embedding.relu()\n",
    "        # embedding = self.conv3(embedding, edge_index)\n",
    "        # embedding = embedding.relu()\n",
    "        \n",
    "        # generate subgraph based on embeddings\n",
    "        feature_emb = embedding.detach()\n",
    "        \n",
    "        subgraph_edge_index, communities, S, batch_communities = self.subgraph_generator(feature_emb, edge_index, batch, ptr)\n",
    "        subgraph_embedding = self.conv4(embedding, subgraph_edge_index)\n",
    "        subgraph_embedding = subgraph_embedding.relu()\n",
    "        subgraph_embedding = self.conv5(subgraph_embedding, subgraph_edge_index)\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        subgraph_pool_embedding = self.subgraph_pooling(subgraph_embedding, communities, batch, ptr, batch_communities)\n",
    "        \n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        subgraph_embedding = global_max_pool(subgraph_embedding, batch)\n",
    "        \n",
    "        \n",
    "        h = torch.cat((embedding, subgraph_embedding), 1)\n",
    "        \n",
    "        h = F.dropout(h, p=0.3, training=self.training)\n",
    "        h = self.lin(h)\n",
    "        h = h.relu()\n",
    "        x = F.dropout(h, p=0.3, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h, S, communities, subgraph_pool_embedding\n",
    "    \n",
    "    def subgraph_generator(self, embeddings, batch_edge_index, batch, ptr):\n",
    "        '''\n",
    "        Return subgraph_edge_index (edge_index of created subgraph)\n",
    "        '''\n",
    "        graph_counter = 0\n",
    "        edge_index = [[],[]]\n",
    "        subgraph_edge_index = [[],[]]\n",
    "        # Gs = []\n",
    "        sub_created = False\n",
    "        graph_bound = {}\n",
    "        all_communities = []\n",
    "        batch_communities = {}\n",
    "        S = []\n",
    "\n",
    "        for i in range(len(ptr)-1):\n",
    "            graph_bound[i] = [ptr[i].item(), ptr[i+1].item()]\n",
    "        \n",
    "        for i, (src, dst) in enumerate(zip(batch_edge_index[0], batch_edge_index[1])):\n",
    "            lower_bound = graph_bound[graph_counter][0]\n",
    "            upper_bound = graph_bound[graph_counter][1]\n",
    "            if ((src >= lower_bound and src < upper_bound) or\n",
    "                (dst >= lower_bound and dst < upper_bound)):\n",
    "                \n",
    "                edge_index[0].append(src - lower_bound)\n",
    "                edge_index[1].append(dst - lower_bound)\n",
    "            else:\n",
    "                sub_created = True\n",
    "                \n",
    "            if (i == len(batch_edge_index[0]) - 1) or sub_created:\n",
    "                sub_created = False\n",
    "                \n",
    "                embs = []\n",
    "                # make new graph\n",
    "                for i, (b, emb) in enumerate(zip(batch, embeddings)):\n",
    "                    if (b == graph_counter):\n",
    "                        embs.append(emb)\n",
    "                # print('emb x', embs)\n",
    "                G = data_transformation(edge_index, embs)\n",
    "                # dont need this at the moment\n",
    "                # Gs.append(G)\n",
    "                \n",
    "                # Calculate similarity matrix\n",
    "                S = calculate_similarity_matrix(G)\n",
    "                \n",
    "                # print('S matrix', S)\n",
    "                # AP Clustering        \n",
    "                clustering = AffinityPropagation(affinity='precomputed', damping=0.8, random_state=42, convergence_iter=15, max_iter=1000)\n",
    "                clustering.fit(S)\n",
    "                \n",
    "                print('clustering label', clustering.labels_)\n",
    "                \n",
    "                # Get community\n",
    "                communities = {}\n",
    "                for lab in clustering.labels_:\n",
    "                    communities[lab] = []\n",
    "                    all_communities.append(lab)\n",
    "                for nd, clust in enumerate(clustering.labels_):\n",
    "                    communities[clust].append(nd)\n",
    "                print(communities)\n",
    "                \n",
    "                edge_index = [[],[]]\n",
    "                batch_communities[graph_counter] = communities\n",
    "                \n",
    "                graph_counter+=1\n",
    "                \n",
    "                # Make subgraph edge_index\n",
    "                for c in communities:\n",
    "                    w = G.subgraph(communities[c])\n",
    "                    for sub in w.edges:\n",
    "                        subgraph_edge_index[0].append(sub[0] + lower_bound)\n",
    "                        subgraph_edge_index[1].append(sub[1] + lower_bound)\n",
    "                \n",
    "                print('all com', all_communities)\n",
    "                print()\n",
    "                # break # sementara aja\n",
    "        \n",
    "        # print('batch communities', batch_communities)\n",
    "        return torch.tensor(subgraph_edge_index), all_communities, S, batch_communities\n",
    "    \n",
    "        \n",
    "    def subgraph_pooling(self, embeddings, communities, batch, ptr, batch_communities):\n",
    "        # batch communities: batch (or graph in this batch) -> communities -> member\n",
    "        pool_type = 'mean'\n",
    "        curr_batch = 0\n",
    "        emb_temp = None\n",
    "        emb_pool = []\n",
    "        all_emb_pool = []\n",
    "        print('batch communities', batch_communities)\n",
    "        \n",
    "        print('batch loop')\n",
    "        print('')\n",
    "        \n",
    "        # LOOP THROUGH BATCH\n",
    "        for b in batch_communities:\n",
    "            print(f'==== BATCH {b} ====')\n",
    "            print('lower bound', ptr[b].item())\n",
    "            print('len communities on this batch', len(batch_communities[b]))\n",
    "            \n",
    "            # initialize array\n",
    "            emb_temp = [[] for _ in range(len(batch_communities[b]))]\n",
    "            emb_pool = [[] for _ in range(len(batch_communities[b]))]\n",
    "            for comm in batch_communities[b]:\n",
    "                for member in batch_communities[b][comm]:\n",
    "                    # emb_temp[comm].append(member + ptr[b].item())\n",
    "                    index_used = member + ptr[b].item()\n",
    "                    emb_temp[comm].append(embeddings[index_used].detach().tolist())\n",
    "                    # print('embtemp-log', emb_temp)\n",
    "                    # print(comm, \"-\",member)\n",
    "                print('break new community', comm)\n",
    "\n",
    "                # Pooling per sub graph                \n",
    "                if pool_type == 'mean': # mean pool\n",
    "                    emb_pool[comm] = np.array(emb_temp[comm]).mean(axis=0)\n",
    "                elif pool_type == 'add': # add pool\n",
    "                    emb_pool[comm] = np.array(emb_temp[comm]).sum(axis=0)\n",
    "                else:\n",
    "                    print('TODO: fill later')\n",
    "                \n",
    "            print(\"pool subgraph === \", np.array(emb_pool))\n",
    "            print(\"Pool size \", np.array(emb_pool).shape)\n",
    "            print()\n",
    "            all_emb_pool.append(emb_pool.copy())\n",
    "            # emb_temp = np.array(emb_temp)\n",
    "            # print(\"emb_temp\", emb_temp)\n",
    "            # print(\"len emb_temp\", len(emb_temp))\n",
    "            # print(\"emb_temp average\")\n",
    "            # print(\"size emb_temp\", len(emb_temp))\n",
    "        # print(len(emb_temp))\n",
    "        \n",
    "        print('')\n",
    "        print('====== ALL SUBGRAPH POOLING RESULT ======')\n",
    "        print(all_emb_pool)\n",
    "        \n",
    "        return all_emb_pool\n",
    "        # curr_batch+=1\n",
    "        # # print('num iteration', curr_batch)\n",
    "        # print(\"communities\", communities)\n",
    "        # print(\"batch\", batch)\n",
    "        # print(\"ptr\", ptr)\n",
    "        # print('calling subgraph pooling')\n",
    "        \n",
    "\n",
    "experiment = Experiment(dataset, 64)\n",
    "emb, h, S, communities, sub_emb = experiment(batch1.x, batch1.edge_index, batch1.batch, batch1.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [1.33333333 2.33333333 2.33333333]\n",
      "sum [4 7 7]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3],[1,3,2],[2,2,2]])\n",
    "\n",
    "print('mean', np.mean(test, axis=0))\n",
    "print('sum', np.sum(test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectk_subgraph():\n",
    "    query_layer = Linear(64,64)\n",
    "    key_layer = Linear(64,64)\n",
    "    value_layer = Linear(64,64)\n",
    "    sub = torch.tensor(sub_emb[0])\n",
    "    sub = sub.to(torch.float32)\n",
    "\n",
    "    # transform\n",
    "    query = query_layer(emb[0])\n",
    "    key = key_layer(sub)\n",
    "    value = value_layer(sub)\n",
    "\n",
    "    # att score\n",
    "    attention_score = torch.matmul(query, key.transpose(0,1))\n",
    "    attention_weight = F.softmax(attention_score, dim=0)\n",
    "\n",
    "    print(f'attention score {attention_score}')\n",
    "    print(f'attention weight {attention_weight}')\n",
    "\n",
    "    print('select top k')\n",
    "    topk_subgraph_embeddings = None\n",
    "    k = 2\n",
    "    if (k < len(sub)):\n",
    "        topk_scores, topk_indices = torch.topk(attention_weight, k)\n",
    "        topk_subgraph_embeddings = sub[topk_indices]\n",
    "    else:\n",
    "        print('too big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.5293e-02, -1.1435e-01,  2.7101e-02,  6.1513e-02, -6.5368e-03,\n",
       "          3.1087e-02, -1.0824e-01,  1.2121e-01, -3.9917e-02,  2.9884e-02,\n",
       "          8.3012e-02, -6.0109e-02,  6.7233e-03,  1.2478e-01, -6.4743e-02,\n",
       "          1.5063e-02,  1.3245e-01,  6.8452e-02,  2.5907e-03, -1.3869e-01,\n",
       "         -4.4172e-02,  8.7378e-02,  7.8119e-02,  1.7918e-01, -6.7543e-03,\n",
       "          1.2613e-01,  4.4999e-03, -5.2727e-02,  1.1778e-01, -2.3626e-01,\n",
       "         -7.6991e-03, -3.5182e-02,  2.4885e-02,  1.4150e-03,  1.7957e-02,\n",
       "          3.4616e-02, -1.6302e-01,  1.8767e-02, -1.4625e-01,  7.5567e-02,\n",
       "          3.6647e-02,  1.3127e-01,  8.2579e-02,  1.1629e-01, -3.6585e-03,\n",
       "          6.2090e-02,  1.6399e-02,  1.1114e-01, -5.2183e-02,  2.4046e-01,\n",
       "         -1.2440e-01, -5.6377e-02,  7.2188e-02,  1.2633e-01,  7.8471e-02,\n",
       "          5.7267e-02,  7.8648e-02, -5.9391e-02, -1.4633e-02, -1.0075e-01,\n",
       "          3.0388e-02, -5.3261e-02, -6.3168e-03,  2.6829e-01],\n",
       "        [-7.1308e-02, -1.0630e-01,  2.8360e-02,  5.5724e-02, -5.2446e-03,\n",
       "          3.0357e-02, -1.0038e-01,  1.1690e-01, -3.5892e-02,  3.1508e-02,\n",
       "          7.8106e-02, -5.3734e-02,  4.4251e-03,  1.1660e-01, -6.2075e-02,\n",
       "          1.7339e-02,  1.2132e-01,  6.4215e-02,  3.5621e-03, -1.3018e-01,\n",
       "         -3.8048e-02,  8.1476e-02,  7.5119e-02,  1.6838e-01, -2.4957e-03,\n",
       "          1.1446e-01,  2.4294e-03, -5.3748e-02,  1.0590e-01, -2.1978e-01,\n",
       "         -4.7815e-03, -3.5679e-02,  2.3437e-02, -1.2389e-04,  1.5851e-02,\n",
       "          3.3461e-02, -1.4996e-01,  1.7162e-02, -1.4034e-01,  7.2492e-02,\n",
       "          3.6340e-02,  1.2270e-01,  7.8913e-02,  1.0369e-01, -1.4476e-03,\n",
       "          5.8153e-02,  1.6046e-02,  1.0360e-01, -4.9008e-02,  2.2042e-01,\n",
       "         -1.1859e-01, -5.2926e-02,  6.3359e-02,  1.1943e-01,  6.9407e-02,\n",
       "          5.8463e-02,  7.4854e-02, -5.4251e-02, -1.0232e-02, -9.4331e-02,\n",
       "          2.8796e-02, -5.1781e-02, -1.8119e-03,  2.4920e-01]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topk_subgraph_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(communities) == \n",
    "batch1.batch.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3, 0, 1, 1, 2, 1, 2, 2, 3, 3, 3, 4, 3, 3, 3, 3, 4, 4,\n",
       "       4], dtype=int64)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering = AffinityPropagation(affinity='precomputed', damping=0.7, random_state=42, convergence_iter=15, max_iter=3000)\n",
    "clustering.fit(S)\n",
    "clustering.labels_\n",
    "# clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MUTAG(188)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expTrain(train_loader, val_loader, test_loader, epoch = 2):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "    experiment = Experiment(dataset, 64)\n",
    "\n",
    "    # Train\n",
    "    print('process training')\n",
    "    for _ in range(epoch):\n",
    "        loss = round(train_base(experiment, train_loader, True).item(), 5)\n",
    "        train_acc = round(test_base(experiment, train_loader, True), 5)\n",
    "        val_acc = round(test_base(experiment, val_loader, True), 5)\n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; test_acc: {val_acc}')\n",
    "\n",
    "    # Test\n",
    "    print('process testing')\n",
    "    test = test_base(experiment, test_loader, True)\n",
    "    print(f'Accuracy: {test}')\n",
    "\n",
    "# expTrain(train_loader, val_loader, test_loader, epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseTrain(train_loader, val_loader, test_loader, epoch = 10):\n",
    "    base = Base(dataset, 64)\n",
    "\n",
    "    # Train\n",
    "    for _ in range(epoch):\n",
    "        loss = round(train_base(base, train_loader).item(), 5)\n",
    "        train_acc = round(test_base(base, train_loader), 5)\n",
    "        val_acc = round(test_base(base, val_loader), 5)\n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; val_acc: {val_acc}; test: {round(test_base(base, test_loader), 2)}')\n",
    "\n",
    "    # Test\n",
    "    test = test_base(base, test_loader)\n",
    "    print(f'Accuracy: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[:round(len(dataset) * 0.8)]\n",
    "test_dataset = dataset[round(len(dataset) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0/10\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.69358; train_acc: 0.7125; val_acc: 0.675; test: 0.81\n",
      "epoch 1; loss: 0.51878; train_acc: 0.72083; val_acc: 0.675; test: 0.73\n",
      "epoch 2; loss: 0.57897; train_acc: 0.71944; val_acc: 0.6375; test: 0.73\n",
      "epoch 3; loss: 0.55901; train_acc: 0.72778; val_acc: 0.6875; test: 0.74\n",
      "epoch 4; loss: 0.58857; train_acc: 0.70556; val_acc: 0.575; test: 0.68\n",
      "epoch 5; loss: 0.49834; train_acc: 0.7125; val_acc: 0.6625; test: 0.72\n",
      "epoch 6; loss: 0.55777; train_acc: 0.73472; val_acc: 0.7125; test: 0.77\n",
      "epoch 7; loss: 0.59016; train_acc: 0.74306; val_acc: 0.725; test: 0.76\n",
      "epoch 8; loss: 0.52072; train_acc: 0.74722; val_acc: 0.6625; test: 0.77\n",
      "epoch 9; loss: 0.58987; train_acc: 0.7125; val_acc: 0.75; test: 0.77\n",
      "Accuracy: 0.77\n",
      "=== Experiment model ===\n",
      "process training\n",
      "epoch 0; loss: 0.67796; train_acc: 0.475; test_acc: 0.575\n",
      "epoch 1; loss: 0.66832; train_acc: 0.65417; test_acc: 0.7125\n",
      "epoch 2; loss: 0.7253; train_acc: 0.60972; test_acc: 0.6625\n",
      "epoch 3; loss: 0.65472; train_acc: 0.67639; test_acc: 0.6\n",
      "epoch 4; loss: 0.55065; train_acc: 0.69861; test_acc: 0.625\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_dataset\n",
    "test_dataset\n",
    "k = 10\n",
    "\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "k_counter = 0\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(train_dataset)))):\n",
    "    # print('Fold {}'.format(fold + 1))\n",
    "    # print(f'Fold',fold,'Train_idx',train_idx,'Val_idx',val_idx)\n",
    "    print(f'Fold {fold}/{k}')\n",
    "    #if k_counter > 2:\n",
    "    #    break\n",
    "    \n",
    "    fold_train = []\n",
    "    for key in train_idx:\n",
    "        fold_train.append(train_dataset[key])\n",
    "\n",
    "    fold_val = [] \n",
    "    for key in val_idx:\n",
    "        fold_val.append(train_dataset[key])\n",
    "\n",
    "    tr = DataLoader(fold_train, batch_size=batch_size, shuffle=True)\n",
    "    vd = DataLoader(fold_val, batch_size=batch_size, shuffle=True)\n",
    "    ts = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Base model\n",
    "    print(\"=== Base model ===\")\n",
    "    baseTrain(tr, vd, ts, 10)\n",
    "    print(\"=== Experiment model ===\")\n",
    "    expTrain(tr, vd, ts, 10)\n",
    "    \n",
    "    k_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
