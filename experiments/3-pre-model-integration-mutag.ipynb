{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from preprocessing import data_transformation\n",
    "from similarity import calculate_similarity_matrix\n",
    "\n",
    "from model import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='datasets/', name='IMDB-BINARY')\n",
    "torch.manual_seed(1234)\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 196], y=[1], num_nodes=21, x=[21, 136])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_degree = 0\n",
    "degs = []\n",
    "for data in dataset:\n",
    "    deg = torch_geometric.utils.degree(data.edge_index[1], num_nodes=data.num_nodes)\n",
    "    degs.extend(deg.numpy())\n",
    "    max_degree = max(max_degree, max(deg).item())\n",
    "# assign to one hot degree for each data (OneHotDegree receive maximum degree parameter)\n",
    "dataset.transform = torch_geometric.transforms.OneHotDegree(int(max_degree))\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split: Train test validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```train_dataset```: for training model<br/>\n",
    "```val_dataset```: evaluate model for hyperparameter tunning<br/>\n",
    "```test_dataset```: testing model after complete training<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, ts, vl = 0.8, 0.1, 0.1\n",
    "dslen = len(dataset)\n",
    "tri = round(tr*dslen)\n",
    "tsi = round((tr+ts)*dslen)\n",
    "train_dataset = dataset[:tri]\n",
    "test_dataset = dataset[tri:tsi]\n",
    "val_dataset = dataset[tsi:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)\n",
    "test_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)\n",
    "val_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper 128\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0])\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\n",
      "tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1])\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1])\n",
      "val loader\n",
      "tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1])\n",
      "test loader\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print('train loader')\n",
    "for data in train_loader:\n",
    "    print(data.y)\n",
    "    \n",
    "print('val loader')\n",
    "for data in val_loader:\n",
    "    print(data.y)\n",
    "    \n",
    "print('test loader')\n",
    "for data in test_loader:\n",
    "    print(data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_add_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(Base, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # classification layer\n",
    "        \n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv3(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        h = self.lin(embedding)\n",
    "        h = h.relu()\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base(\n",
       "  (conv1): GCNConv(136, 64)\n",
       "  (conv2): GCNConv(64, 64)\n",
       "  (conv3): GCNConv(64, 64)\n",
       "  (lin): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (lin2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = Base(dataset, 64)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6222, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_base(model, loader, experiment_mode=False):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(h, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss\n",
    "    #     print(h[0])\n",
    "    # print(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_base(model, loader, experiment_mode=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        if experiment_mode:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch, data.ptr)\n",
    "        else:\n",
    "            emb, h = model(data.x, data.edge_index, data.batch)\n",
    "        pred = h.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct/len(loader.dataset)\n",
    "\n",
    "base = Base(dataset, 64)\n",
    "train_base(base, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; loss: 0.56; train_acc: 0.69; test_acc: 0.76\n",
      "epoch 1; loss: 0.46; train_acc: 0.71; test_acc: 0.69\n",
      "epoch 2; loss: 0.53; train_acc: 0.72; test_acc: 0.72\n",
      "epoch 3; loss: 0.55; train_acc: 0.69; test_acc: 0.64\n",
      "epoch 4; loss: 0.55; train_acc: 0.66; test_acc: 0.59\n",
      "epoch 5; loss: 0.49; train_acc: 0.75; test_acc: 0.73\n",
      "epoch 6; loss: 0.58; train_acc: 0.74; test_acc: 0.66\n",
      "epoch 7; loss: 0.5; train_acc: 0.75; test_acc: 0.72\n",
      "epoch 8; loss: 0.52; train_acc: 0.71; test_acc: 0.64\n",
      "epoch 9; loss: 0.48; train_acc: 0.73; test_acc: 0.68\n",
      "epoch 10; loss: 0.5; train_acc: 0.74; test_acc: 0.68\n",
      "epoch 11; loss: 0.53; train_acc: 0.68; test_acc: 0.59\n",
      "epoch 12; loss: 0.47; train_acc: 0.76; test_acc: 0.7\n",
      "epoch 13; loss: 0.53; train_acc: 0.73; test_acc: 0.66\n",
      "epoch 14; loss: 0.52; train_acc: 0.76; test_acc: 0.7\n",
      "epoch 15; loss: 0.46; train_acc: 0.77; test_acc: 0.75\n",
      "epoch 16; loss: 0.44; train_acc: 0.77; test_acc: 0.72\n",
      "epoch 17; loss: 0.47; train_acc: 0.73; test_acc: 0.66\n",
      "epoch 18; loss: 0.48; train_acc: 0.78; test_acc: 0.68\n",
      "epoch 19; loss: 0.49; train_acc: 0.67; test_acc: 0.59\n",
      "epoch 20; loss: 0.49; train_acc: 0.7; test_acc: 0.64\n",
      "epoch 21; loss: 0.5; train_acc: 0.71; test_acc: 0.64\n",
      "epoch 22; loss: 0.5; train_acc: 0.71; test_acc: 0.62\n",
      "epoch 23; loss: 0.49; train_acc: 0.73; test_acc: 0.64\n",
      "epoch 24; loss: 0.51; train_acc: 0.69; test_acc: 0.62\n",
      "epoch 25; loss: 0.45; train_acc: 0.76; test_acc: 0.75\n",
      "epoch 26; loss: 0.52; train_acc: 0.73; test_acc: 0.67\n",
      "epoch 27; loss: 0.4; train_acc: 0.79; test_acc: 0.69\n",
      "epoch 28; loss: 0.56; train_acc: 0.68; test_acc: 0.63\n",
      "epoch 29; loss: 0.45; train_acc: 0.76; test_acc: 0.69\n",
      "epoch 30; loss: 0.49; train_acc: 0.7; test_acc: 0.63\n",
      "epoch 31; loss: 0.5; train_acc: 0.75; test_acc: 0.64\n",
      "epoch 32; loss: 0.49; train_acc: 0.71; test_acc: 0.63\n",
      "epoch 33; loss: 0.61; train_acc: 0.78; test_acc: 0.67\n",
      "epoch 34; loss: 0.51; train_acc: 0.71; test_acc: 0.66\n",
      "epoch 35; loss: 0.56; train_acc: 0.77; test_acc: 0.67\n",
      "epoch 36; loss: 0.54; train_acc: 0.7; test_acc: 0.63\n",
      "epoch 37; loss: 0.59; train_acc: 0.61; test_acc: 0.55\n",
      "epoch 38; loss: 0.46; train_acc: 0.73; test_acc: 0.66\n",
      "epoch 39; loss: 0.56; train_acc: 0.68; test_acc: 0.61\n",
      "epoch 40; loss: 0.61; train_acc: 0.62; test_acc: 0.56\n",
      "epoch 41; loss: 0.72; train_acc: 0.68; test_acc: 0.61\n",
      "epoch 42; loss: 0.63; train_acc: 0.65; test_acc: 0.57\n",
      "epoch 43; loss: 0.73; train_acc: 0.72; test_acc: 0.63\n",
      "epoch 44; loss: 0.57; train_acc: 0.65; test_acc: 0.57\n",
      "epoch 45; loss: 0.53; train_acc: 0.74; test_acc: 0.65\n",
      "epoch 46; loss: 0.47; train_acc: 0.73; test_acc: 0.62\n",
      "epoch 47; loss: 0.56; train_acc: 0.64; test_acc: 0.57\n",
      "epoch 48; loss: 0.64; train_acc: 0.62; test_acc: 0.56\n",
      "epoch 49; loss: 0.46; train_acc: 0.66; test_acc: 0.61\n",
      "epoch 50; loss: 0.5; train_acc: 0.73; test_acc: 0.66\n",
      "epoch 51; loss: 1.29; train_acc: 0.67; test_acc: 0.59\n",
      "epoch 52; loss: 0.65; train_acc: 0.56; test_acc: 0.51\n",
      "epoch 53; loss: 0.64; train_acc: 0.6; test_acc: 0.55\n",
      "epoch 54; loss: 0.65; train_acc: 0.58; test_acc: 0.59\n",
      "epoch 55; loss: 0.66; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 56; loss: 0.65; train_acc: 0.57; test_acc: 0.59\n",
      "epoch 57; loss: 0.66; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 58; loss: 0.65; train_acc: 0.54; test_acc: 0.56\n",
      "epoch 59; loss: 0.65; train_acc: 0.57; test_acc: 0.57\n",
      "epoch 60; loss: 0.68; train_acc: 0.53; test_acc: 0.56\n",
      "epoch 61; loss: 0.66; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 62; loss: 0.65; train_acc: 0.57; test_acc: 0.56\n",
      "epoch 63; loss: 0.66; train_acc: 0.57; test_acc: 0.56\n",
      "epoch 64; loss: 0.66; train_acc: 0.52; test_acc: 0.55\n",
      "epoch 65; loss: 0.65; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 66; loss: 0.66; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 67; loss: 0.65; train_acc: 0.57; test_acc: 0.56\n",
      "epoch 68; loss: 0.67; train_acc: 0.52; test_acc: 0.55\n",
      "epoch 69; loss: 0.65; train_acc: 0.57; test_acc: 0.56\n",
      "epoch 70; loss: 0.65; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 71; loss: 0.66; train_acc: 0.57; test_acc: 0.56\n",
      "epoch 72; loss: 0.65; train_acc: 0.55; test_acc: 0.56\n",
      "epoch 73; loss: 0.65; train_acc: 0.54; test_acc: 0.55\n",
      "epoch 74; loss: 0.65; train_acc: 0.57; test_acc: 0.56\n",
      "epoch 75; loss: 0.65; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 76; loss: 0.65; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 77; loss: 0.66; train_acc: 0.55; test_acc: 0.56\n",
      "epoch 78; loss: 0.65; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 79; loss: 0.65; train_acc: 0.56; test_acc: 0.56\n",
      "epoch 80; loss: 0.7; train_acc: 0.48; test_acc: 0.55\n",
      "epoch 81; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 82; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 83; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 84; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 85; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 86; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 87; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 88; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 89; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 90; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 91; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 92; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 93; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 94; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 95; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 96; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 97; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 98; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "epoch 99; loss: 0.69; train_acc: 0.52; test_acc: 0.45\n",
      "Accuracy: 0.43\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "base = Base(dataset, 64)\n",
    "train_base(base, train_loader)\n",
    "\n",
    "# Train\n",
    "for _ in range(epoch):\n",
    "    loss = round(train_base(base, train_loader).item(), 2)\n",
    "    train_acc = round(test_base(base, train_loader), 2)\n",
    "    val_acc = round(test_base(base, val_loader), 2)\n",
    "    \n",
    "    print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; test_acc: {val_acc}')\n",
    "\n",
    "# Test\n",
    "test = test_base(base, test_loader)\n",
    "print(f'Accuracy: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(Experiment, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # classification layer\n",
    "        \n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        \n",
    "        # generate subgraph based on embeddings\n",
    "        feature_emb = embedding.detach()\n",
    "        G = data_transformation(edge_index, feature_emb)\n",
    "        S = calculate_similarity_matrix(G)\n",
    "        # clustering = AffinityPropagation(affinity='precomputed', random_state=123, max_iter=200).fit(S)\n",
    "        \n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        h = self.lin(embedding)\n",
    "        h = h.relu()\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h\n",
    "\n",
    "    def data_transformation():\n",
    "        print('s')\n",
    "        \n",
    "\n",
    "\n",
    "experiment = Experiment(dataset, 64)\n",
    "# train_base(experiment, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 12108], y=[64], num_nodes=1200, x=[1200, 136], batch=[1200], ptr=[65])\n",
      "tensor([ 0,  0,  0,  ..., 63, 63, 63])\n",
      "edge_index tensor([[   0,    0,    0,  ..., 1199, 1199, 1199],\n",
      "        [   1,    3,    5,  ..., 1194, 1196, 1197]])\n",
      "batch None\n",
      "ptr tensor([   0,   21,   37,   57,   81,   93,  107,  125,  143,  161,  173,  189,\n",
      "         203,  231,  251,  271,  292,  319,  339,  351,  370,  382,  398,  413,\n",
      "         433,  452,  466,  492,  504,  519,  536,  550,  570,  600,  612,  624,\n",
      "         640,  663,  678,  697,  709,  729,  745,  777,  802,  816,  832,  862,\n",
      "         874,  924,  936,  964,  976,  996, 1011, 1032, 1050, 1080, 1101, 1114,\n",
      "        1136, 1151, 1166, 1188, 1200])\n"
     ]
    }
   ],
   "source": [
    "batch1 = None\n",
    "for batch in train_loader:\n",
    "    batch1 = batch\n",
    "    break\n",
    "print(batch1)\n",
    "print(batch1.batch)\n",
    "print(\"edge_index\", batch1.edge_index)\n",
    "print(\"batch\",batch1.edge_attr)\n",
    "print(\"ptr\",batch1.ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1199)\n",
      "tensor(1199)\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,\n",
      "          2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
      "          4,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,\n",
      "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,\n",
      "         11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13,\n",
      "         13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15,\n",
      "         15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17,\n",
      "         17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19,\n",
      "         19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
      "        [ 1,  3,  5,  6, 10, 13, 14,  0,  3,  5,  6, 10, 13, 14,  7,  8, 10, 11,\n",
      "         12, 15, 16, 18, 20,  0,  1,  5,  6, 10, 13, 14,  7,  8,  9, 10, 15, 19,\n",
      "         20,  0,  1,  3,  6, 10, 13, 14,  0,  1,  3,  5, 10, 13, 14,  2,  4,  8,\n",
      "          9, 10, 11, 12, 15, 16, 17, 18, 19, 20,  2,  4,  7,  9, 10, 11, 12, 15,\n",
      "         16, 17, 18, 19, 20,  4,  7,  8, 10, 15, 19, 20,  0,  1,  2,  3,  4,  5,\n",
      "          6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,  2,  7,  8, 10,\n",
      "         12, 15, 16, 18, 20,  2,  7,  8, 10, 11, 15, 16, 17, 18, 20,  0,  1,  3,\n",
      "          5,  6, 10, 14,  0,  1,  3,  5,  6, 10, 13,  2,  4,  7,  8,  9, 10, 11,\n",
      "         12, 16, 17, 18, 19, 20,  2,  7,  8, 10, 11, 12, 15, 17, 18, 20,  7,  8,\n",
      "         10, 12, 15, 16, 20,  2,  7,  8, 10, 11, 12, 15, 16, 20,  4,  7,  8,  9,\n",
      "         10, 15, 20,  2,  4,  7,  8,  9, 10, 11, 12, 15, 16, 17, 18, 19]])\n",
      "tensor([   0,   21,   37,   57,   81,   93,  107,  125,  143,  161,  173,  189,\n",
      "         203,  231,  251,  271,  292,  319,  339,  351,  370,  382,  398,  413,\n",
      "         433,  452,  466,  492,  504,  519,  536,  550,  570,  600,  612,  624,\n",
      "         640,  663,  678,  697,  709,  729,  745,  777,  802,  816,  832,  862,\n",
      "         874,  924,  936,  964,  976,  996, 1011, 1032, 1050, 1080, 1101, 1114,\n",
      "        1136, 1151, 1166, 1188, 1200]) ; len: 65\n"
     ]
    }
   ],
   "source": [
    "print(max(batch1.edge_index[0]))\n",
    "print(max(batch1.edge_index[1]))\n",
    "print((dataset[0].edge_index))\n",
    "print((batch1.ptr), '; len:', len(batch1.ptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. 0 - 21\n",
      "1. 21 - 37\n",
      "2. 37 - 57\n",
      "3. 57 - 81\n",
      "4. 81 - 93\n",
      "5. 93 - 107\n",
      "6. 107 - 125\n",
      "7. 125 - 143\n",
      "8. 143 - 161\n",
      "9. 161 - 173\n",
      "10. 173 - 189\n",
      "11. 189 - 203\n",
      "12. 203 - 231\n",
      "13. 231 - 251\n",
      "14. 251 - 271\n",
      "15. 271 - 292\n",
      "16. 292 - 319\n",
      "17. 319 - 339\n",
      "18. 339 - 351\n",
      "19. 351 - 370\n",
      "20. 370 - 382\n",
      "21. 382 - 398\n",
      "22. 398 - 413\n",
      "23. 413 - 433\n",
      "24. 433 - 452\n",
      "25. 452 - 466\n",
      "26. 466 - 492\n",
      "27. 492 - 504\n",
      "28. 504 - 519\n",
      "29. 519 - 536\n",
      "30. 536 - 550\n",
      "31. 550 - 570\n",
      "32. 570 - 600\n",
      "33. 600 - 612\n",
      "34. 612 - 624\n",
      "35. 624 - 640\n",
      "36. 640 - 663\n",
      "37. 663 - 678\n",
      "38. 678 - 697\n",
      "39. 697 - 709\n",
      "40. 709 - 729\n",
      "41. 729 - 745\n",
      "42. 745 - 777\n",
      "43. 777 - 802\n",
      "44. 802 - 816\n",
      "45. 816 - 832\n",
      "46. 832 - 862\n",
      "47. 862 - 874\n",
      "48. 874 - 924\n",
      "49. 924 - 936\n",
      "50. 936 - 964\n",
      "51. 964 - 976\n",
      "52. 976 - 996\n",
      "53. 996 - 1011\n",
      "54. 1011 - 1032\n",
      "55. 1032 - 1050\n",
      "56. 1050 - 1080\n",
      "57. 1080 - 1101\n",
      "58. 1101 - 1114\n",
      "59. 1114 - 1136\n",
      "60. 1136 - 1151\n",
      "61. 1151 - 1166\n",
      "62. 1166 - 1188\n",
      "63. 1188 - 1200\n"
     ]
    }
   ],
   "source": [
    "graph_bound = {}\n",
    "\n",
    "for i in range(len(batch1.ptr)-1):\n",
    "    graph_bound[i] = [batch1.ptr[i].item(), batch1.ptr[i+1].item()]\n",
    "    print(str(i)+\".\", batch1.ptr[i].item(), \"-\", batch1.ptr[i+1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below --> Subgraph extractor with batch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Graph 0 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}\n",
      "=== Graph 1 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}\n",
      "=== Graph 2 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}\n",
      "=== Graph 3 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]}\n",
      "=== Graph 4 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}\n",
      "=== Graph 5 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[0 0 0 1 0 1 1 0 1 1 1 1 0 0]\n",
      "{0, 1}\n",
      "communities {0: [0, 1, 2, 4, 7, 12, 13], 1: [3, 5, 6, 8, 9, 10, 11]}\n",
      "=== Graph 6 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}\n",
      "=== Graph 7 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}\n",
      "=== Graph 8 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[1 0 3 1 3 1 2 0 3 0 2 0 0 3 3 0 2 1]\n",
      "{0, 1, 2, 3}\n",
      "communities {1: [0, 3, 5, 17], 0: [1, 7, 9, 11, 12, 15], 3: [2, 4, 8, 13, 14], 2: [6, 10, 16]}\n",
      "=== Graph 9 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{0}\n",
      "communities {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}\n",
      "=== Graph 10 ===\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "masalah disini bro\n"
     ]
    }
   ],
   "source": [
    "# idx_from = 0\n",
    "# idx_to = 0\n",
    "graph_counter = 0\n",
    "graph_bound\n",
    "edge_index = [[],[]]\n",
    "Gs = []\n",
    "\n",
    "from similarity import calculate_similarity_matrix, testt\n",
    "# AP Clustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "print(f'=== Graph {graph_counter} ===')\n",
    "for i, (src, dst) in enumerate(zip(batch1.edge_index[0], batch1.edge_index[1])):\n",
    "    # if (graph_counter < len(batch1.ptr)):\n",
    "    lower_bound = graph_bound[graph_counter][0]\n",
    "    upper_bound = graph_bound[graph_counter][1]\n",
    "    if ((src >= lower_bound and src < upper_bound) or\n",
    "        (dst >= lower_bound and dst < upper_bound)):\n",
    "        # print(i,src.item()-lower_bound, dst.item()-lower_bound)\n",
    "        edge_index[0].append(src - lower_bound)\n",
    "        edge_index[1].append(dst - lower_bound)\n",
    "    else:\n",
    "        # print(edge_index)\n",
    "        embs = []\n",
    "        # make new graph\n",
    "        for i, (b, emb) in enumerate(zip(batch1.batch, batch1.x)):\n",
    "            if (b == graph_counter):\n",
    "                # print(i, emb)\n",
    "                embs.append(emb)\n",
    "        \n",
    "        G = data_transformation(edge_index, embs)\n",
    "        Gs.append(G)\n",
    "        print(sorted(list(G.nodes)))\n",
    "        # print('pre', precalc_shortest_path_length)\n",
    "        # for node in sorted(list(G.nodes)):\n",
    "        #     print(G.nodes[node])\n",
    "        \n",
    "        \n",
    "        # testt()\n",
    "        if graph_counter == 10:\n",
    "            print('masalah disini bro')\n",
    "            break\n",
    "        \n",
    "        # Calculate S matrix\n",
    "        S = calculate_similarity_matrix(G)\n",
    "        \n",
    "        # AP Clustering\n",
    "        clustering = AffinityPropagation(affinity='precomputed', damping=0.9, random_state=123, max_iter=1000).fit(S)\n",
    "\n",
    "        print(clustering.labels_)\n",
    "        # print(clustering.)\n",
    "        \n",
    "        communities = {}\n",
    "        print(set(clustering.labels_))\n",
    "        # communities init\n",
    "        for lab in clustering.labels_:\n",
    "            communities[lab] = []\n",
    "        \n",
    "        for nd, clust in enumerate(clustering.labels_):\n",
    "            communities[clust].append(nd)\n",
    "        print(\"communities\", communities) \n",
    "            \n",
    "        edge_index = [[],[]]\n",
    "        graph_counter+=1\n",
    "        \n",
    "        print(f'=== Graph {graph_counter} ===')\n",
    "        \n",
    "    if i == len(batch1.edge_index[0]) - 1:\n",
    "        embs = []\n",
    "        # make new graph\n",
    "        for i, (b, emb) in enumerate(zip(batch1.batch, batch1.x)):\n",
    "            if (b == graph_counter):\n",
    "                # print(i, emb)\n",
    "                embs.append(emb)\n",
    "        \n",
    "        G = data_transformation(edge_index, embs)\n",
    "        Gs.append(G)\n",
    "        \n",
    "        S = calculate_similarity_matrix(G)\n",
    "        # AP Clustering        \n",
    "        clustering = AffinityPropagation(affinity='precomputed', damping=0.9, random_state=123, max_iter=1000).fit(S)\n",
    "        \n",
    "        print(sorted(list(G.nodes)))\n",
    "        print(clustering.labels_)\n",
    "        \n",
    "        # print(edge_index)\n",
    "        print('udh di akhir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3].x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n",
      "{'node_features': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for node in Gs[6].nodes:\n",
    "    print(Gs[0].nodes[node])\n",
    "    # Udah bisa tambah nodes per batch, tinggal masukin ke algo utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,\n",
       "          3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,\n",
       "          5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,\n",
       "          7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,\n",
       "         10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11],\n",
       "        [ 3,  4,  5,  6,  8,  9, 11,  2,  5,  6,  7, 10,  1,  5,  6,  7, 10,  0,\n",
       "          4,  5,  6,  8,  9, 11,  0,  3,  5,  6,  8,  9, 11,  0,  1,  2,  3,  4,\n",
       "          6,  7,  8,  9, 10, 11,  0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11,  1,\n",
       "          2,  5,  6, 10,  0,  3,  4,  5,  6,  9, 11,  0,  3,  4,  5,  6,  8, 11,\n",
       "          1,  2,  5,  6,  7,  0,  3,  4,  5,  6,  8,  9]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[63].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "1 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "2 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "3 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "4 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "5 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "6 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "7 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "8 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "9 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "10 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "11 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "12 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "13 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "14 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "15 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "16 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "17 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "18 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "19 tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "20 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i, (b, emb) in enumerate(zip(batch1.batch, batch1.x)):\n",
    "    if (b == 0):\n",
    "        print(i, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 12332], y=[64], num_nodes=1302, x=[1302, 136], batch=[1302], ptr=[65])\n",
      "=== Graph 0 ===\n",
      "Graph with 14 nodes and 40 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13)], [tensor(1), tensor(3), tensor(4), tensor(5), tensor(8), tensor(9), tensor(10), tensor(0), tensor(3), tensor(4), tensor(5), tensor(8), tensor(9), tensor(10), tensor(5), tensor(7), tensor(12), tensor(0), tensor(1), tensor(4), tensor(5), tensor(8), tensor(9), tensor(10), tensor(0), tensor(1), tensor(3), tensor(5), tensor(8), tensor(9), tensor(10), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(5), tensor(11), tensor(13), tensor(2), tensor(5), tensor(12), tensor(0), tensor(1), tensor(3), tensor(4), tensor(5), tensor(9), tensor(10), tensor(0), tensor(1), tensor(3), tensor(4), tensor(5), tensor(8), tensor(10), tensor(0), tensor(1), tensor(3), tensor(4), tensor(5), tensor(8), tensor(9), tensor(5), tensor(6), tensor(13), tensor(2), tensor(5), tensor(7), tensor(5), tensor(6), tensor(11)]]\n",
      "13\n",
      "14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13]]\n",
      "=== Graph 1 ===\n",
      "Graph with 14 nodes and 35 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13)], [tensor(3), tensor(7), tensor(9), tensor(11), tensor(3), tensor(6), tensor(12), tensor(13), tensor(0), tensor(3), tensor(7), tensor(9), tensor(11), tensor(0), tensor(1), tensor(2), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(3), tensor(5), tensor(8), tensor(10), tensor(3), tensor(4), tensor(8), tensor(10), tensor(1), tensor(3), tensor(12), tensor(13), tensor(0), tensor(2), tensor(3), tensor(9), tensor(11), tensor(3), tensor(4), tensor(5), tensor(10), tensor(0), tensor(2), tensor(3), tensor(7), tensor(11), tensor(3), tensor(4), tensor(5), tensor(8), tensor(0), tensor(2), tensor(3), tensor(7), tensor(9), tensor(1), tensor(3), tensor(6), tensor(13), tensor(1), tensor(3), tensor(6), tensor(12)]]\n",
      "13\n",
      "14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24]]\n",
      "=== Graph 2 ===\n",
      "Graph with 14 nodes and 36 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13)], [tensor(3), tensor(6), tensor(8), tensor(10), tensor(4), tensor(8), tensor(12), tensor(13), tensor(0), tensor(3), tensor(4), tensor(6), tensor(8), tensor(10), tensor(0), tensor(2), tensor(6), tensor(8), tensor(10), tensor(1), tensor(2), tensor(8), tensor(12), tensor(13), tensor(7), tensor(8), tensor(9), tensor(11), tensor(0), tensor(2), tensor(3), tensor(8), tensor(10), tensor(5), tensor(8), tensor(9), tensor(11), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(5), tensor(7), tensor(8), tensor(11), tensor(0), tensor(2), tensor(3), tensor(6), tensor(8), tensor(5), tensor(7), tensor(8), tensor(9), tensor(1), tensor(4), tensor(8), tensor(13), tensor(1), tensor(4), tensor(8), tensor(12)]]\n",
      "13\n",
      "14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39]]\n",
      "=== Graph 3 ===\n",
      "Graph with 14 nodes and 61 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13)], [tensor(4), tensor(5), tensor(7), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(2), tensor(5), tensor(6), tensor(8), tensor(12), tensor(1), tensor(5), tensor(6), tensor(8), tensor(12), tensor(0), tensor(4), tensor(5), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(0), tensor(3), tensor(5), tensor(7), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(1), tensor(2), tensor(5), tensor(8), tensor(12), tensor(0), tensor(3), tensor(4), tensor(5), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(1), tensor(2), tensor(3), tensor(5), tensor(6), tensor(11), tensor(12), tensor(0), tensor(3), tensor(4), tensor(5), tensor(7), tensor(10), tensor(11), tensor(12), tensor(13), tensor(0), tensor(3), tensor(4), tensor(5), tensor(7), tensor(9), tensor(11), tensor(12), tensor(13), tensor(0), tensor(3), tensor(4), tensor(5), tensor(7), tensor(8), tensor(9), tensor(10), tensor(12), tensor(13), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(13), tensor(0), tensor(3), tensor(4), tensor(5), tensor(7), tensor(9), tensor(10), tensor(11), tensor(12)]]\n",
      "13\n",
      "14\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[0 2 1 0 1 1 2 2 1 1 2 0 2 2]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51]]\n",
      "=== Graph 4 ===\n",
      "Graph with 22 nodes and 66 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21)], [tensor(6), tensor(14), tensor(15), tensor(17), tensor(3), tensor(8), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(6), tensor(14), tensor(15), tensor(17), tensor(1), tensor(8), tensor(11), tensor(12), tensor(13), tensor(14), tensor(7), tensor(10), tensor(14), tensor(20), tensor(21), tensor(9), tensor(14), tensor(16), tensor(18), tensor(19), tensor(0), tensor(2), tensor(14), tensor(15), tensor(17), tensor(4), tensor(10), tensor(14), tensor(20), tensor(21), tensor(1), tensor(3), tensor(11), tensor(12), tensor(13), tensor(14), tensor(5), tensor(14), tensor(16), tensor(18), tensor(19), tensor(4), tensor(7), tensor(14), tensor(20), tensor(21), tensor(1), tensor(3), tensor(8), tensor(12), tensor(13), tensor(14), tensor(1), tensor(3), tensor(8), tensor(11), tensor(13), tensor(14), tensor(1), tensor(3), tensor(8), tensor(11), tensor(12), tensor(14), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(0), tensor(2), tensor(6), tensor(14), tensor(17), tensor(5), tensor(9), tensor(14), tensor(18), tensor(19), tensor(0), tensor(2), tensor(6), tensor(14), tensor(15), tensor(5), tensor(9), tensor(14), tensor(16), tensor(19), tensor(5), tensor(9), tensor(14), tensor(16), tensor(18), tensor(4), tensor(7), tensor(10), tensor(14), tensor(21), tensor(4), tensor(7), tensor(10), tensor(14), tensor(20)]]\n",
      "21\n",
      "22\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47, 56, 56, 56, 56, 56, 62, 62, 62, 62, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 73, 57, 57, 57, 57, 57, 59, 59, 59, 59, 64, 64, 64, 67, 67, 68, 60, 60, 60, 60, 63, 63, 63, 66, 66, 76, 61, 61, 61, 61, 65, 65, 65, 72, 72, 74], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51, 62, 70, 71, 73, 58, 58, 70, 71, 73, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 58, 73, 58, 59, 64, 67, 68, 69, 64, 67, 68, 69, 67, 68, 69, 68, 69, 69, 63, 66, 76, 77, 66, 76, 77, 76, 77, 77, 65, 72, 74, 75, 72, 74, 75, 74, 75, 75]]\n",
      "=== Graph 5 ===\n",
      "Graph with 30 nodes and 435 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(17), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(18), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(19), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(20), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(21), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(22), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(23), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(24), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(25), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(26), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(27), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(28), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29), tensor(29)], [tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(25), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(26), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(27), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(28), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(29), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(17), tensor(18), tensor(19), tensor(20), tensor(21), tensor(22), tensor(23), tensor(24), tensor(25), tensor(26), tensor(27), tensor(28)]]\n",
      "29\n",
      "30\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "[4 0 2 6 7 0 2 1 6 7 0 1 7 1 3 1 2 0 3 4 7 1 1 5 4 6 4 6 3 7]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47, 56, 56, 56, 56, 56, 62, 62, 62, 62, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 73, 57, 57, 57, 57, 57, 59, 59, 59, 59, 64, 64, 64, 67, 67, 68, 60, 60, 60, 60, 63, 63, 63, 66, 66, 76, 61, 61, 61, 61, 65, 65, 65, 72, 72, 74, 78, 78, 78, 102, 102, 104, 79, 79, 79, 88, 88, 83, 94, 94, 80, 86, 86, 86, 103, 103, 81, 82, 82, 82, 82, 87, 87, 87, 90, 90, 98, 85, 85, 85, 85, 85, 89, 89, 89, 89, 91, 91, 91, 93, 93, 99, 96, 96, 106], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51, 62, 70, 71, 73, 58, 58, 70, 71, 73, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 58, 73, 58, 59, 64, 67, 68, 69, 64, 67, 68, 69, 67, 68, 69, 68, 69, 69, 63, 66, 76, 77, 66, 76, 77, 76, 77, 77, 65, 72, 74, 75, 72, 74, 75, 74, 75, 75, 97, 102, 104, 97, 104, 97, 83, 88, 95, 83, 95, 95, 80, 84, 84, 81, 103, 105, 81, 105, 105, 87, 90, 98, 107, 90, 98, 107, 98, 107, 107, 89, 91, 93, 99, 100, 91, 93, 99, 100, 93, 99, 100, 99, 100, 100, 92, 106, 92]]\n",
      "=== Graph 6 ===\n",
      "Graph with 13 nodes and 44 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12)], [tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(0), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(0), tensor(1), tensor(4), tensor(7), tensor(9), tensor(12), tensor(0), tensor(1), tensor(4), tensor(5), tensor(6), tensor(0), tensor(1), tensor(2), tensor(3), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(0), tensor(1), tensor(3), tensor(4), tensor(6), tensor(0), tensor(1), tensor(3), tensor(4), tensor(5), tensor(0), tensor(1), tensor(2), tensor(4), tensor(9), tensor(0), tensor(1), tensor(4), tensor(10), tensor(11), tensor(0), tensor(1), tensor(2), tensor(4), tensor(7), tensor(12), tensor(0), tensor(1), tensor(4), tensor(8), tensor(11), tensor(0), tensor(1), tensor(4), tensor(8), tensor(10), tensor(0), tensor(1), tensor(2), tensor(4), tensor(9)]]\n",
      "12\n",
      "13\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[0 0 0 0 1 1 0 1 1 0 1 1 1]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47, 56, 56, 56, 56, 56, 62, 62, 62, 62, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 73, 57, 57, 57, 57, 57, 59, 59, 59, 59, 64, 64, 64, 67, 67, 68, 60, 60, 60, 60, 63, 63, 63, 66, 66, 76, 61, 61, 61, 61, 65, 65, 65, 72, 72, 74, 78, 78, 78, 102, 102, 104, 79, 79, 79, 88, 88, 83, 94, 94, 80, 86, 86, 86, 103, 103, 81, 82, 82, 82, 82, 87, 87, 87, 90, 90, 98, 85, 85, 85, 85, 85, 89, 89, 89, 89, 91, 91, 91, 93, 93, 99, 96, 96, 106, 108, 108, 108, 108, 108, 109, 109, 109, 109, 110, 111, 112, 112, 112, 112, 112, 112, 116, 116, 118], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51, 62, 70, 71, 73, 58, 58, 70, 71, 73, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 58, 73, 58, 59, 64, 67, 68, 69, 64, 67, 68, 69, 67, 68, 69, 68, 69, 69, 63, 66, 76, 77, 66, 76, 77, 76, 77, 77, 65, 72, 74, 75, 72, 74, 75, 74, 75, 75, 97, 102, 104, 97, 104, 97, 83, 88, 95, 83, 95, 95, 80, 84, 84, 81, 103, 105, 81, 105, 105, 87, 90, 98, 107, 90, 98, 107, 98, 107, 107, 89, 91, 93, 99, 100, 91, 93, 99, 100, 93, 99, 100, 99, 100, 100, 92, 106, 92, 110, 111, 114, 117, 109, 110, 111, 114, 117, 117, 114, 113, 115, 116, 118, 119, 120, 118, 119, 119]]\n",
      "=== Graph 7 ===\n",
      "Graph with 15 nodes and 63 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14)], [tensor(2), tensor(3), tensor(5), tensor(6), tensor(10), tensor(11), tensor(0), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(1), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(1), tensor(2), tensor(5), tensor(6), tensor(10), tensor(11), tensor(1), tensor(2), tensor(7), tensor(8), tensor(9), tensor(12), tensor(13), tensor(14), tensor(0), tensor(1), tensor(2), tensor(3), tensor(6), tensor(10), tensor(11), tensor(0), tensor(1), tensor(2), tensor(3), tensor(5), tensor(10), tensor(11), tensor(1), tensor(2), tensor(4), tensor(8), tensor(9), tensor(12), tensor(13), tensor(14), tensor(1), tensor(2), tensor(4), tensor(7), tensor(9), tensor(12), tensor(13), tensor(14), tensor(1), tensor(2), tensor(4), tensor(7), tensor(8), tensor(12), tensor(13), tensor(14), tensor(0), tensor(1), tensor(2), tensor(3), tensor(5), tensor(6), tensor(11), tensor(0), tensor(1), tensor(2), tensor(3), tensor(5), tensor(6), tensor(10), tensor(1), tensor(2), tensor(4), tensor(7), tensor(8), tensor(9), tensor(13), tensor(14), tensor(1), tensor(2), tensor(4), tensor(7), tensor(8), tensor(9), tensor(12), tensor(14), tensor(1), tensor(2), tensor(4), tensor(7), tensor(8), tensor(9), tensor(12), tensor(13)]]\n",
      "14\n",
      "15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[0 0 1 0 0 1 0 1 0 0 1 1 1 1 1]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47, 56, 56, 56, 56, 56, 62, 62, 62, 62, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 73, 57, 57, 57, 57, 57, 59, 59, 59, 59, 64, 64, 64, 67, 67, 68, 60, 60, 60, 60, 63, 63, 63, 66, 66, 76, 61, 61, 61, 61, 65, 65, 65, 72, 72, 74, 78, 78, 78, 102, 102, 104, 79, 79, 79, 88, 88, 83, 94, 94, 80, 86, 86, 86, 103, 103, 81, 82, 82, 82, 82, 87, 87, 87, 90, 90, 98, 85, 85, 85, 85, 85, 89, 89, 89, 89, 91, 91, 91, 93, 93, 99, 96, 96, 106, 108, 108, 108, 108, 108, 109, 109, 109, 109, 110, 111, 112, 112, 112, 112, 112, 112, 116, 116, 118, 121, 121, 121, 122, 122, 122, 122, 122, 124, 125, 125, 129, 123, 123, 123, 123, 123, 123, 123, 126, 126, 131, 128, 128, 128, 133, 133, 134], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51, 62, 70, 71, 73, 58, 58, 70, 71, 73, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 58, 73, 58, 59, 64, 67, 68, 69, 64, 67, 68, 69, 67, 68, 69, 68, 69, 69, 63, 66, 76, 77, 66, 76, 77, 76, 77, 77, 65, 72, 74, 75, 72, 74, 75, 74, 75, 75, 97, 102, 104, 97, 104, 97, 83, 88, 95, 83, 95, 95, 80, 84, 84, 81, 103, 105, 81, 105, 105, 87, 90, 98, 107, 90, 98, 107, 98, 107, 107, 89, 91, 93, 99, 100, 91, 93, 99, 100, 93, 99, 100, 99, 100, 100, 92, 106, 92, 110, 111, 114, 117, 109, 110, 111, 114, 117, 117, 114, 113, 115, 116, 118, 119, 120, 118, 119, 119, 124, 127, 122, 124, 125, 127, 129, 130, 127, 129, 130, 130, 126, 128, 131, 132, 133, 134, 135, 131, 132, 132, 133, 134, 135, 134, 135, 135]]\n",
      "=== Graph 8 ===\n",
      "Graph with 17 nodes and 51 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(15), tensor(16), tensor(16), tensor(16), tensor(16), tensor(16)], [tensor(4), tensor(6), tensor(10), tensor(12), tensor(15), tensor(3), tensor(6), tensor(13), tensor(14), tensor(16), tensor(0), tensor(4), tensor(6), tensor(10), tensor(12), tensor(15), tensor(1), tensor(6), tensor(13), tensor(14), tensor(16), tensor(0), tensor(2), tensor(6), tensor(10), tensor(12), tensor(15), tensor(6), tensor(7), tensor(8), tensor(9), tensor(11), tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(15), tensor(16), tensor(5), tensor(6), tensor(8), tensor(9), tensor(11), tensor(5), tensor(6), tensor(7), tensor(9), tensor(11), tensor(5), tensor(6), tensor(7), tensor(8), tensor(11), tensor(0), tensor(2), tensor(4), tensor(6), tensor(12), tensor(15), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(0), tensor(2), tensor(4), tensor(6), tensor(10), tensor(15), tensor(1), tensor(3), tensor(6), tensor(14), tensor(16), tensor(1), tensor(3), tensor(6), tensor(13), tensor(16), tensor(0), tensor(2), tensor(4), tensor(6), tensor(10), tensor(12), tensor(1), tensor(3), tensor(6), tensor(13), tensor(14)]]\n",
      "16\n",
      "17\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47, 56, 56, 56, 56, 56, 62, 62, 62, 62, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 73, 57, 57, 57, 57, 57, 59, 59, 59, 59, 64, 64, 64, 67, 67, 68, 60, 60, 60, 60, 63, 63, 63, 66, 66, 76, 61, 61, 61, 61, 65, 65, 65, 72, 72, 74, 78, 78, 78, 102, 102, 104, 79, 79, 79, 88, 88, 83, 94, 94, 80, 86, 86, 86, 103, 103, 81, 82, 82, 82, 82, 87, 87, 87, 90, 90, 98, 85, 85, 85, 85, 85, 89, 89, 89, 89, 91, 91, 91, 93, 93, 99, 96, 96, 106, 108, 108, 108, 108, 108, 109, 109, 109, 109, 110, 111, 112, 112, 112, 112, 112, 112, 116, 116, 118, 121, 121, 121, 122, 122, 122, 122, 122, 124, 125, 125, 129, 123, 123, 123, 123, 123, 123, 123, 126, 126, 131, 128, 128, 128, 133, 133, 134, 136, 136, 136, 136, 136, 136, 140, 140, 140, 140, 140, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 146, 146, 146, 148, 148, 151, 137, 137, 137, 137, 139, 139, 139, 149, 149, 150, 141, 141, 141, 141, 143, 143, 143, 144, 144, 145], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51, 62, 70, 71, 73, 58, 58, 70, 71, 73, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 58, 73, 58, 59, 64, 67, 68, 69, 64, 67, 68, 69, 67, 68, 69, 68, 69, 69, 63, 66, 76, 77, 66, 76, 77, 76, 77, 77, 65, 72, 74, 75, 72, 74, 75, 74, 75, 75, 97, 102, 104, 97, 104, 97, 83, 88, 95, 83, 95, 95, 80, 84, 84, 81, 103, 105, 81, 105, 105, 87, 90, 98, 107, 90, 98, 107, 98, 107, 107, 89, 91, 93, 99, 100, 91, 93, 99, 100, 93, 99, 100, 99, 100, 100, 92, 106, 92, 110, 111, 114, 117, 109, 110, 111, 114, 117, 117, 114, 113, 115, 116, 118, 119, 120, 118, 119, 119, 124, 127, 122, 124, 125, 127, 129, 130, 127, 129, 130, 130, 126, 128, 131, 132, 133, 134, 135, 131, 132, 132, 133, 134, 135, 134, 135, 135, 140, 142, 146, 148, 151, 138, 138, 142, 146, 148, 151, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 138, 148, 151, 138, 151, 138, 139, 149, 150, 152, 149, 150, 152, 150, 152, 152, 143, 144, 145, 147, 144, 145, 147, 145, 147, 147]]\n",
      "=== Graph 9 ===\n",
      "Graph with 15 nodes and 61 edges\n",
      "edge_idx [[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(3), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(4), tensor(5), tensor(5), tensor(5), tensor(5), tensor(5), tensor(6), tensor(6), tensor(6), tensor(6), tensor(6), tensor(7), tensor(7), tensor(7), tensor(7), tensor(7), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(8), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(9), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(10), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(11), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(12), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14), tensor(14)], [tensor(3), tensor(4), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(2), tensor(4), tensor(5), tensor(6), tensor(7), tensor(0), tensor(1), tensor(4), tensor(5), tensor(6), tensor(7), tensor(0), tensor(4), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(1), tensor(2), tensor(3), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(1), tensor(2), tensor(4), tensor(6), tensor(7), tensor(1), tensor(2), tensor(4), tensor(5), tensor(7), tensor(1), tensor(2), tensor(4), tensor(5), tensor(6), tensor(0), tensor(3), tensor(4), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(3), tensor(4), tensor(8), tensor(10), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(3), tensor(4), tensor(8), tensor(9), tensor(11), tensor(12), tensor(13), tensor(14), tensor(0), tensor(3), tensor(4), tensor(8), tensor(9), tensor(10), tensor(12), tensor(13), tensor(14), tensor(0), tensor(3), tensor(4), tensor(8), tensor(9), tensor(10), tensor(11), tensor(13), tensor(14), tensor(0), tensor(3), tensor(4), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(14), tensor(0), tensor(3), tensor(4), tensor(8), tensor(9), tensor(10), tensor(11), tensor(12), tensor(13)]]\n",
      "14\n",
      "15\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 9, 2, 2, 7, 6, 6, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 21, 21, 21, 23, 23, 25, 15, 15, 15, 20, 20, 26, 18, 18, 18, 19, 19, 22, 28, 28, 28, 28, 28, 31, 31, 31, 31, 34, 34, 34, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 38, 29, 29, 29, 32, 32, 32, 40, 33, 33, 33, 35, 35, 37, 42, 42, 53, 43, 43, 48, 49, 49, 49, 52, 52, 54, 44, 44, 46, 46, 47, 47, 56, 56, 56, 56, 56, 62, 62, 62, 62, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 73, 57, 57, 57, 57, 57, 59, 59, 59, 59, 64, 64, 64, 67, 67, 68, 60, 60, 60, 60, 63, 63, 63, 66, 66, 76, 61, 61, 61, 61, 65, 65, 65, 72, 72, 74, 78, 78, 78, 102, 102, 104, 79, 79, 79, 88, 88, 83, 94, 94, 80, 86, 86, 86, 103, 103, 81, 82, 82, 82, 82, 87, 87, 87, 90, 90, 98, 85, 85, 85, 85, 85, 89, 89, 89, 89, 91, 91, 91, 93, 93, 99, 96, 96, 106, 108, 108, 108, 108, 108, 109, 109, 109, 109, 110, 111, 112, 112, 112, 112, 112, 112, 116, 116, 118, 121, 121, 121, 122, 122, 122, 122, 122, 124, 125, 125, 129, 123, 123, 123, 123, 123, 123, 123, 126, 126, 131, 128, 128, 128, 133, 133, 134, 136, 136, 136, 136, 136, 136, 140, 140, 140, 140, 140, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 142, 146, 146, 146, 148, 148, 151, 137, 137, 137, 137, 139, 139, 139, 149, 149, 150, 141, 141, 141, 141, 143, 143, 143, 144, 144, 145, 153, 153, 153, 153, 153, 153, 153, 153, 153, 153, 156, 156, 156, 156, 156, 156, 156, 156, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 157, 161, 161, 161, 161, 161, 161, 162, 162, 162, 162, 162, 163, 163, 163, 163, 164, 164, 164, 165, 165, 166, 154, 154, 154, 154, 155, 155, 155, 158, 158, 159], [1, 3, 4, 5, 8, 9, 10, 3, 4, 5, 8, 9, 10, 4, 5, 8, 9, 10, 5, 8, 9, 10, 2, 6, 7, 8, 9, 10, 11, 12, 13, 9, 10, 10, 7, 12, 12, 11, 13, 13, 17, 21, 23, 25, 16, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 16, 23, 25, 16, 25, 16, 20, 26, 27, 26, 27, 27, 19, 22, 24, 22, 24, 24, 31, 34, 36, 38, 30, 30, 34, 36, 38, 30, 36, 38, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 30, 32, 40, 41, 30, 40, 41, 41, 35, 37, 39, 37, 39, 39, 53, 45, 45, 48, 54, 54, 52, 54, 55, 54, 55, 55, 47, 50, 47, 51, 50, 51, 62, 70, 71, 73, 58, 58, 70, 71, 73, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 58, 73, 58, 59, 64, 67, 68, 69, 64, 67, 68, 69, 67, 68, 69, 68, 69, 69, 63, 66, 76, 77, 66, 76, 77, 76, 77, 77, 65, 72, 74, 75, 72, 74, 75, 74, 75, 75, 97, 102, 104, 97, 104, 97, 83, 88, 95, 83, 95, 95, 80, 84, 84, 81, 103, 105, 81, 105, 105, 87, 90, 98, 107, 90, 98, 107, 98, 107, 107, 89, 91, 93, 99, 100, 91, 93, 99, 100, 93, 99, 100, 99, 100, 100, 92, 106, 92, 110, 111, 114, 117, 109, 110, 111, 114, 117, 117, 114, 113, 115, 116, 118, 119, 120, 118, 119, 119, 124, 127, 122, 124, 125, 127, 129, 130, 127, 129, 130, 130, 126, 128, 131, 132, 133, 134, 135, 131, 132, 132, 133, 134, 135, 134, 135, 135, 140, 142, 146, 148, 151, 138, 138, 142, 146, 148, 151, 137, 138, 139, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 138, 148, 151, 138, 151, 138, 139, 149, 150, 152, 149, 150, 152, 150, 152, 152, 143, 144, 145, 147, 144, 145, 147, 145, 147, 147, 156, 157, 161, 162, 163, 164, 165, 166, 167, 155, 157, 161, 162, 163, 164, 165, 166, 167, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 162, 163, 164, 165, 166, 167, 163, 164, 165, 166, 167, 164, 165, 166, 167, 165, 166, 167, 166, 167, 167, 155, 158, 159, 160, 158, 159, 160, 159, 160, 160]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# idx_from = 0\n",
    "# idx_to = 0\n",
    "graph_counter = 0\n",
    "graph_bound\n",
    "edge_index = [[],[]]\n",
    "subgraph_edge_index = [[],[]]\n",
    "Gs = []\n",
    "sub_created = False\n",
    "from similarity import calculate_similarity_matrix, testt\n",
    "# AP Clustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "batches = []\n",
    "for b in train_loader:\n",
    "    batches.append(b)\n",
    "batch1 = batches[2]\n",
    "print(batch1)\n",
    "\n",
    "# return 0\n",
    "graph_bound = {}\n",
    "\n",
    "for i in range(len(batch1.ptr)-1):\n",
    "    graph_bound[i] = [batch1.ptr[i].item(), batch1.ptr[i+1].item()]\n",
    "    # print(str(i)+\".\", batch1.ptr[i].item(), \"-\", batch1.ptr[i+1].item())\n",
    "\n",
    "for i, (src, dst) in enumerate(zip(batch1.edge_index[0], batch1.edge_index[1])):\n",
    "    # if (graph_counter < len(batch1.ptr)):\n",
    "    lower_bound = graph_bound[graph_counter][0]\n",
    "    upper_bound = graph_bound[graph_counter][1]\n",
    "    if ((src >= lower_bound and src < upper_bound) or\n",
    "        (dst >= lower_bound and dst < upper_bound)):\n",
    "        # print(i,src.item()-lower_bound, dst.item()-lower_bound)\n",
    "        edge_index[0].append(src - lower_bound)\n",
    "        edge_index[1].append(dst - lower_bound)\n",
    "    else:\n",
    "        sub_created = True\n",
    "        # continue\n",
    "        \n",
    "        \n",
    "        # # print(edge_index)\n",
    "        # embs = []\n",
    "        # # make new graph\n",
    "        # for i, (b, emb) in enumerate(zip(batch1.batch, batch1.x)):\n",
    "        #     if (b == graph_counter):\n",
    "        #         # print(i, emb)\n",
    "        #         embs.append(emb)\n",
    "        \n",
    "        # G = data_transformation(edge_index, embs)\n",
    "        # Gs.append(G)\n",
    "        # print(sorted(list(G.nodes)))\n",
    "        # # print('pre', precalc_shortest_path_length)\n",
    "        # # for node in sorted(list(G.nodes)):\n",
    "        # #     print(G.nodes[node])\n",
    "        \n",
    "        \n",
    "        # # testt()\n",
    "        # if graph_counter == 10:\n",
    "        #     print('masalah disini bro')\n",
    "        #     break\n",
    "        \n",
    "        # # Calculate S matrix\n",
    "        # S = calculate_similarity_matrix(G)\n",
    "        \n",
    "        # # AP Clustering\n",
    "        # clustering = AffinityPropagation(affinity='precomputed', damping=0.9, random_state=123, max_iter=1000).fit(S)\n",
    "\n",
    "        # print(clustering.labels_)\n",
    "        # # print(clustering.)\n",
    "        \n",
    "        # communities = {}\n",
    "        # print(\"cluster labels:\", set(clustering.labels_))\n",
    "        # # communities init\n",
    "        # for lab in clustering.labels_:\n",
    "        #     communities[lab] = []\n",
    "        \n",
    "        # for nd, clust in enumerate(clustering.labels_):\n",
    "        #     communities[clust].append(nd)\n",
    "        # print(\"communities\", communities) \n",
    "            \n",
    "        # edge_index = [[],[]]\n",
    "        # graph_counter+=1\n",
    "        \n",
    "        # # make subgraph edge_index\n",
    "        # for c in communities:\n",
    "        #     w = G.subgraph(communities[c])\n",
    "        #     # print(\"edges subgraph\", w.edges)\n",
    "        #     for sub in w.edges:\n",
    "        #         # print(sub[0], sub[1])\n",
    "        #         subgraph_edge_index[0].append(sub[0] + lower_bound)\n",
    "        #         subgraph_edge_index[1].append(sub[1] + lower_bound)\n",
    "                \n",
    "        # print(subgraph_edge_index)\n",
    "        # print(f'=== Graph {graph_counter} ===') \n",
    "        \n",
    "    if (i == len(batch1.edge_index[0]) - 1) or sub_created:\n",
    "        print(f'=== Graph {graph_counter} ===')\n",
    "        \n",
    "        sub_created = False\n",
    "        \n",
    "        embs = []\n",
    "        # make new graph\n",
    "        for i, (b, emb) in enumerate(zip(batch1.batch, batch1.x)):\n",
    "            if (b == graph_counter):\n",
    "                # print(i, emb)\n",
    "                embs.append(emb)\n",
    "        \n",
    "        G = data_transformation(edge_index, embs)\n",
    "        print(G)\n",
    "        print(\"edge_idx\", edge_index)\n",
    "        print(max(G.nodes))\n",
    "        print(len(G.nodes))\n",
    "        \n",
    "        Gs.append(G)\n",
    "        \n",
    "        S = calculate_similarity_matrix(G)\n",
    "        # AP Clustering        \n",
    "        clustering = AffinityPropagation(affinity='precomputed', damping=0.9, random_state=123, max_iter=1000).fit(S)\n",
    "        \n",
    "        print(sorted(list(G.nodes)))\n",
    "        print(clustering.labels_)\n",
    "        \n",
    "        # Modif disini nanti\n",
    "        #########\n",
    "        communities = {}\n",
    "        # print(\"cluster labels:\", set(clustering.labels_))\n",
    "        # communities init\n",
    "        for lab in clustering.labels_:\n",
    "            communities[lab] = []\n",
    "        \n",
    "        for nd, clust in enumerate(clustering.labels_):\n",
    "            communities[clust].append(nd)\n",
    "        # print(\"communities\", communities) \n",
    "            \n",
    "        edge_index = [[],[]]\n",
    "        graph_counter+=1\n",
    "        \n",
    "        # make subgraph edge_index\n",
    "        for c in communities:\n",
    "            w = G.subgraph(communities[c])\n",
    "            # print(\"edges subgraph\", w.edges)\n",
    "            for sub in w.edges:\n",
    "                # print(sub[0], sub[1])\n",
    "                subgraph_edge_index[0].append(sub[0] + lower_bound)\n",
    "                subgraph_edge_index[1].append(sub[1] + lower_bound)\n",
    "                \n",
    "        print(subgraph_edge_index)\n",
    "        if (graph_counter == 10):\n",
    "            break\n",
    "        # print(f'=== Graph {graph_counter} ===')\n",
    "        # print(edge_index)\n",
    "        # print('udh di akhir')\n",
    "\n",
    "embeddings_used = []\n",
    "nodes_used = set(np.array(subgraph_edge_index).flatten())\n",
    "feat = batch1.x\n",
    "# for i, f in enumerate(feat):\n",
    "#     if(i in nodes_used):\n",
    "#         embeddings_used.append(feat[i].detach().numpy())\n",
    "        \n",
    "# print(len(embeddings_used))\n",
    "# z = torch.zeros(len(embeddings_used), len(embeddings_used[0]))\n",
    "# z = torch.tensor(embeddings_used)\n",
    "\n",
    "# print(torch.tensor(subgraph_edge_index).size())\n",
    "# nodes_used = set(np.array(subgraph_edge_index).flatten())\n",
    "# feat = batch1.x\n",
    "# for i, f in enumerate(feat):\n",
    "#     if(i in nodes_used):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sclab\\AppData\\Local\\Temp\\ipykernel_24520\\334928070.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(subgraph_edge_index), torch.tensor(embeddings)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from similarity import calculate_similarity_matrix, testt\n",
    "\n",
    "\n",
    "# AP Clustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Experiment(torch.nn.Module):\n",
    "    # merging type: o --> complement only, s --> substraction, c --> concatenation\n",
    "    def __init__(self, dataset, hidden_channels):\n",
    "        super(Experiment, self).__init__()\n",
    "        \n",
    "        # weight seed\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # embeddings for subgraph\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # self.conv6 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # classification layer\n",
    "        \n",
    "        self.lin = Linear(hidden_channels*2, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, ptr):\n",
    "        # Embed original\n",
    "        embedding = self.conv1(x, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv2(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        embedding = self.conv3(embedding, edge_index)\n",
    "        embedding = embedding.relu()\n",
    "        \n",
    "        # generate subgraph based on embeddings\n",
    "        feature_emb = embedding.detach()\n",
    "        # G = data_transformation(edge_index, feature_emb)\n",
    "        # S = calculate_similarity_matrix(G)\n",
    "        # clustering = AffinityPropagation(affinity='precomputed', random_state=123, max_iter=200).fit(S)\n",
    "        subgraph_edge_index, _ = self.subgraph_generator(feature_emb, edge_index, batch, ptr)\n",
    "        subgraph_embedding = self.conv4(embedding, subgraph_edge_index)\n",
    "        subgraph_embedding = subgraph_embedding.relu()\n",
    "        subgraph_embedding = self.conv5(subgraph_embedding, subgraph_edge_index)\n",
    "        subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        # subgraph_embedding = self.conv1(x, subgraph_edge_index)\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        # subgraph_embedding = self.conv2(subgraph_embedding, subgraph_edge_index)\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        # subgraph_embedding = self.conv3(subgraph_embedding, subgraph_edge_index)\n",
    "        # subgraph_embedding = subgraph_embedding.relu()\n",
    "        \n",
    "        # print(subgraph_edge_index)\n",
    "        embedding = global_mean_pool(embedding, batch)\n",
    "        # self.subgraph_pooling(\"\",\"\",\"\")\n",
    "        subgraph_embedding = global_max_pool(subgraph_embedding, batch)\n",
    "        \n",
    "        \n",
    "        h = torch.cat((embedding, subgraph_embedding), 1)\n",
    "        \n",
    "        h = F.dropout(h, p=0.3, training=self.training)\n",
    "        h = self.lin(h)\n",
    "        h = h.relu()\n",
    "        x = F.dropout(h, p=0.3, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return embedding, h\n",
    "    \n",
    "    def subgraph_pooling(self, embeddings, batch, ptr):\n",
    "        print('subgraph pooling')\n",
    "\n",
    "    def subgraph_generator(self, embeddings, batch_edge_index, batch, ptr):\n",
    "        '''\n",
    "        Return subgraph_edge_index (edge_index of created subgraph)\n",
    "        '''\n",
    "        # print('processing subgraph_generator...')\n",
    "        graph_counter = 0\n",
    "        edge_index = [[],[]]\n",
    "        subgraph_edge_index = [[],[]]\n",
    "        # Gs = []\n",
    "        sub_created = False\n",
    "        graph_bound = {}\n",
    "\n",
    "        for i in range(len(ptr)-1):\n",
    "            graph_bound[i] = [ptr[i].item(), ptr[i+1].item()]\n",
    "        \n",
    "        for i, (src, dst) in enumerate(zip(batch_edge_index[0], batch_edge_index[1])):\n",
    "            lower_bound = graph_bound[graph_counter][0]\n",
    "            upper_bound = graph_bound[graph_counter][1]\n",
    "            if ((src >= lower_bound and src < upper_bound) or\n",
    "                (dst >= lower_bound and dst < upper_bound)):\n",
    "                \n",
    "                edge_index[0].append(src - lower_bound)\n",
    "                edge_index[1].append(dst - lower_bound)\n",
    "            else:\n",
    "                sub_created = True\n",
    "                \n",
    "            if (i == len(batch_edge_index[0]) - 1) or sub_created:\n",
    "                # print(f'=== Graph {graph_counter} ===')\n",
    "                \n",
    "                sub_created = False\n",
    "                \n",
    "                embs = []\n",
    "                # make new graph\n",
    "                for i, (b, emb) in enumerate(zip(batch, embeddings)):\n",
    "                    if (b == graph_counter):\n",
    "                        embs.append(emb)\n",
    "                \n",
    "                G = data_transformation(edge_index, embs)\n",
    "                # dont need this at the moment\n",
    "                # Gs.append(G)\n",
    "                \n",
    "                # Calculate similarity matrix\n",
    "                S = calculate_similarity_matrix(G)\n",
    "                \n",
    "                # AP Clustering        \n",
    "                # clustering = AffinityPropagation(affinity='precomputed', damping=0.9, random_state=123, max_iter=1000).fit(S)\n",
    "                clustering = AffinityPropagation(affinity='precomputed', damping=0.9, random_state=123, convergence_iter=5, max_iter=100).fit(S)\n",
    "                \n",
    "                # Get community\n",
    "                communities = {}\n",
    "                for lab in clustering.labels_:\n",
    "                    communities[lab] = []\n",
    "                \n",
    "                for nd, clust in enumerate(clustering.labels_):\n",
    "                    communities[clust].append(nd)\n",
    "                \n",
    "                edge_index = [[],[]]\n",
    "                graph_counter+=1\n",
    "                \n",
    "                # Make subgraph edge_index\n",
    "                for c in communities:\n",
    "                    w = G.subgraph(communities[c])\n",
    "                    for sub in w.edges:\n",
    "                        subgraph_edge_index[0].append(sub[0] + lower_bound)\n",
    "                        subgraph_edge_index[1].append(sub[1] + lower_bound)\n",
    "                        \n",
    "                # INI LUPA WOY\n",
    "                # if (graph_counter == 10):\n",
    "                #     break\n",
    "                \n",
    "                \n",
    "        # print(\"finished subgraph_generator\")\n",
    "        \n",
    "        # embeddings_used = []\n",
    "        # nodes_used = set(np.array(subgraph_edge_index).flatten())\n",
    "        \n",
    "        # for i, f in enumerate(embeddings):\n",
    "        #     if(i in nodes_used):\n",
    "        #         embeddings_used.append(embeddings[i].detach().numpy())\n",
    "                \n",
    "        \n",
    "        # print(\"nodes used\", len(nodes_used))\n",
    "        # print(\"nodes used\", (nodes_used))\n",
    "        # z = torch.tensor(embeddings_used)\n",
    "        # print(z.size())\n",
    "        \n",
    "        # return torch.tensor(subgraph_edge_index), z\n",
    "        # pakai embeddings yang awal\n",
    "        return torch.tensor(subgraph_edge_index), torch.tensor(embeddings)\n",
    "    # (embeddings)\n",
    "    \n",
    "btch = None\n",
    "experiment = Experiment(dataset, 64)\n",
    "bcount = 0\n",
    "for b in train_loader:\n",
    "    # print(\"batch count\",bcount)\n",
    "    bcount+=1\n",
    "    btch = b\n",
    "    # print(btch.ptr)\n",
    "    experiment(btch.x, btch.edge_index, btch.batch, btch.ptr)\n",
    "    break\n",
    "    # break\n",
    "    # experiment(btch.x, btch.edge_index, btch.batch)\n",
    "\n",
    "# print(experiment)\n",
    "# experiment(btch.x, btch.edge_index, btch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expTrain(train_loader, val_loader, test_loader, epoch = 2):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning) \n",
    "\n",
    "    experiment = Experiment(dataset, 64)\n",
    "\n",
    "    # Train\n",
    "    print('process training')\n",
    "    for _ in range(epoch):\n",
    "        loss = round(train_base(experiment, train_loader, True).item(), 5)\n",
    "        train_acc = round(test_base(experiment, train_loader, True), 5)\n",
    "        val_acc = round(test_base(experiment, val_loader, True), 5)\n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; test_acc: {val_acc}')\n",
    "\n",
    "    # Test\n",
    "    print('process testing')\n",
    "    test = test_base(experiment, test_loader, True)\n",
    "    print(f'Accuracy: {test}')\n",
    "\n",
    "# expTrain(train_loader, val_loader, test_loader, epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseTrain(train_loader, val_loader, test_loader, epoch = 10):\n",
    "    base = Base(dataset, 64)\n",
    "\n",
    "    # Train\n",
    "    for _ in range(epoch):\n",
    "        loss = round(train_base(base, train_loader).item(), 5)\n",
    "        train_acc = round(test_base(base, train_loader), 5)\n",
    "        val_acc = round(test_base(base, val_loader), 5)\n",
    "        \n",
    "        print(f'epoch {_}; loss: {loss}; train_acc: {train_acc}; val_acc: {val_acc}; test: {round(test_base(base, test_loader), 2)}')\n",
    "\n",
    "    # Test\n",
    "    test = test_base(base, test_loader)\n",
    "    print(f'Accuracy: {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0/10\n",
      "=== Base model ===\n",
      "epoch 0; loss: 0.66798; train_acc: 0.67778; val_acc: 0.575; test: 0.64\n",
      "epoch 1; loss: 0.69515; train_acc: 0.61389; val_acc: 0.475; test: 0.52\n",
      "epoch 2; loss: 0.56255; train_acc: 0.69583; val_acc: 0.6375; test: 0.76\n",
      "epoch 3; loss: 0.60316; train_acc: 0.61528; val_acc: 0.4625; test: 0.49\n",
      "epoch 4; loss: 0.53212; train_acc: 0.725; val_acc: 0.625; test: 0.73\n",
      "epoch 5; loss: 0.52244; train_acc: 0.74167; val_acc: 0.6375; test: 0.75\n",
      "epoch 6; loss: 0.55323; train_acc: 0.74306; val_acc: 0.65; test: 0.73\n",
      "epoch 7; loss: 0.49166; train_acc: 0.74028; val_acc: 0.6625; test: 0.73\n",
      "epoch 8; loss: 0.58636; train_acc: 0.68056; val_acc: 0.5375; test: 0.6\n",
      "epoch 9; loss: 0.51889; train_acc: 0.74028; val_acc: 0.6625; test: 0.72\n",
      "Accuracy: 0.72\n",
      "=== Experiment model ===\n",
      "process training\n",
      "epoch 0; loss: 0.69331; train_acc: 0.475; test_acc: 0.575\n",
      "epoch 1; loss: 0.59453; train_acc: 0.67778; test_acc: 0.5625\n",
      "epoch 2; loss: 0.63216; train_acc: 0.6125; test_acc: 0.475\n",
      "epoch 3; loss: 0.60769; train_acc: 0.69861; test_acc: 0.675\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_dataset\n",
    "test_dataset\n",
    "k = 10\n",
    "\n",
    "splits = KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "k_counter = 0\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(train_dataset)))):\n",
    "    # print('Fold {}'.format(fold + 1))\n",
    "    # print(f'Fold',fold,'Train_idx',train_idx,'Val_idx',val_idx)\n",
    "    print(f'Fold {fold}/{k}')\n",
    "    #if k_counter > 2:\n",
    "    #    break\n",
    "    \n",
    "    fold_train = []\n",
    "    for key in train_idx:\n",
    "        fold_train.append(dataset[key])\n",
    "\n",
    "    fold_val = [] \n",
    "    for key in val_idx:\n",
    "        fold_val.append(dataset[key])\n",
    "\n",
    "    tr = DataLoader(fold_train, batch_size=batch_size, shuffle=False)\n",
    "    vd = DataLoader(fold_val, batch_size=batch_size, shuffle=False)\n",
    "    ts = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Base model\n",
    "    print(\"=== Base model ===\")\n",
    "    baseTrain(tr, vd, ts, 10)\n",
    "    print(\"=== Experiment model ===\")\n",
    "    expTrain(tr, vd, ts, 10)\n",
    "    \n",
    "    k_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
